id,technology,published,updated,title,summary,authors
http://arxiv.org/abs/2406.04641v1,3D printing,2024-06-07T04:56:05Z,2024-06-07T04:56:05Z,"Preparation of high precision aspherical lenses based on micro
  stereolithography technology","  The 3D printing technology based on digital light processing (DLP) has
highlighted its powerful manufacturing capabilities for optical components.
However, the printing structure obtained by DLP based down projection printing
is easily adhered to the printing window below, and the printed lens surface
will have a step effect. This article uses DLP 3D printing technology to print
non spherical lenses. During the printing process, a new type of inert liquid
fluoride solution was used as the isolation layer, which can more effectively
and conveniently prevent the printing structure from sticking to the printing
window. At the same time, a vertical lifting immersion method was proposed to
smooth the step effect on the surface of the lens.
","['Xiaoying Lu', 'Hua Liu']"
http://arxiv.org/abs/1405.0199v1,3D printing,2014-02-25T04:43:22Z,2014-02-25T04:43:22Z,"Liquid Phase 3D Printing for Quickly Manufacturing Metal Objects with
  Low Melting Point Alloy Ink","  Conventional 3D printings are generally time-consuming and printable metal
inks are rather limited. From an alternative way, we proposed a liquid phase 3D
printing for quickly making metal objects. Through introducing metal alloys
whose melting point is slightly above room temperature as printing inks,
several representative structures spanning from one, two and three dimension to
more complex patterns were demonstrated to be quickly fabricated. Compared with
the air cooling in a conventional 3D printing, the liquid-phase-manufacturing
offers a much higher cooling rate and thus significantly improves the speed in
fabricating metal objects. This unique strategy also efficiently prevents the
liquid metal inks from air oxidation which is hard to avoid otherwise in an
ordinary 3D printing. Several key physical factors (like properties of the
cooling fluid, injection speed and needle diameter, types and properties of the
printing ink, etc.) were disclosed which would evidently affect the printing
quality. In addition, a basic route to make future liquid phase 3D printer
incorporated with both syringe pump and needle arrays was also suggested. The
liquid phase 3D printing method, which owns potential values not available in a
conventional modality, opens an efficient way for quickly making metal objects
in the coming time.
","['Lei Wang', 'Jing Liu']"
http://arxiv.org/abs/2202.11426v2,3D printing,2022-02-23T11:14:24Z,2022-03-29T16:06:20Z,Open5x: Accessible 5-axis 3D printing and conformal slicing,"  The common layer-by-layer deposition of regular, 3-axis 3D printing
simplifies both the fabrication process and the 3D printer's mechanical design.
However, the resulting 3D printed objects have some unfavourable
characteristics including visible layers, uneven structural strength and
support material. To overcome these, researchers have employed robotic arms and
multi-axis CNCs to deposit materials in conformal layers. Conformal deposition
improves the quality of the 3D printed parts through support-less printing and
curved layer deposition. However, such multi-axis 3D printing is inaccessible
to many individuals due to high costs and technical complexities. Furthermore,
the limited GUI support for conformal slicers creates an additional barrier for
users. To open multi-axis 3D printing up to more makers and researchers, we
present a cheap and accessible way to upgrade a regular 3D printer to 5 axes.
We have also developed a GUI-based conformal slicer, integrated within a
popular CAD package. Together, these deliver an accessible workflow for
designing, simulating and creating conformally-printed 3D models.
","['Freddie Hong', 'Steve Hodges', 'Connor Myant', 'David Boyle']"
http://arxiv.org/abs/2401.11778v1,3D printing,2024-01-22T09:17:24Z,2024-01-22T09:17:24Z,All Inkjet-printed Organic Solar Cells on 3D Objects,"  Drop-on-demand inkjet printing is a promising and commercially relevant
technology for producing organic electronic devices of arbitrary shape on a
wide variety of different substrates. In this work we transfer the inkjet
printing process of organic photovoltaic devices from 2D to 3D substrates,
using a 5-axis robot system equipped with a multi nozzle inkjet printing unit.
We present a ready-to-use 3D printing system for industrial application, using
a 5-axis motion system controlled by commercial 3D motion software, combined
with a commonly used multi-nozzle inkjet print head controlled by the
corresponding printing software. The very first time inkjet-printed solar cells
on glass/ITO with power conversion efficiencies (PCE) of up to 7% are realized
on a 3D object with surfaces tilted by angles of up to 60{\deg} against the
horizontal direction. Undesired ink flow during deposition of the
inkjet-printed layers was avoided by proper ink formulation. In order to be
able to print organic (opto-)electronic devices also on substrates without
sputtered indium tin oxide bottom electrode, the bottom electrode was
inkjet-printed from silver nanoparticle (AgNP) ink, resulting in the first all
inkjet-printed (i.e., including bottom electrode) solar cell on a 3D object
ever with a record PCE of 2.5%. This work paves the way for functionalizing
even complex objects, such as cars, mobile phones, or Internet of Things (IoT)
applications with inkjet-printed (opto-)electronic devices.
","['Marc Steinberger', 'Andreas Distler', 'Johannes Hörber', 'Kai Cheong Tam', 'Christoph J. Brabec', 'Hans-Joachim Egelhaaf']"
http://arxiv.org/abs/2305.09394v1,3D printing,2023-05-16T12:28:15Z,2023-05-16T12:28:15Z,"3D Printing and Design in Isolation: A Case from a Simulated Lunar
  Mission","  Despite the decades-long history of 3D printing, it is not used to its full
potential. Yet 3D printing holds promise for isolated communities, aiming for
self-sufficiency. In this experiential study conducted in an analog space
habitat we evaluated challenges and opportunities of using 3D printing. Our
study revealed barriers such as: 1) setting up and maintaining the 3D printing
equipment while minding different kinds of pollution, that is air, temperature
and sound, 2) design skill and familiarity with specialized software as well as
materials and 3) the awareness of what can be achieved to meet community needs.
We observed that in-community experience and know-how are reliable sources of
3D print ideas, that improve quality of life of community members if they are
encouraged and supported by participatory design. Co-design of 3D prints in
small, specialized communities is a promising area of study, that can bring new
applications of 3D print technology.
","['Wiktor Stawski', 'Kinga Skorupska', 'Wiesław Kopeć']"
http://arxiv.org/abs/2103.02063v1,3D printing,2021-03-02T22:25:34Z,2021-03-02T22:25:34Z,A 3D Printing Hexacopter: Design and Demonstration,"  3D printing using robots has garnered significant interest in manufacturing
and construction in recent years. A robot's versatility paired with the design
freedom of 3D printing offers promising opportunities for how parts and
structures are built in the future. However, 3D printed objects are still
limited in size and location due to a lack of vertical mobility of ground
robots. These limitations severely restrict the potential of the 3D printing
process. To overcome these limitations, we develop a hexacopter testbed that
can print via fused deposition modeling during flight. We discuss the design of
this testbed and develop a simple control strategy for initial print tests. By
successfully performing these initial print tests, we demonstrate the
feasibility of this approach and lay the groundwork for printing 3D parts and
structures with drones.
","['Alexander Nettekoven', 'Ufuk Topcu']"
http://arxiv.org/abs/2105.10943v1,3D printing,2021-05-23T14:25:34Z,2021-05-23T14:25:34Z,4D printing of mechanical metamaterials,"  Mechanical metamaterials owe their extraordinary properties and
functionalities to their micro-/nanoscale design of which shape, including both
geometry and topology, is perhaps the most important aspect. 4D printing
enables programmed, predictable, and precise change in the shape of mechanical
metamaterials to achieve multi-functionality, adaptive properties, and the
other types of desired behaviors that cannot be achieved using simple 3D
printing. This paper presents an overview of 4D printing as applied to
mechanical metamaterials. It starts by presenting a systematic definition of
what 4D printing is and what shape aspects (e.g., geometry, topology) are
relevant for the 4D printing of mechanical metamaterials. Instead of focusing
on different printing processes and materials, the paper addresses the most
fundamental aspects of the shapeshifting behaviors required for transforming a
flat construct to a target 3D shape (i.e., 2D to 3D shapeshifting) or
transforming a 3D shape to another 3D shape (i.e., 3D to 3D shapeshifting). In
either case, we will discuss the rigid-body shape morphing (e.g., rigid
origami) as well as deformable-body shapeshifting. The paper concludes with a
discussion of the major challenges ahead of us for applying 4D printing to
mechanical metamaterials and suggests several areas for future research.
",['Amir A. Zadpoor']
http://arxiv.org/abs/2403.16470v1,3D printing,2024-03-25T06:52:26Z,2024-03-25T06:52:26Z,Data-Driven Extrusion Force Control Tuning for 3D Printing,"  The quality of 3D prints often varies due to different conditions inherent to
each print, such as filament type, print speed, and nozzle size. Closed-loop
process control methods improve the accuracy and repeatability of 3D prints.
However, optimal tuning of controllers for given process parameters and design
geometry is often a challenge with manually tuned controllers resulting in
inconsistent and suboptimal results. This work employs Bayesian optimization to
identify the optimal controller parameters. Additionally, we explore transfer
learning in the context of 3D printing by leveraging prior information from
past trials. By integrating optimized extrusion force control and transfer
learning, we provide a novel framework for closed-loop 3D printing and propose
an automated calibration routine that produces high-quality prints for a
desired combination of print settings, material, and shape.
","['Xavier Guidetti', 'Ankita Mukne', 'Marvin Rueppel', 'Yannick Nagel', 'Efe C. Balta', 'John Lygeros']"
http://arxiv.org/abs/1705.05893v1,3D printing,2017-05-16T19:56:58Z,2017-05-16T19:56:58Z,"Computed Axial Lithography (CAL): Toward Single Step 3D Printing of
  Arbitrary Geometries","  Most additive manufacturing processes today operate by printing voxels (3D
pixels) serially point-by-point to build up a 3D part. In some more
recently-developed techniques, for example optical printing methods such as
projection stereolithography [Zheng et al. 2012], [Tumbleston et al. 2015],
parts are printed layer-by-layer by curing full 2d (very thin in one dimension)
layers of the 3d part in each print step. There does not yet exist a technique
which is able to print arbitrarily-defined 3D geometries in a single print
step. If such a technique existed, it could be used to expand the range of
printable geometries in additive manufacturing and relax constraints on factors
such as overhangs in topology optimization. It could also vastly increase print
speed for 3D parts. In this work, we develop the principles for an approach for
single exposure 3D printing of arbitrarily defined geometries. The approach,
termed Computed Axial Lithgography (CAL), is based on tomographic
reconstruction, with mathematical optimization to generate a set of projections
to optically define an arbitrary dose distribution within a target volume. We
demonstrate the potential ability of the technique to print 3D parts using a
prototype CAL system based on sequential illumination from many angles. We also
propose new hardware designs which will help us to realize true single-shot
arbitrary-geometry 3D CAL.
","['Brett Kelly', 'Indrasen Bhattacharya', 'Maxim Shusteff', 'Robert M. Panas', 'Hayden K. Taylor', 'Christopher M. Spadaccini']"
http://arxiv.org/abs/1406.4817v1,3D printing,2014-06-15T06:28:17Z,2014-06-15T06:28:17Z,3D Printing of Scintillating Materials,"  We demonstrate, for the first time, the applicability of 3D printing
technique to the manufacture of scintillation detectors. We report of a
formulation, usable in stereolithographic printing, that exhibits scintillation
efficiency on the order of 30\% of that of commercial polystyrene based
scintillators. We discuss the applicability of these techniques and propose
future enhancements that will allow tailoring the printed scintillation
detectors to various application.
","['Y. Mishnayot', 'M. Layani', 'I. Cooperstein', 'S. Magdassi', 'G. Ron']"
http://arxiv.org/abs/1809.07940v1,3D printing,2018-09-21T04:28:49Z,2018-09-21T04:28:49Z,"Printing-while-moving: a new paradigm for large-scale robotic 3D
  Printing","  Building and Construction have recently become an exciting application ground
for robotics. In particular, rapid progress in materials formulation and in
robotics technology has made robotic 3D Printing of concrete a promising
technique for in-situ construction. Yet, scalability remains an important
hurdle to widespread adoption: the printing systems (gantry- based or
arm-based) are often much larger than the structure to be printed, hence
cumbersome. Recently, a mobile printing system - a manipulator mounted on a
mobile base - was proposed to alleviate this issue: such a system, by moving
its base, can potentially print a structure larger than itself. However, the
proposed system could only print while being stationary, imposing thereby a
limit on the size of structures that can be printed in a single take. Here, we
develop a system that implements the printing-while-moving paradigm, which
enables printing single-piece structures of arbitrary sizes with a single
robot. This development requires solving motion planning, localization, and
motion control problems that are specific to mobile 3D Printing. We report our
framework to address those problems, and demonstrate, for the first time, a
printing-while-moving experiment, wherein a 210 cm x 45 cm x 10 cm concrete
structure is printed by a robot arm that has a reach of 87 cm.
","['Mehmet Efe Tiryaki', 'Xu Zhang', 'Quang-Cuong Pham']"
http://arxiv.org/abs/1806.00394v1,3D printing,2018-06-01T15:28:58Z,2018-06-01T15:28:58Z,3D Conductive Polymer Printed Metasurface Antenna for Fresnel Focusing,"  We demonstrate a 3D printed holographic metasurface antenna for beam-focusing
applications at 10 GHz within the X-band frequency regime. The metasurface
antenna is printed using a dual-material 3D printer leveraging a biodegradable
conductive polymer material (Electrifi) to print the conductive parts and
polylactic acid (PLA) to print the dielectric substrate. The entire metasurface
antenna is 3D printed at once; no additional techniques, such as metal-plating
and laser etching, are required. It is demonstrated that using the 3D printed
conductive polymer metasurface antenna, high-fidelity beam focusing can be
achieved within the Fresnel region of the antenna. It is also shown that the
material conductivity for 3D printing has a substantial effect on the radiation
characteristics of the metasurface antenna.
","['Okan Yurduseven', 'Shengrong Ye', 'Thomas Fromenteze', 'Daniel L. Marks', 'Benjamin J. Wiley', 'David R. Smith']"
http://arxiv.org/abs/2404.11776v1,3D printing,2024-04-17T21:57:29Z,2024-04-17T21:57:29Z,"3D object quality prediction for Metal Jet Printer with Multimodal
  thermal encoder","  With the advancements in 3D printing technologies, it is extremely important
that the quality of 3D printed objects, and dimensional accuracies should meet
the customer's specifications. Various factors during metal printing affect the
printed parts' quality, including the power quality, the printing stage
parameters, the print part's location inside the print bed, the curing stage
parameters, and the metal sintering process. With the large data gathered from
HP's MetJet printing process, AI techniques can be used to analyze, learn, and
effectively infer the printed part quality metrics, as well as assist in
improving the print yield. In-situ thermal sensing data captured by
printer-installed thermal sensors contains the part thermal signature of fusing
layers. Such part thermal signature contains a convoluted impact from various
factors. In this paper, we use a multimodal thermal encoder network to fuse
data of a different nature including the video data vectorized printer control
data, and exact part thermal signatures with a trained encoder-decoder module.
We explored the data fusing techniques and stages for data fusing, the
optimized end-to-end model architecture indicates an improved part quality
prediction accuracy.
","[' Rachel', ' Chen', 'Wenjia Zheng', 'Sandeep Jalui', 'Pavan Suri', 'Jun Zeng']"
http://arxiv.org/abs/1605.03246v1,3D printing,2016-05-10T23:41:51Z,2016-05-10T23:41:51Z,"Analysis of 3D-printed metal for rapid-prototyped reflective terahertz
  optics","  We explore the potential of 3D metal printing to realize complex conductive
terahertz devices. Factors impacting performance such as printing resolution,
surface roughness, oxidation, and material loss are investigated via
analytical, numerical, and experimental approaches. The high degree of control
offered by a 3D-printed topology is exploited to realize a zone plate operating
at 530 GHz. Reflection efficiency at this frequency is found to be over 90%.
The high-performance of this preliminary device suggest that 3D metal printing
can play a strong role in guided-wave and general beam control devices in the
terahertz range.
","['Daniel Headland', 'Withawat Withayachumnankul', 'Michael Webb', 'Heike Ebendorff-Heidepriem', 'Andre Luiten', 'Derek Abbott']"
http://arxiv.org/abs/2501.11995v1,3D printing,2025-01-21T09:34:37Z,2025-01-21T09:34:37Z,"Fabrication of Poly (ε-Caprolactone) 3D scaffolds with
  controllable porosity using ultrasound","  3D printing has progressed significantly, allowing objects to be produced
using a wide variety of materials. Recent advances have employed focused
ultrasound in 3D printing, to allow printing inside acoustically transparent
materials. Here we introduce a Selective Ultrasonic Melting (SUM) method for 3D
printing of poly ({\epsilon}-caprolactone) (PCL) powder mixed with water. The
printing was done by mechanically moving a focused ultrasound transducer. The
microstructure and porosity of the prints were analyzed with micro-computed
tomography ({\mu}CT). The open porosity of the printed samples was determined
using the water intrusion method and by passing fluorescent microspheres
through the structure. The cytocompatibility of the printed structures was
confirmed by seeding NIH-3T3 fibroblast cells on the scaffolds, followed by
analysis using live/dead fluorescent assay. and visualization using scanning
electron microscopy (SEM). We demonstrated that SUM is a viable technique to
print structures with active control of their porosity This method provides an
alternative to methods such as fused deposition modelling (FDM) and material
jetting.
","['Martin Weber', 'Dmitry Nikolaev', 'Mikko Koskenniemi', 'Jere Hyvönen', 'Joel Jääskeläinen', 'Armand Navarre', 'Ekaterina Takmakova', 'Arun Teotia', 'Pekka Katajisto', 'Robert Luxenhofer', 'Edward Hæggström', 'Ari Salmi']"
http://arxiv.org/abs/2401.08982v1,3D printing,2024-01-17T05:26:30Z,2024-01-17T05:26:30Z,Robot Tape Manipulation for 3D Printing,"  3D printing has enabled various applications using different forms of
materials, such as filaments, sheets, and inks. Typically, during 3D printing,
feedstocks are transformed into discrete building blocks and placed or
deposited in a designated location similar to the manipulation and assembly of
discrete objects. However, 3D printing of continuous and flexible tape (with
the geometry between filaments and sheets) without breaking or transformation
remains underexplored and challenging. Here, we report the design and
implementation of a customized end-effector, i.e., tape print module (TPM), to
realize robot tape manipulation for 3D printing by leveraging the tension
formed on the tape between two endpoints. We showcase the feasibility of
manufacturing representative 2D and 3D structures while utilizing conductive
copper tape for various electronic applications, such as circuits and sensors.
We believe this manipulation strategy could unlock the potential of other tape
materials for manufacturing, including packaging tape and carbon fiber prepreg
tape, and inspire new mechanisms for robot manipulation, 3D printing, and
packaging.
","['Nahid Tushar', 'Rencheng Wu', 'Yu She', 'Wenchao Zhou', 'Wan Shou']"
http://arxiv.org/abs/1807.02921v1,3D printing,2018-07-09T02:52:01Z,2018-07-09T02:52:01Z,"Inferring Quality in Point Cloud-based 3D Printed Objects using
  Topological Data Analysis","  Assessing the quality of 3D printed models before they are printed remains a
challeng- ing problem, particularly when considering point cloud-based models.
This paper introduces an approach to quality assessment, which uses techniques
from the field of Topological Data Analy- sis (TDA) to compute a topological
abstraction of the eventual printed model. Two main tools of TDA, Mapper and
persistent homology, are used to analyze both the printed space and empty space
created by the model. This abstraction enables investigating certain qualities
of the model, with respect to print quality, and identifies potential anomalies
that may appear in the final product.
","['Paul Rosen', 'Mustafa Hajij', 'Junyi Tu', 'Tanvirul Arafin', 'Les Piegl']"
http://arxiv.org/abs/1605.09737v1,3D printing,2016-05-31T17:39:49Z,2016-05-31T17:39:49Z,3D Printed Stencils for Texturing Flat Surfaces,"  We address the problem of texturing flat surfaces by spray-painting through
3D printed stencils. We propose a system that (1) decomposes an image into
alpha-blended layers; (2) computes a stippling given a transparency channel;
(3) generates a 3D printed stencil given a stippling and (4) simulates the
effects of spray-painting through the stencil.
",['Vaibhav Vavilala']
http://arxiv.org/abs/2004.12471v2,3D printing,2020-04-26T20:22:31Z,2020-07-11T14:12:22Z,3D Printed Lightweight Composite Foams,"  The goal of this paper is to enable 3D printed lightweight composite foams by
blending hollow glass micro balloons (GMB) with high density polyethylene
(HDPE). To that end, lightweight feedstock for printing syntactic foam
composites is developed. The blend for this is prepared by varying GMB content
(20, 40, and 60 volume %) in HDPE for filament extrusion, which is subsequently
used for three-dimensional printing (3DP). The rheological properties and the
melt flow index (MFI) of blends are investigated for identifying suitable
printing parameters. It is observed that the storage and loss modulus, as well
as complex viscosity, increases with increasing GMB content, whereas MFI
decreases. Further, the coefficient of thermal expansion of HDPE and foam
filaments decreases with increasing GMB content, thereby lowering the thermal
stresses in prints, which promotes the reduction in warpage. The mechanical
properties of filaments are determined by subjecting them to tensile tests,
whereas 3D printed samples are tested under tensile and flexure tests. The
tensile modulus of the filament increases with increasing GMB content (8-47%)
as compared to HDPE and exhibit comparable filament strength. 3D printed foams
show higher specific tensile and flexural modulus as compared to neat HDPE,
making them suitable candidate materials for weight sensitive applications.
HDPE having 60% by volume GMB exhibited the highest modulus and is 48.02%
higher than the printed HDPE. Finally, the property map reveals higher modulus
and comparable strength against injection and compression molded foams. Printed
foam registered 1.8 times higher modulus than molded samples. Hence, 3D printed
foams have the potential for replacing components processed through
conventional manufacturing processes that have limitations on geometrically
complex designs, lead time, and associated costs.
","['Bharath H S', 'Dileep Bonthu', 'Pavana Prabhakar', 'Mrityunjay Doddamani']"
http://arxiv.org/abs/1605.04797v2,3D printing,2016-05-16T15:09:19Z,2016-07-02T03:15:10Z,"Thingi10K: A Dataset of 10,000 3D-Printing Models","  Empirically validating new 3D-printing related algorithms and implementations
requires testing data representative of inputs encountered \emph{in the wild}.
An ideal benchmarking dataset should not only draw from the same distribution
of shapes people print in terms of class (e.g., toys, mechanisms, jewelry),
representation type (e.g., triangle soup meshes) and complexity (e.g., number
of facets), but should also capture problems and artifacts endemic to 3D
printing models (e.g., self-intersections, non-manifoldness). We observe that
the contextual and geometric characteristics of 3D printing models differ
significantly from those used for computer graphics applications, not to
mention standard models (e.g., Stanford bunny, Armadillo, Fertility). We
present a new dataset of 10,000 models collected from an online 3D printing
model-sharing database. Via analysis of both geometric (e.g., triangle aspect
ratios, manifoldness) and contextual (e.g., licenses, tags, classes)
characteristics, we demonstrate that this dataset represents a more concise
summary of real-world models used for 3D printing compared to existing
datasets. To facilitate future research endeavors, we also present an online
query interface to select subsets of the dataset according to project-specific
characteristics. The complete dataset and per-model statistical data are freely
available to the public.
","['Qingnan Zhou', 'Alec Jacobson']"
http://arxiv.org/abs/2304.02924v1,Artificial intelligence,2023-04-06T08:26:38Z,2023-04-06T08:26:38Z,The Governance of Physical Artificial Intelligence,"  Physical artificial intelligence can prove to be one of the most important
challenges of the artificial intelligence. The governance of physical
artificial intelligence would define its responsible intelligent application in
the society.
","['Yingbo Li', 'Anamaria-Beatrice Spulber', 'Yucong Duan']"
http://arxiv.org/abs/2005.10488v1,Artificial intelligence,2020-05-21T07:00:31Z,2020-05-21T07:00:31Z,"Does an artificial intelligence perform market manipulation with its own
  discretion? -- A genetic algorithm learns in an artificial market simulation","  Who should be charged with responsibility for an artificial intelligence
performing market manipulation have been discussed. In this study, I
constructed an artificial intelligence using a genetic algorithm that learns in
an artificial market simulation, and investigated whether the artificial
intelligence discovers market manipulation through learning with an artificial
market simulation despite a builder of artificial intelligence has no intention
of market manipulation. As a result, the artificial intelligence discovered
market manipulation as an optimal investment strategy. This result suggests
necessity of regulation, such as obligating builders of artificial intelligence
to prevent artificial intelligence from performing market manipulation.
",['Takanobu Mizuta']
http://arxiv.org/abs/1509.01213v1,Artificial intelligence,2015-07-01T16:26:21Z,2015-07-01T16:26:21Z,Impact of Artificial Intelligence on Economic Theory,"  Artificial intelligence has impacted many aspects of human life. This paper
studies the impact of artificial intelligence on economic theory. In particular
we study the impact of artificial intelligence on the theory of bounded
rationality, efficient market hypothesis and prospect theory.
",['Tshilidzi Marwala']
http://arxiv.org/abs/2101.02179v1,Artificial intelligence,2020-12-27T23:45:03Z,2020-12-27T23:45:03Z,The case for psychometric artificial general intelligence,"  A short review of the literature on measurement and detection of artificial
general intelligence is made. Proposed benchmarks and tests for artificial
general intelligence are critically evaluated against multiple criteria. Based
on the findings, the most promising approaches are identified and some useful
directions for future work are proposed.
",['Mark McPherson']
http://arxiv.org/abs/1304.3846v1,Artificial intelligence,2013-04-13T20:44:25Z,2013-04-13T20:44:25Z,"Proceedings of the Thirteenth Conference on Uncertainty in Artificial
  Intelligence (1997)","  This is the Proceedings of the Thirteenth Conference on Uncertainty in
Artificial Intelligence, which was held in Providence, RI, August 1-3, 1997
","['Dan Geiger', 'Prakash Shenoy']"
http://arxiv.org/abs/1304.3851v1,Artificial intelligence,2013-04-13T21:03:12Z,2013-04-13T21:03:12Z,"Proceedings of the Ninth Conference on Uncertainty in Artificial
  Intelligence (1993)","  This is the Proceedings of the Ninth Conference on Uncertainty in Artificial
Intelligence, which was held in Washington, DC, July 9-11, 1993
","['David Heckerman', 'E. Mamdani']"
http://arxiv.org/abs/1304.3859v1,Artificial intelligence,2013-04-13T21:37:12Z,2013-04-13T21:37:12Z,"Proceedings of the Second Conference on Uncertainty in Artificial
  Intelligence (1986)","  This is the Proceedings of the Second Conference on Uncertainty in Artificial
Intelligence, which was held in Philadelphia, PA, August 8-10, 1986
","['Laveen Kanal', 'John Lemmer']"
http://arxiv.org/abs/1311.0716v1,Artificial intelligence,2013-10-30T14:19:49Z,2013-10-30T14:19:49Z,Artificial Intelligence in Humans,"  In this paper, I put forward that in many instances, thinking mechanisms are
equivalent to artificial intelligence modules programmed into the human mind.
",['Michael Swan Laufer']
http://arxiv.org/abs/1810.06018v1,Artificial intelligence,2018-10-14T11:40:30Z,2018-10-14T11:40:30Z,"AAAI FSS-18: Artificial Intelligence in Government and Public Sector
  Proceedings","  Proceedings of the AAAI Fall Symposium on Artificial Intelligence in
Government and Public Sector, Arlington, Virginia, USA, October 18-20, 2018
","['Frank Stein', 'Alun Preece', 'Mihai Boicu']"
http://arxiv.org/abs/2104.13155v2,Artificial intelligence,2021-04-27T13:03:25Z,2021-05-07T18:34:10Z,"Watershed of Artificial Intelligence: Human Intelligence, Machine
  Intelligence, and Biological Intelligence","  This article reviews the ""Once learning"" mechanism that was proposed 23 years
ago and the subsequent successes of ""One-shot learning"" in image classification
and ""You Only Look Once - YOLO"" in objective detection. Analyzing the current
development of Artificial Intelligence (AI), the proposal is that AI should be
clearly divided into the following categories: Artificial Human Intelligence
(AHI), Artificial Machine Intelligence (AMI), and Artificial Biological
Intelligence (ABI), which will also be the main directions of theory and
application development for AI. As a watershed for the branches of AI, some
classification standards and methods are discussed: 1) Human-oriented,
machine-oriented, and biological-oriented AI R&D; 2) Information input
processed by Dimensionality-up or Dimensionality-reduction; 3) The use of
one/few or large samples for knowledge learning.
","['Li Weigang', 'Liriam Enamoto', 'Denise Leyi Li', 'Geraldo Pereira Rocha Filho']"
http://arxiv.org/abs/2102.12076v1,Artificial intelligence,2021-02-24T05:43:44Z,2021-02-24T05:43:44Z,"Perspective: Purposeful Failure in Artificial Life and Artificial
  Intelligence","  Complex systems fail. I argue that failures can be a blueprint characterizing
living organisms and biological intelligence, a control mechanism to increase
complexity in evolutionary simulations, and an alternative to classical fitness
optimization. Imitating biological successes in Artificial Life and Artificial
Intelligence can be misleading; imitating failures offers a path towards
understanding and emulating life it in artificial systems.
",['Lana Sinapayen']
http://arxiv.org/abs/2404.03499v1,Artificial intelligence,2024-04-04T14:57:32Z,2024-04-04T14:57:32Z,Comprehensible Artificial Intelligence on Knowledge Graphs: A survey,"  Artificial Intelligence applications gradually move outside the safe walls of
research labs and invade our daily lives. This is also true for Machine
Learning methods on Knowledge Graphs, which has led to a steady increase in
their application since the beginning of the 21st century. However, in many
applications, users require an explanation of the Artificial Intelligences
decision. This led to increased demand for Comprehensible Artificial
Intelligence. Knowledge Graphs epitomize fertile soil for Comprehensible
Artificial Intelligence, due to their ability to display connected data, i.e.
knowledge, in a human- as well as machine-readable way. This survey gives a
short history to Comprehensible Artificial Intelligence on Knowledge Graphs.
Furthermore, we contribute by arguing that the concept Explainable Artificial
Intelligence is overloaded and overlapping with Interpretable Machine Learning.
By introducing the parent concept Comprehensible Artificial Intelligence, we
provide a clear-cut distinction of both concepts while accounting for their
similarities. Thus, we provide in this survey a case for Comprehensible
Artificial Intelligence on Knowledge Graphs consisting of Interpretable Machine
Learning on Knowledge Graphs and Explainable Artificial Intelligence on
Knowledge Graphs. This leads to the introduction of a novel taxonomy for
Comprehensible Artificial Intelligence on Knowledge Graphs. In addition, a
comprehensive overview of the research on Comprehensible Artificial
Intelligence on Knowledge Graphs is presented and put into the context of the
taxonomy. Finally, research gaps in the field of Comprehensible Artificial
Intelligence on Knowledge Graphs are identified for future research.
","['Simon Schramm', 'Christoph Wehner', 'Ute Schmid']"
http://arxiv.org/abs/2007.07710v1,Artificial intelligence,2020-07-11T14:06:13Z,2020-07-11T14:06:13Z,Human $\neq$ AGI,"  Terms Artificial General Intelligence (AGI) and Human-Level Artificial
Intelligence (HLAI) have been used interchangeably to refer to the Holy Grail
of Artificial Intelligence (AI) research, creation of a machine capable of
achieving goals in a wide range of environments. However, widespread implicit
assumption of equivalence between capabilities of AGI and HLAI appears to be
unjustified, as humans are not general intelligences. In this paper, we will
prove this distinction.
",['Roman V. Yampolskiy']
http://arxiv.org/abs/2111.11295v1,Artificial intelligence,2021-11-08T00:10:49Z,2021-11-08T00:10:49Z,"Artificial Intelligence Technology analysis using Artificial
  Intelligence patent through Deep Learning model and vector space model","  Thanks to rapid development of artificial intelligence technology in recent
years, the current artificial intelligence technology is contributing to many
part of society. Education, environment, medical care, military, tourism,
economy, politics, etc. are having a very large impact on society as a whole.
For example, in the field of education, there is an artificial intelligence
tutoring system that automatically assigns tutors based on student's level. In
the field of economics, there are quantitative investment methods that
automatically analyze large amounts of data to find investment laws to create
investment models or predict changes in financial markets. As such, artificial
intelligence technology is being used in various fields. So, it is very
important to know exactly what factors have an important influence on each
field of artificial intelligence technology and how the relationship between
each field is connected. Therefore, it is necessary to analyze artificial
intelligence technology in each field. In this paper, we analyze patent
documents related to artificial intelligence technology. We propose a method
for keyword analysis within factors using artificial intelligence patent data
sets for artificial intelligence technology analysis. This is a model that
relies on feature engineering based on deep learning model named KeyBERT, and
using vector space model. A case study of collecting and analyzing artificial
intelligence patent data was conducted to show how the proposed model can be
applied to real world problems.
","['Yongmin Yoo', 'Dongjin Lim', 'Kyungsun Kim']"
http://arxiv.org/abs/1712.06440v1,Artificial intelligence,2017-12-14T17:49:04Z,2017-12-14T17:49:04Z,Three IQs of AI Systems and their Testing Methods,"  The rapid development of artificial intelligence has brought the artificial
intelligence threat theory as well as the problem about how to evaluate the
intelligence level of intelligent products. Both need to find a quantitative
method to evaluate the intelligence level of intelligence systems, including
human intelligence. Based on the standard intelligence system and the extended
Von Neumann architecture, this paper proposes General IQ, Service IQ and Value
IQ evaluation methods for intelligence systems, depending on different
evaluation purposes. Among them, the General IQ of intelligence systems is to
answer the question of whether the artificial intelligence can surpass the
human intelligence, which is reflected in putting the intelligence systems on
an equal status and conducting the unified evaluation. The Service IQ and Value
IQ of intelligence systems are used to answer the question of how the
intelligent products can better serve the human, reflecting the intelligence
and required cost of each intelligence system as a product in the process of
serving human.
","['Feng Liu', 'Yong Shi', 'Ying Liu']"
http://arxiv.org/abs/2108.04770v1,Artificial intelligence,2021-08-10T16:24:30Z,2021-08-10T16:24:30Z,"Examining correlation between trust and transparency with explainable
  artificial intelligence","  Trust between humans and artificial intelligence(AI) is an issue which has
implications in many fields of human computer interaction. The current issue
with artificial intelligence is a lack of transparency into its decision
making, and literature shows that increasing transparency increases trust.
Explainable artificial intelligence has the ability to increase transparency of
AI, which could potentially increase trust for humans. This paper attempts to
use the task of predicting yelp review star ratings with assistance from an
explainable and non explainable artificial intelligence to see if trust is
increased with increased transparency. Results show that for these tasks,
explainable artificial intelligence provided significant increase in trust as a
measure of influence.
",['Arnav Kartikeya']
http://arxiv.org/abs/2110.01831v1,Artificial intelligence,2021-10-05T05:58:23Z,2021-10-05T05:58:23Z,"The Artificial Scientist: Logicist, Emergentist, and Universalist
  Approaches to Artificial General Intelligence","  We attempt to define what is necessary to construct an Artificial Scientist,
explore and evaluate several approaches to artificial general intelligence
(AGI) which may facilitate this, conclude that a unified or hybrid approach is
necessary and explore two theories that satisfy this requirement to some
degree.
","['Michael Timothy Bennett', 'Yoshihiro Maruyama']"
http://arxiv.org/abs/1205.2596v2,Artificial intelligence,2012-05-11T18:35:50Z,2014-08-28T04:30:01Z,"Proceedings of the Twenty-Seventh Conference on Uncertainty in
  Artificial Intelligence (2011)","  This is the Proceedings of the Twenty-Seventh Conference on Uncertainty in
Artificial Intelligence, which was held in Barcelona, Spain, July 14 - 17 2011.
","['Fabio Cozman', 'Avi Pfeffer']"
http://arxiv.org/abs/1205.2597v2,Artificial intelligence,2012-05-11T18:40:29Z,2014-08-28T04:29:00Z,"Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial
  Intelligence (2010)","  This is the Proceedings of the Twenty-Sixth Conference on Uncertainty in
Artificial Intelligence, which was held on Catalina Island, CA, July 8 - 11
2010.
","['Peter Grunwald', 'Peter Spirtes']"
http://arxiv.org/abs/1206.3959v2,Artificial intelligence,2012-06-13T16:43:44Z,2014-08-28T04:27:28Z,"Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial
  Intelligence (2009)","  This is the Proceedings of the Twenty-Fifth Conference on Uncertainty in
Artificial Intelligence, which was held in Montreal, QC, Canada, June 18 - 21
2009.
","['Jeff Bilmes', 'Andrew Ng']"
http://arxiv.org/abs/2407.09982v1,Cultured meat,2024-04-30T13:35:18Z,2024-04-30T13:35:18Z,"Artificial intelligence and machine learning applications for cultured
  meat","  Cultured meat has the potential to provide a complementary meat industry with
reduced environmental, ethical, and health impacts. However, major
technological challenges remain which require time- and resource-intensive
research and development efforts. Machine learning has the potential to
accelerate cultured meat technology by streamlining experiments, predicting
optimal results, and reducing experimentation time and resources. However, the
use of machine learning in cultured meat is in its infancy. This review covers
the work available to date on the use of machine learning in cultured meat and
explores future possibilities. We address four major areas of cultured meat
research and development: establishing cell lines, cell culture media design,
microscopy and image analysis, and bioprocessing and food processing
optimization. This review aims to provide the foundation necessary for both
cultured meat and machine learning scientists to identify research
opportunities at the intersection between cultured meat and machine learning.
","['Michael E. Todhunter', 'Sheikh Jubair', 'Ruchika Verma', 'Rikard Saqe', 'Kevin Shen', 'Breanna Duffy']"
http://arxiv.org/abs/2401.02691v1,Cultured meat,2024-01-05T07:46:07Z,2024-01-05T07:46:07Z,"Scaffolding fundamentals and recent advances in sustainable scaffolding
  techniques for cultured meat development","  In cultured meat (CM) products the paramount significance lies in the
fundamental attributes like texture and sensory of the processed end product.
To cater to the tactile and gustatory preferences of real meat, the product
needs to be designed to incorporate its texture and sensory attributes.
Presently CM products are mainly grounded products like sausage, nugget,
frankfurter, burger patty, surimi, and steak with less sophistication and need
to mimic real meat to grapple with the traditional meat market. The existence
of fibrous microstructure in connective and muscle tissues has attracted
considerable interest in the realm of tissue engineering. Scaffolding plays an
important role in CM production by aiding cell adhesion, growth,
differentiation, and alignment. A wide array of scaffolding technologies has
been developed for implementation in the realm of biomedical research. In
recent years researchers also focus on edible scaffolding to ease the process
of CM. However, it is imperative to implement cutting edge technologies like 3D
scaffolds, 3D printing, electrospun nanofibers in order to advance the creation
of sustainable and edible scaffolding methods in CM production, with the
ultimate goal of replicating the sensory and nutritional attributes to mimic
real meat cut. This review discusses recent advances in scaffolding techniques
and biomaterials related to structured CM production and required advances to
create muscle fiber structures to mimic real meat.
  Keywords: Cultured meat, Scaffolding, Biomaterials, Edible scaffolding,
Electrospinning, 3D bioprinting, real meat.
","['AMM Nurul Alam', 'Chan-Jin Kim', 'So-Hee Kim', 'Swati Kumari', 'Eun-Yeong Lee', 'Young-Hwa Hwang', 'Seon-Tea Joo']"
http://arxiv.org/abs/1806.09912v1,Cultured meat,2018-06-26T11:16:15Z,2018-06-26T11:16:15Z,"Boiling, steaming or rinsing? (physics of the Chinese cuisine)","  Some physical aspects of Chinese cuisine are discussed. We start from the
cultural and historical particularities of the Chinese cuisine and technologies
of food production. What is the difference between raw and boiled meat? What is
the difference in the physical processes of heat transfer during steaming of
dumplings and their cooking in boiling water? Why is it possible to cook meat
stripes in a ""hot pot"" in ten seconds, while baking a turkey requires several
hours? This article is devoted to discussion of these questions.
","['Andrey Varlamov', 'Zheng Zhou', 'Yan Chen']"
http://arxiv.org/abs/1306.5104v1,Cultured meat,2013-06-21T11:30:13Z,2013-06-21T11:30:13Z,Preference for meat is not innate in dogs,"  Indian free ranging dogs live in a carbohydrate rich environment as
scavengers in and around human settlements. They rarely hunt and consequently
do not encounter rich sources of protein. Instead they have adapted to a diet
of primarily carbohydrates. As descendants of the exclusively carnivorous
wolves, they are subjected to the evolutionary load of a physiological demand
for proteins. To meet their protein needs they resort to a thumb rule, if it
smells like meat, eat it. Pups face high competition from group and non group
members and are in a phase of rapid growth with high protein demands. Following
the thumb rule, then they can acquire more protein at the cost of increased
competition and reduced supplementary non protein nutrition. However, if the
mother supplements their diet with protein rich regurgitates and milk, then the
pups can benefit by being generalists. Using a choice test in the field we show
that while adults have a clear preference for meat, pups have no such
preference, and they even eat degraded protein eagerly. Thus the thumb rule
used by adult dogs for efficient scavenging is not innate, and needs to be
learned. The thumb rule might be acquired by cultural transmission, through
exposure to meat in the regurgitate of the mother, or while accompanying her on
foraging trips.
","['Anandarup Bhadra', 'Anindita Bhadra']"
http://arxiv.org/abs/2308.02700v2,Cultured meat,2023-08-04T20:35:59Z,2023-08-23T20:01:55Z,"Simultaneous self-organization of arterial and venous networks driven by
  the physics of global power optimization","  Understanding of vascular organization is a long-standing problem in
quantitative biology and biophysics and is essential for the growth of large
cultured tissues. Approaches are needed that (1) make predictions of optimal
arteriovenous networks in order to understand the natural vasculatures that
originate from evolution (2) can design vasculature for 3D printing of cultured
tissues, meats, organoids and organs. I present a method for determining the
globally optimal structure of interlocking arterial and venous (arteriovenous)
networks. The core physics is comprised of the minimization of total power
associated with the whole vascular network, with penalties to stop arterial and
venous segments from intersecting. Specifically, the power needed for
Poiseuille flow through vessels and the metabolic power cost for blood
maintenance are optimized. Simultaneous determination of both arterial and
venous vasculatures is essential to avoid intersections between vessels that
would bypass the capillary network. As proof-of-concept, I examine the optimal
vascular structure for supplying square- and disk-like tissue shapes that would
be suitable for bioprinting in multi-well plates. Features in the trees are
driven by the bifurcation exponent and metabolic constant which affect whether
arteries and veins follow the same or different routes through the tissue. They
also affect the level of tortuosity in the vessels. The method could be used to
understand the distribution of blood vessels within organs, to form the core of
simulations, and combined with 3D printing to generate vasculatures for
arbitrary volumes of cultured tissue and cultured meat.
",['James P. Hague']
http://arxiv.org/abs/2306.13435v1,Cultured meat,2023-06-23T10:58:40Z,2023-06-23T10:58:40Z,"High-throughput design of cultured tissue moulds using a biophysical
  model","  The technique presented here identifies tethered mould designs, optimised for
growing cultured tissue with very highly-aligned cells. It is based on a
microscopic biophysical model for polarised cellular hydrogels. There is an
unmet need for tools to assist mould and scaffold designs for the growth of
cultured tissues with bespoke cell organisations, that can be used in
applications such as regenerative medicine, drug screening and cultured meat.
High-throughput biophysical calculations were made for a wide variety of
computer-generated moulds, with cell-matrix interactions and tissue-scale
forces simulated using a contractile-network dipole-orientation model.
Elongated moulds with central broadening and one of the following tethering
strategies are found to lead to highly-aligned cells: (1) tethers placed within
the bilateral protrusions resulting from an indentation on the short edge, to
guide alignment (2) tethers placed within a single vertex to shrink the
available space for misalignment. As such, proof-of-concept has been shown for
mould and tethered scaffold design based on a recently developed biophysical
model. The approach is applicable to a broad range of cell types that align in
tissues and is extensible for 3D scaffolds.
","['James P. Hague', 'Allison E. Andrews', 'Hugh Dickinson']"
http://arxiv.org/abs/2410.13685v1,Cultured meat,2024-10-17T15:47:12Z,2024-10-17T15:47:12Z,"Label-free prediction of fluorescence markers in bovine satellite cells
  using deep learning","  Assessing the quality of bovine satellite cells (BSCs) is essential for the
cultivated meat industry, which aims to address global food sustainability
challenges. This study aims to develop a label-free method for predicting
fluorescence markers in isolated BSCs using deep learning. We employed a
U-Net-based CNN model to predict multiple fluorescence signals from a single
bright-field microscopy image of cell culture. Two key biomarkers, DAPI and
Pax7, were used to determine the abundance and quality of BSCs. The image
pre-processing pipeline included fluorescence denoising to improve prediction
performance and consistency. A total of 48 biological replicates were used,
with statistical performance metrics such as Pearson correlation coefficient
and SSIM employed for model evaluation. The model exhibited better performance
with DAPI predictions due to uniform staining. Pax7 predictions were more
variable, reflecting biological heterogeneity. Enhanced visualization
techniques, including color mapping and image overlay, improved the
interpretability of the predictions by providing better contextual and
perceptual information. The findings highlight the importance of data
pre-processing and demonstrate the potential of deep learning to advance
non-invasive, label-free assessment techniques in the cultivated meat industry,
paving the way for reliable and actionable AI-driven evaluations.
","['Sania Sinha', 'Aarham Wasit', 'Won Seob Kim', 'Jongkyoo Kim', 'Jiyoon Yi']"
http://arxiv.org/abs/2202.13672v2,Cultured meat,2022-02-28T10:42:45Z,2022-06-08T06:23:38Z,Molecular and colloidal transport in bacterial cellulose hydrogels,"  Bacterial cellulose biofilms are complex networks of strong interwoven
nanofibers that control transport and protect bacterial colonies in the film.
Design of diverse applications of bacterial cellulose films also relies on
understanding and controlling transport through the fiber mesh, and transport
simulations of the films are most accurate when guided by experimental
characterization of the structures and the resultant diffusion inside.
Diffusion through such films is a function of their key microstructural length
scales, determining how molecules, as well as particles and microorganisms,
permeate them. We use microscopy to study the unique bacterial cellulose film
structure and quantify the mobility dynamics of various sizes of tracer
particles and macromolecules. Mobility is hindered within the films, as
confinement and local movement strongly depend on void size relative to
diffusing tracers. The biofilms have a naturally periodic structure of
alternating dense and porous layers of nanofiber mesh, and we tune the
magnitude of the spacing via fermentation conditions. Micron-sized particles
can diffuse through the porous layers, but can not penetrate the dense layers.
Tracer mobility in the porous layers is isotropic, indicating a largely random
pore structure there. Molecular diffusion through the whole film is only
slightly reduced by the structural tortuosity. Knowledge of transport
variations within bacterial cellulose networks can be used to guide design of
symbiotic cultures in these structures and enhance their use in applications
biomedical implants, wound dressings, lab-grown meat, and sensors.
","['Firoozeh Babayekhorasani', 'Maryam Hosseini', 'Patrick T. Spicer']"
http://arxiv.org/abs/2401.07875v1,Cultured meat,2024-01-15T18:08:54Z,2024-01-15T18:08:54Z,Safely and Autonomously Cutting Meat with a Collaborative Robot Arm,"  Labor shortages in the United States are impacting a number of industries
including the meat processing sector. Collaborative technologies that work
alongside humans while increasing production abilities may support the industry
by enhancing automation and improving job quality. However, existing automation
technologies used in the meat industry have limited collaboration potential,
low flexibility, and high cost. The objective of this work was to explore the
use of a robot arm to collaboratively work alongside a human and complete tasks
performed in a meat processing facility. Toward this objective, we demonstrated
proof-of-concept approaches to ensure human safety while exploring the capacity
of the robot arm to perform example meat processing tasks. In support of human
safety, we developed a knife instrumentation system to detect when the cutting
implement comes into contact with meat within the collaborative space. To
demonstrate the capability of the system to flexibly conduct a variety of basic
meat processing tasks, we developed vision and control protocols to execute
slicing, trimming, and cubing of pork loins. We also collected a subjective
evaluation of the actions from experts within the U.S. meat processing
industry. On average the experts rated the robot's performance as adequate.
Moreover, the experts generally preferred the cuts performed in collaboration
with a human worker to cuts completed autonomously, highlighting the benefits
of robotic technologies that assist human workers rather than replace them.
Video demonstrations of our proposed framework can be found here:
https://youtu.be/56mdHjjYMVc
","['Ryan Wright', 'Sagar Parekh', 'Robin White', 'Dylan P. Losey']"
http://arxiv.org/abs/2402.13439v1,Cultured meat,2024-02-21T00:16:08Z,2024-02-21T00:16:08Z,"Estimating Demand for Lamb, Beef, Pork, and Poultry in Canada","  This paper investigates the demand for lamb, beef, pork, and poultry in
Canada, both at the national level and in disaggregated provinces, to identify
meat consumption patterns in different provinces. Meat consumption plays a
significant role in Canada's economy and is an important source of calories for
the population. However, meat demand faces several consumption challenges due
to logistic constraints, as a significant portion of the supply is imported
from other countries. Therefore, there is a need for a better understanding of
the causal relationships underlying lamb, beef, pork, and poultry consumption
in Canada. Until recently, there have been no attempts to estimate meat
consumption at the provincial level in Canada. Different Almost Ideal Demand
System (AIDS) models have been applied for testing specifications to circumvent
several econometric and theoretical problems. In particular, generalized AIDS
and its Quadratic extension QUAIDS methods have been estimated across each
province using the Iterative Linear Least Squares Estimator (ILLE) estimation
Method. Weekly retail meat consumption price and quantity data from 2019 to
2022 have been used for Canada and for each province namely Quebec, Maritime
provinces (New Brunswick, Nova Scotia, and Prince Edward Island), Ontario,
total West (Yukon, Northwest Territory and Nunavut), Alberta,
Manitoba-Saskatchewan and Manitoba as well as British Columbia. Consistent
coefficients and demand elasticities estimates reveal patterns of substitution
and/or complementarity between the four categories of meat. Meat consumption
patterns differ across each province. Results show that the demand for the four
categories of meat is responsive to price changes. Overall, lamb expenditure
was found to be elastic and thus considered a luxury good during the study
period, while the other three categories are considered normal goods across
Canada.
",['Zakary Rodrigue Diakité']
http://arxiv.org/abs/2504.04872v1,Cultured meat,2025-04-07T09:27:37Z,2025-04-07T09:27:37Z,Simulating Persuasive Dialogues on Meat Reduction with Generative Agents,"  Meat reduction benefits human and planetary health, but social norms keep
meat central in shared meals. To date, the development of communication
strategies that promote meat reduction while minimizing social costs has
required the costly involvement of human participants at each stage of the
process. We present work in progress on simulating multi-round dialogues on
meat reduction between Generative Agents based on large language models (LLMs).
We measure our main outcome using established psychological questionnaires
based on the Theory of Planned Behavior and additionally investigate Social
Costs. We find evidence that our preliminary simulations produce outcomes that
are (i) consistent with theoretical expectations; and (ii) valid when compared
to data from previous studies with human participants. Generative agent-based
models are a promising tool for identifying novel communication strategies on
meat reduction-tailored to highly specific participant groups-to then be tested
in subsequent studies with human participants.
","['Georg Ahnert', 'Elena Wurth', 'Markus Strohmaier', 'Jutta Mata']"
http://arxiv.org/abs/2503.08664v1,Cultured meat,2025-03-11T17:50:59Z,2025-03-11T17:50:59Z,"MEAT: Multiview Diffusion Model for Human Generation on Megapixels with
  Mesh Attention","  Multiview diffusion models have shown considerable success in image-to-3D
generation for general objects. However, when applied to human data, existing
methods have yet to deliver promising results, largely due to the challenges of
scaling multiview attention to higher resolutions. In this paper, we explore
human multiview diffusion models at the megapixel level and introduce a
solution called mesh attention to enable training at 1024x1024 resolution.
Using a clothed human mesh as a central coarse geometric representation, the
proposed mesh attention leverages rasterization and projection to establish
direct cross-view coordinate correspondences. This approach significantly
reduces the complexity of multiview attention while maintaining cross-view
consistency. Building on this foundation, we devise a mesh attention block and
combine it with keypoint conditioning to create our human-specific multiview
diffusion model, MEAT. In addition, we present valuable insights into applying
multiview human motion videos for diffusion training, addressing the
longstanding issue of data scarcity. Extensive experiments show that MEAT
effectively generates dense, consistent multiview human images at the megapixel
level, outperforming existing multiview diffusion methods.
","['Yuhan Wang', 'Fangzhou Hong', 'Shuai Yang', 'Liming Jiang', 'Wayne Wu', 'Chen Change Loy']"
http://arxiv.org/abs/2208.13484v1,Cultured meat,2022-08-29T10:37:31Z,2022-08-29T10:37:31Z,"Pasture Intake Protects Against Commercial Diet-induced
  Lipopolysaccharide Production Facilitated by Gut Microbiota through
  Activating Intestinal Alkaline Phosphatase Enzyme in Meat Geese","  In-house feeding system (IHF, a low dietary fiber source) may cause altered
cecal microbiota composition and inflammatory responses in meat geese via
increased endotoxemia (lipopolysaccharides) with reduced intestinal alkaline
phosphatase (ALP) production. The effects of artificial pasture grazing system
(AGF, a high dietary fiber source) on modulating gut microbiota architecture
and gut barrier functions have not been investigated in meat geese. The
intestinal ALP functions to regulate gut microbial homeostasis and barrier
function appears to inhibit pro-inflammatory cytokines by reducing LPS-induced
reactive oxygen species (ROS) production. The purpose of our study was to
investigate whether this enzyme could play a critical role in attenuating ROS
generation and then ROS facilitated NF-\k{appa}B pathway-induced systemic
inflammation in meat geese. First, we assessed the impacts of IHF and AGF on
gut microbial composition via 16 sRNA sequencing in meat geese. In the gut
microbiota analysis, meat geese supplemented with pasture demonstrated a
significant reduction in microbial richness and diversity compared to IHF meat
geese demonstrating antimicrobial, antioxidation, and anti-inflammatory ability
of AGF system. Second host markers analysis through protein expression of serum
and cecal tissues and quantitative PCR of cecal tissues were evaluated. We
confirmed a significant increase in intestinal ALP-induced Nrf2 signaling
pathway representing LPS dephosphorylation mediated TLR4/MyD88 induced ROS
reduction mechanisms in AGF meat geese. Further, the correlation analysis of
top 44 host markers with gut microbiota shows that artificial pasture intake
induced gut barrier functions via reducing ROS-mediated NF-\k{appa}B
pathway-induced gut permeability, systemic inflammation, and aging phenotypes.
","['Qasim Ali', 'Sen Ma', 'Umar Farooq', 'Jiakuan Niu', 'Fen Li', 'Muhammad Abaidullah', 'Boshuai Liu', 'Shaokai La', 'Defeng Li', 'Zhichang Wang', 'Hao Sun', 'Yalei Cui', 'Yinghua Shi']"
http://arxiv.org/abs/2005.12671v1,Cultured meat,2020-04-12T15:43:14Z,2020-04-12T15:43:14Z,"Towards real time assessment of intramuscular fat content in meat using
  optical fibre-based optical coherence tomography","  We consider the use of optical coherence tomography (OCT) imaging to predict
the quality of meat. We find that intramuscular fat (IMF) absorbs infrared
light about nine times stronger than muscle, which enables us to estimate fat
content in intact meat samples. The method is made very efficient by extracting
relevant information from the three-dimensional high-resolution images
generated by OCT using principal component analysis (PCA). The principal
components are then used as regressors into a support vector regression (SVR)
prediction model. The SVR model is found to predict IMF content stably and
accurately, with an R^2 value of 0.94. Our study paves the way for automated,
contact-less, non-destructive, real time classification of the quality of meat
samples.
","['Abi Thampi', 'Sam Hitchman', 'Stéphane Coen', 'Frédérique Vanholsbeeck']"
http://arxiv.org/abs/2210.05358v2,Cultured meat,2022-10-06T15:03:23Z,2022-10-18T10:05:09Z,On estimating Armington elasticities for Japan's meat imports,"  By fully accounting for the distinct tariff regimes levied on imported meat,
we estimate substitution elasticities of Japan's two-stage import aggregation
functions for beef, chicken and pork. While the regression analysis crucially
depends on the price that consumers face, the post-tariff price of imported
meat depends not only on ad valorem duties but also on tariff rate quotas and
gate price system regimes. The effective tariff rate is consequently evaluated
by utilizing monthly transaction data. To address potential endogeneity
problems, we apply exchange rates that we believe to be independent of the
demand shocks for imported meat. The panel nature of the data allows us to
retrieve the first-stage aggregates via time dummy variables, free of demand
shocks, to be used as part of the explanatory variable and as an instrument in
the second-stage regression.
","['Satoshi Nakano', 'Kazuhiko Nishimura']"
http://arxiv.org/abs/2406.14259v1,Cultured meat,2024-06-20T12:28:47Z,2024-06-20T12:28:47Z,"MEAT: Median-Ensemble Adversarial Training for Improving Robustness and
  Generalization","  Self-ensemble adversarial training methods improve model robustness by
ensembling models at different training epochs, such as model weight averaging
(WA). However, previous research has shown that self-ensemble defense methods
in adversarial training (AT) still suffer from robust overfitting, which
severely affects the generalization performance. Empirically, in the late
phases of training, the AT becomes more overfitting to the extent that the
individuals for weight averaging also suffer from overfitting and produce
anomalous weight values, which causes the self-ensemble model to continue to
undergo robust overfitting due to the failure in removing the weight anomalies.
To solve this problem, we aim to tackle the influence of outliers in the weight
space in this work and propose an easy-to-operate and effective Median-Ensemble
Adversarial Training (MEAT) method to solve the robust overfitting phenomenon
existing in self-ensemble defense from the source by searching for the median
of the historical model weights. Experimental results show that MEAT achieves
the best robustness against the powerful AutoAttack and can effectively
allievate the robust overfitting. We further demonstrate that most defense
methods can improve robust generalization and robustness by combining with
MEAT.
","['Zhaozhe Hu', 'Jia-Li Yin', 'Bin Chen', 'Luojun Lin', 'Bo-Hao Chen', 'Ximeng Liu']"
http://arxiv.org/abs/2504.00066v1,Cultured meat,2025-03-31T16:16:58Z,2025-03-31T16:16:58Z,"Meat, Vegetable, Soup -- The First Successful Attempt to Classify
  Everything","  We present the results of a novel classification scheme for all items,
objects, concepts, and crucially -- things -- in the known and unknown
universe. Our definitions of meat, soup and vegetable are near-exhaustive and
represent a new era of scientific discovery within the rapidly-developing field
of Arbitrary Classification. While the definitions of vegetable (growing in the
ground), meat (growing in an animal) and soup (containing both vegetable and
meat) may appear simple at first, we discuss a range of complex cases in which
progress is rapidly being made, and provide definitions and clarifications for
as many objects as a weekend of typing will allow.
","['G. Weaver', 'M. J. Selfridge', 'J. M. Setchfield', 'F. Dresbach', 'V. Varma', 'J. Martinez Garcia', 'A. Moharana', 'J. Keegans', 'L. J. Adams']"
http://arxiv.org/abs/2203.11684v1,Cultured meat,2022-03-22T12:58:39Z,2022-03-22T12:58:39Z,Meta-attention for ViT-backed Continual Learning,"  Continual learning is a longstanding research topic due to its crucial role
in tackling continually arriving tasks. Up to now, the study of continual
learning in computer vision is mainly restricted to convolutional neural
networks (CNNs). However, recently there is a tendency that the newly emerging
vision transformers (ViTs) are gradually dominating the field of computer
vision, which leaves CNN-based continual learning lagging behind as they can
suffer from severe performance degradation if straightforwardly applied to
ViTs. In this paper, we study ViT-backed continual learning to strive for
higher performance riding on recent advances of ViTs. Inspired by mask-based
continual learning methods in CNNs, where a mask is learned per task to adapt
the pre-trained ViT to the new task, we propose MEta-ATtention (MEAT), i.e.,
attention to self-attention, to adapt a pre-trained ViT to new tasks without
sacrificing performance on already learned tasks. Unlike prior mask-based
methods like Piggyback, where all parameters are associated with corresponding
masks, MEAT leverages the characteristics of ViTs and only masks a portion of
its parameters. It renders MEAT more efficient and effective with less overhead
and higher accuracy. Extensive experiments demonstrate that MEAT exhibits
significant superiority to its state-of-the-art CNN counterparts, with 4.0~6.0%
absolute boosts in accuracy. Our code has been released at
https://github.com/zju-vipa/MEAT-TIL.
","['Mengqi Xue', 'Haofei Zhang', 'Jie Song', 'Mingli Song']"
http://arxiv.org/abs/2412.11167v2,Cultured meat,2024-12-15T12:30:52Z,2025-02-16T12:21:29Z,Cultural Palette: Pluralising Culture Alignment via Multi-agent Palette,"  Large language models (LLMs) face challenges in aligning with diverse
cultural values despite their remarkable performance in generation, which stems
from inherent monocultural biases and difficulties in capturing nuanced
cultural semantics. Existing methods struggle to adapt to unkown culture after
fine-tuning. Inspired by cultural geography across five continents, we propose
Cultural Palette, a multi-agent framework that redefines cultural alignment as
an adaptive ""color-blending"" process for country-specific adaptation. Our
approach harnesses cultural geography across five continents (Africa, America,
Asia, Europe, Oceania) through three key steps: First, we synthesize the
Pentachromatic Cultural Palette Dataset using GPT-4o, refining
continental-level dialogues with Hofstede cultural dimensions to establish
foundational cultural representations. Second, five continent-level alignment
agents form specialized cultural communities that generate region-specific
draft responses. Third, a Meta Agent employs Cultural MoErges to dynamically
blend these cultural ""colors"" through attention-gated parameter merging, akin
to mixing pigments on a palette, resolving conflicts while preserving cultural
nuances to produce the final culturally-aligned response. Extensive experiments
across various countries demonstrate that Cultural Palette surpasses existing
baselines in cultural alignment.
","['Jiahao Yuan', 'Zixiang Di', 'Shangzixin Zhao', 'Usman Naseem']"
http://arxiv.org/abs/1304.3546v1,Cultured meat,2013-04-12T06:30:33Z,2013-04-12T06:30:33Z,The Meat of the Matter: A thumb rule for scavenging dogs?,"  Animals that scavenge in and around human localities need to utilize a broad
range of resources. Preference for any one kind of food, under such
circumstances, might be inefficient. Indian free-ranging dogs, Canis lupus
familiaris are scavengers that are heavily dependent on humans for sustaining
their omnivorous diet. The current study suggests that because of evolutionary
load, these dogs, which are descendants of the decidedly carnivorous gray wolf,
still retain a preference for meat though they live on carbohydrate-rich
resources. The plasticity in their diet probably fosters efficient scavenging
in a competitive environment, while a thumb rule for preferentially acquiring
specific nutrients enables them to sequester proteins from the
carbohydrate-rich environment.
","['Anandarup Bhadra', 'Debottam Bhattacharjee', 'Manabi Paul', 'Anindita Bhadra']"
http://arxiv.org/abs/2006.16925v3,Neurotechnology,2020-06-23T07:46:22Z,2024-09-18T23:37:41Z,"Ethical Analysis on the Application of Neurotechnology for Human
  Augmentation in Physicians and Surgeons","  With the shortage of physicians and surgeons and increase in demand worldwide
due to situations such as the COVID-19 pandemic, there is a growing interest in
finding solutions to help address the problem. A solution to this problem would
be to use neurotechnology to provide them augmented cognition, senses and
action for optimal diagnosis and treatment. Consequently, doing so can
negatively impact them and others. We argue that applying neurotechnology for
human enhancement in physicians and surgeons can cause injustices, and harm to
them and patients. In this paper, we will first describe the augmentations and
neurotechnologies that can be used to achieve the relevant augmentations for
physicians and surgeons. We will then review selected ethical concerns
discussed within literature, discuss the neuroengineering behind using
neurotechnology for augmentation purposes, then conclude with an analysis on
outcomes and ethical issues of implementing human augmentation via
neurotechnology in medical and surgical practice.
","['Soaad Hossain', 'Syed Ishtiaque Ahmed']"
http://arxiv.org/abs/1607.05023v1,Neurotechnology,2016-07-18T11:28:11Z,2016-07-18T11:28:11Z,"Intelligent Biohybrid Neurotechnologies: Are They Really What They
  Claim?","  In the era of intelligent biohybrid neurotechnologies for brain repair, new
fanciful terms are appearing in the scientific dictionary to define what has so
far been unimaginable. As the emerging neurotechnologies are becoming
increasingly polyhedral and sophisticated, should we talk about evolution and
rank the intelligence of these devices?
","['Gabriella Panuccio', 'Marianna Semprini', 'Lorenzo Natale', 'Michela Chiappalone']"
http://arxiv.org/abs/2404.00047v2,Neurotechnology,2024-03-25T09:43:20Z,2024-09-11T17:02:08Z,"Foundational guidelines for enhancing neurotechnology research and
  development through end-user involvement","  Neurotechnologies are increasingly becoming integrated with our everyday
lives, our bodies and our mental states. As the popularity and impact of
neurotechnology grows, so does our responsibility to ensure we understand its
particular implications on its end users, as well as broader ethical and
societal implications. Enabling end-users and stakeholders to participate in
the development of neurotechnology, from its earliest stages of conception,
will help us better navigate our design around these considerations and deliver
more impactful technologies. There are many terms and frameworks to articulate
the concept of involving end users in the technology development lifecycle, for
example: 'Public and Patient Involvement and Engagement' (PPIE), 'lived
experience' and 'co-design'. Here we utilise the PPIE framework to develop
clear guidelines for implementing a robust involvement process of current and
future end-users in neurotechnology. We present best practice guidance for
researchers and engineers who are interested in developing and conducting a PPI
strategy for their neurotechnology. We provide advice from various online
sources to orient individual teams (and funders) to carve up their own approach
to meaningful involvement. After an introduction that coveys the tangible and
conceptual benefits of user involvement, we guide the reader to develop a
general strategy towards setting up their own process. We then help the reader
map out their relevant stakeholders and provide advice on how to consider user
diversity and representation. We also provide advice on how to quantify the
outcomes of the engagement, as well as a check-list to ensure transparency and
accountability at various stages. The aim is the establishment of gold-standard
methodologies for ensuring that patient and public insights are at the
forefront of our scientific inquiry and product development.
","['Amparo Güemes', 'Tiago da Silva Costa', 'Tamar Makin']"
http://arxiv.org/abs/1903.00981v1,Neurotechnology,2019-03-03T20:20:32Z,2019-03-03T20:20:32Z,"A Separation Principle for Discrete-Time Fractional-Order Dynamical
  Systems and its Implications to Closed-loop Neurotechnology","  Closed-loop neurotechnology requires the capability to predict the state
evolution and its regulation under (possibly) partial measurements. There is
evidence that neurophysiological dynamics can be modeled by fractional-order
dynamical systems. Therefore, we propose to establish a separation principle
for discrete-time fractional-order dynamical systems, which are inherently
nonlinear and are able to capture spatiotemporal relations that exhibit
non-Markovian properties. The separation principle states that the problems of
controller and state estimator design can be done independently of each other
while ensuring proper estimation and control in closed-loop setups. Lastly, we
illustrate, as proof-of-concept, the application of the separation principle
when designing controllers and estimators for these classes of systems in the
context of neurophysiological data. In particular, we rely on real data to
derive the models used to assess and regulate the evolution of closed-loop
neurotechnologies based on electroencephalographic data.
","['Sarthak Chatterjee', 'Orlando Romero', 'Sérgio Pequito']"
http://arxiv.org/abs/2110.11475v1,Neurotechnology,2021-10-21T20:54:24Z,2021-10-21T20:54:24Z,Future of Smart Classroom in the Era of Wearable Neurotechnology,"  Interdisciplinary research among engineering, computer science, and
neuroscience to understand and utilize the human brain signals resulted in
advances and widespread applicability of wearable neurotechnology in adaptive
human-in-the-loop smart systems. Considering these advances, we envision that
future education will exploit the advances in wearable neurotechnology and move
toward more personalized smart classrooms where instructions and interactions
are tailored towards. students' individual strengths and needs. In this paper,
we discuss the future of smart classrooms and how advances in neuroscience,
machine learning, and embedded systems as key enablers will provide the
infrastructure for envisioned smart classrooms and personalized education along
with open challenges that are required to be addressed.
","['Mojtaba Taherisadr', 'Berken Utku Demirel', 'Mohammad Abdullah Al Faruque', 'Salma Elmalaki']"
http://arxiv.org/abs/2403.07945v4,Neurotechnology,2024-03-11T03:44:18Z,2025-01-26T20:27:15Z,"A Mathematical Framework for the Problem of Security for Cognition in
  Neurotechnology","  The rapid advancement in neurotechnology in recent years has created an
emerging critical intersection between neurotechnology and security.
Implantable devices, non-invasive monitoring, and non-invasive therapies all
carry with them the prospect of violating the privacy and autonomy of
individuals' cognition. A growing number of scientists and physicians have made
calls to address this issue, but applied efforts have been relatively limited.
A major barrier hampering scientific and engineering efforts to address these
security issues is the lack of a clear means of describing and analyzing
relevant problems. In this paper we develop Cognitive Neurosecurity, a
mathematical framework which enables such description and analysis by drawing
on methods and results from multiple fields. We demonstrate certain statistical
properties which have significant implications for Cognitive Neurosecurity, and
then present descriptions of the algorithmic problems faced by attackers
attempting to violate privacy and autonomy, and defenders attempting to
obstruct such attempts.
","['Bryce Allen Bagley', 'Claudia K Petritsch']"
http://arxiv.org/abs/2207.13190v1,Neurotechnology,2022-07-26T21:38:01Z,2022-07-26T21:38:01Z,How does artificial intelligence contribute to iEEG research?,"  Artificial intelligence (AI) is a fast-growing field focused on modeling and
machine implementation of various cognitive functions with an increasing number
of applications in computer vision, text processing, robotics, neurotechnology,
bio-inspired computing and others. In this chapter, we describe how AI methods
can be applied in the context of intracranial electroencephalography (iEEG)
research. IEEG data is unique as it provides extremely high-quality signals
recorded directly from brain tissue. Applying advanced AI models to these data
carries the potential to further our understanding of many fundamental
questions in neuroscience. At the same time, as an invasive technique, iEEG
lends itself well to long-term, mobile brain-computer interface applications,
particularly for communication in severely paralyzed individuals. We provide a
detailed overview of these two research directions in the application of AI
techniques to iEEG. That is, (1) the development of computational models that
target fundamental questions about the neurobiological nature of cognition
(AI-iEEG for neuroscience) and (2) applied research on monitoring and
identification of event-driven brain states for the development of clinical
brain-computer interface systems (AI-iEEG for neurotechnology). We explain key
machine learning concepts, specifics of processing and modeling iEEG data and
details of state-of-the-art iEEG-based neurotechnology and brain-computer
interfaces.
","['Julia Berezutskaya', 'Anne-Lise Saive', 'Karim Jerbi', 'Marcel van Gerven']"
http://arxiv.org/abs/1703.02365v1,Neurotechnology,2017-03-07T13:12:31Z,2017-03-07T13:12:31Z,"Scientific Outreach with Teegi, a Tangible EEG Interface to Talk about
  Neurotechnologies","  Teegi is an anthropomorphic and tangible avatar exposing a users' brain
activity in real time. It is connected to a device sensing the brain by means
of electroencephalog-raphy (EEG). Teegi moves its hands and feet and closes its
eyes along with the person being monitored. It also displays on its scalp the
associated EEG signals, thanks to a semi-spherical display made of LEDs.
Attendees can interact directly with Teegi -- e.g. move its limbs -- to
discover by themselves the underlying brain processes. Teegi can be used for
scientific outreach to introduce neurotechnologies in general and
brain-computer interfaces (BCI) in particular.
","['Jérémy Frey', 'Renaud Gervais', 'Thibault Lainé', 'Maxime Duluc', 'Hugo Germain', 'Stéphanie Fleck', 'Fabien Lotte', 'Martin Hachet']"
http://arxiv.org/abs/2405.10780v2,Neurotechnology,2024-05-13T21:37:50Z,2024-05-31T15:00:36Z,"Intelligent and Miniaturized Neural Interfaces: An Emerging Era in
  Neurotechnology","  Integrating smart algorithms on neural devices presents significant
opportunities for various brain disorders. In this paper, we review the latest
advancements in the development of three categories of intelligent neural
prostheses featuring embedded signal processing on the implantable or wearable
device. These include: 1) Neural interfaces for closed-loop symptom tracking
and responsive stimulation; 2) Neural interfaces for emerging network-related
conditions, such as psychiatric disorders; and 3) Intelligent BMI SoCs for
movement recovery following paralysis.
","['Mahsa Shoaran', 'Uisub Shin', 'MohammadAli Shaeri']"
http://arxiv.org/abs/1804.10454v2,Neurotechnology,2018-04-27T11:56:04Z,2019-01-21T11:39:50Z,"Mining within-trial oscillatory brain dynamics to address the
  variability of optimized spatial filters","  Data-driven spatial filtering algorithms optimize scores such as the contrast
between two conditions to extract oscillatory brain signal components. Most
machine learning approaches for filter estimation, however, disregard
within-trial temporal dynamics and are extremely sensitive to changes in
training data and involved hyperparameters. This leads to highly variable
solutions and impedes the selection of a suitable candidate for,
e.g.,~neurotechnological applications. Fostering component introspection, we
propose to embrace this variability by condensing the functional signatures of
a large set of oscillatory components into homogeneous clusters, each
representing specific within-trial envelope dynamics.
  The proposed method is exemplified by and evaluated on a complex hand force
task with a rich within-trial structure. Based on electroencephalography data
of 18 healthy subjects, we found that the components' distinct temporal
envelope dynamics are highly subject-specific. On average, we obtained seven
clusters per subject, which were strictly confined regarding their underlying
frequency bands. As the analysis method is not limited to a specific spatial
filtering algorithm, it could be utilized for a wide range of
neurotechnological applications, e.g., to select and monitor functionally
relevant features for brain-computer interface protocols in stroke
rehabilitation.
","['Andreas Meinel', 'Henrich Kolkhorst', 'Michael Tangermann']"
http://arxiv.org/abs/1410.7550v1,Neurotechnology,2014-10-28T08:37:01Z,2014-10-28T08:37:01Z,Learning deep dynamical models from image pixels,"  Modeling dynamical systems is important in many disciplines, e.g., control,
robotics, or neurotechnology. Commonly the state of these systems is not
directly observed, but only available through noisy and potentially
high-dimensional observations. In these cases, system identification, i.e.,
finding the measurement mapping and the transition mapping (system dynamics) in
latent space can be challenging. For linear system dynamics and measurement
mappings efficient solutions for system identification are available. However,
in practical applications, the linearity assumptions does not hold, requiring
non-linear system identification techniques. If additionally the observations
are high-dimensional (e.g., images), non-linear system identification is
inherently hard. To address the problem of non-linear system identification
from high-dimensional observations, we combine recent advances in deep learning
and system identification. In particular, we jointly learn a low-dimensional
embedding of the observation by means of deep auto-encoders and a predictive
transition model in this low-dimensional space. We demonstrate that our model
enables learning good predictive models of dynamical systems from pixel
information only.
","['Niklas Wahlström', 'Thomas B. Schön', 'Marc Peter Deisenroth']"
http://arxiv.org/abs/2106.12295v1,Neurotechnology,2021-06-23T10:24:15Z,2021-06-23T10:24:15Z,Quantum Brain Networks: a Perspective,"  We propose Quantum Brain Networks (QBraiNs) as a new interdisciplinary field
integrating knowledge and methods from neurotechnology, artificial
intelligence, and quantum computing. The objective is to develop an enhanced
connectivity between the human brain and quantum computers for a variety of
disruptive applications. We foresee the emergence of hybrid classical-quantum
networks of wetware and hardware nodes, mediated by machine learning techniques
and brain-machine interfaces. QBraiNs will harness and transform in
unprecedented ways arts, science, technologies, and entrepreneurship, in
particular activities related to medicine, Internet of humans, intelligent
devices, sensorial experience, gaming, Internet of things, crypto trading, and
business.
","['E. R. Miranda', 'S. Venkatesh', 'C. Hernani-Morales', 'L. Lamata', 'J. D. Martín-Guerrero', 'E. Solano']"
http://arxiv.org/abs/2204.02362v2,Neurotechnology,2022-04-04T12:47:07Z,2022-04-13T12:02:18Z,"Challenges and Opportunities of Edge AI for Next-Generation Implantable
  BMIs","  Neuroscience and neurotechnology are currently being revolutionized by
artificial intelligence (AI) and machine learning. AI is widely used to study
and interpret neural signals (analytical applications), assist people with
disabilities (prosthetic applications), and treat underlying neurological
symptoms (therapeutic applications). In this brief, we will review the emerging
opportunities of on-chip AI for the next-generation implantable brain-machine
interfaces (BMIs), with a focus on state-of-the-art prosthetic BMIs. Major
technological challenges for the effectiveness of AI models will be discussed.
Finally, we will present algorithmic and IC design solutions to enable a new
generation of AI-enhanced and high-channel-count BMIs.
","['MohammadAli Shaeri', 'Arshia Afzal', 'Mahsa Shoaran']"
http://arxiv.org/abs/1505.03964v1,Neurotechnology,2015-05-15T05:53:45Z,2015-05-15T05:53:45Z,"Algebraic identification of the effective connectivity of constrained
  geometric network models of neural signaling","  Cellular neural circuit and networks consisting of interconnected neurons and
glia are ulti- mately responsible for the information processing associated
with information processing in the brain. While there are major efforts aimed
at mapping the structural and (electro)physiological connectivity of brain
networks, such as the White House BRAIN Initiative aimed at the devel- opment
of neurotechnologies capable of high density neural recordings, theoretical and
compu- tational methods for analyzing and making sense of all this data seem to
be further behind. Here, we propose and provide a summary of an approach for
calculating effective connectivity from experimental observations of neuronal
network activity. The proposed method operates on network-level data, makes use
of all relevant prior knowledge, such as dynamical models of individual cells
in the network and the physical structural connectivity of the network, and is
broadly applicable to large classes of biological and non-biological networks.
","['Marius Buibas', 'Gabriel A. Silva']"
http://arxiv.org/abs/2007.11674v1,Neurotechnology,2020-07-18T18:05:14Z,2020-07-18T18:05:14Z,"Using EEG-based brain connectivity for the study of brain dynamics in
  brain-computer interfaces","  The analysis of brain connectivity aims to understand the emergence of
functional networks into the brain. This information can be used in the process
of electroencephalographic (EEG) signal analysis and classification for a
braincomputer interface (BCI). These systems provide an alternative channel of
communication and control to people with motor impairments. In this article,
four strategies for using the brain connectivity in a BCI environment as a tool
to obtain a deeper understanding of the cerebral mechanisms are proposed, with
the principal aim of developing a scheme oriented to neuro-rehabilitation of
gait in combination with different neurotechnologies and exoskeletons. This
scheme would allow improving current schemes and/or to design new control
strategies, as well as rehabilitation approaches.
",['J. A. Gaxiola-Tirado']
http://arxiv.org/abs/2101.05084v1,Neurotechnology,2020-12-10T15:32:17Z,2020-12-10T15:32:17Z,"This Face Does Not Exist ... But It Might Be Yours! Identity Leakage in
  Generative Models","  Generative adversarial networks (GANs) are able to generate high resolution
photo-realistic images of objects that ""do not exist."" These synthetic images
are rather difficult to detect as fake. However, the manner in which these
generative models are trained hints at a potential for information leakage from
the supplied training data, especially in the context of synthetic faces. This
paper presents experiments suggesting that identity information in face images
can flow from the training corpus into synthetic samples without any
adversarial actions when building or using the existing model. This raises
privacy-related questions, but also stimulates discussions of (a) the face
manifold's characteristics in the feature space and (b) how to create
generative models that do not inadvertently reveal identity information of real
subjects whose images were used for training. We used five different face
matchers (face_recognition, FaceNet, ArcFace, SphereFace and Neurotechnology
MegaMatcher) and the StyleGAN2 synthesis model, and show that this identity
leakage does exist for some, but not all methods. So, can we say that these
synthetically generated faces truly do not exist? Databases of real and
synthetically generated faces are made available with this paper to allow full
replicability of the results discussed in this work.
","['Patrick Tinsley', 'Adam Czajka', 'Patrick Flynn']"
http://arxiv.org/abs/2302.03752v1,Neurotechnology,2023-02-07T20:57:15Z,2023-02-07T20:57:15Z,"Dynamic Visualization of Gyral and Sulcal Stereoelectroencephalographic
  contacts in Humans","  Stereoelectroencephalography (SEEG) is a neurosurgical method to survey
electrophysiological activity within the brain to treat disorders such as
Epilepsy. In this stereotactic approach, leads are implanted through straight
trajectories to survey both cortical and sub-cortical activity. Visualizing the
recorded locations covering sulcal and gyral activity while staying true to the
cortical architecture is challenging due to the folded, three-dimensional
nature of the human cortex. To overcome this challenge, we developed a novel
visualization concept, allowing investigators to dynamically morph between the
subjects' cortical reconstruction and an inflated cortex representation. This
inflated view, in which gyri and sulci are viewed on a smooth surface, allows
better visualization of electrodes buried within the sulcus while staying true
to the underlying cortical architecture.
","['Markus Adamek', 'Alexander P Rockhill', 'Peter Brunner', 'Dora Hermes']"
http://arxiv.org/abs/2409.11751v1,Neurotechnology,2024-09-18T07:09:59Z,2024-09-18T07:09:59Z,"Accelerated Algorithms for Source Orientation Detection (AORI) and
  Spatiotemporal LCMV (ALCMV) Beamforming in EEG Source Localization","  This paper illustrates the development of two efficient source localization
algorithms for electroencephalography (EEG) data, aimed at enhancing real-time
brain signal reconstruction while addressing the computational challenges of
traditional methods. Accurate EEG source localization is crucial for
applications in cognitive neuroscience, neurorehabilitation, and brain-computer
interfaces (BCIs). To make significant progress toward precise source
orientation detection and improved signal reconstruction, we introduce the
Accelerated Linear Constrained Minimum Variance (ALCMV) beamforming toolbox and
the Accelerated Brain Source Orientation Detection (AORI) toolbox. The ALCMV
algorithm speeds up EEG source reconstruction by utilizing recursive covariance
matrix calculations, while AORI simplifies source orientation detection from
three dimensions to one, reducing computational load by 66% compared to
conventional methods. Using both simulated and real EEG data, we demonstrate
that these algorithms maintain high accuracy, with orientation errors below
0.2% and signal reconstruction accuracy within 2%. These findings suggest that
the proposed toolboxes represent a substantial advancement in the efficiency
and speed of EEG source localization, making them well-suited for real-time
neurotechnological applications.
","['Ava Yektaeian Vaziri', 'Bahador Makkiabadi']"
http://arxiv.org/abs/2505.20509v1,Neurotechnology,2025-05-26T20:20:46Z,2025-05-26T20:20:46Z,"OpenNIRScap: An Open-Source, Low-Cost Wearable Near-Infrared
  Spectroscopy-based Brain Interfacing Cap","  Functional Near-Infrared Spectroscopy (fNIRS) is a non-invasive, real-time
method for monitoring brain activity by measuring hemodynamic responses in the
cerebral cortex. However, existing systems are expensive, bulky, and limited to
clinical or research environments. This paper introduces OpenNIRScap, an
open-source, low-cost, and wearable fNIRS system designed to make real-time
brain monitoring more accessible in everyday environments. The device features
24 custom-designed sensor boards with dual-wavelength light emitters and
photodiode detectors, a central electrical control unit (ECU) with analog
multiplexing, and a real-time data processing pipeline. Bench validation and
pilot tests on volunteers have confirmed the ability of the system to capture
cognitively evoked hemodynamic responses, supporting its potential as an
affordable tool for cognitive monitoring and portable neurotechnology
applications. The hardware, software, and graphical user interface have all
been open-sourced and made publicly available at the following link:
https://github.com/tonykim07/fNIRS.
","['Tony Kim', 'Haotian Liu', 'Chiung-Ting Huang', 'Ingrid Wu', 'Xilin Liu']"
http://arxiv.org/abs/2505.24790v1,Neurotechnology,2025-05-30T16:52:44Z,2025-05-30T16:52:44Z,"Towards model-based design of causal manipulations of brain circuits
  with high spatiotemporal precision","  Recent advancements in neurotechnology enable precise spatiotemporal patterns
of microstimulations with single-cell resolution. The choice of perturbation
sites must satisfy two key criteria: efficacy in evoking significant responses
and selectivity for the desired target effects. This choice is currently based
on laborious trial-and-error procedures, unfeasible for sequences of multi-site
stimulations. Efficient methods to design complex perturbation patterns are
urgently needed. Can we design a spatiotemporal pattern of stimulation to steer
neural activity and behavior towards a desired target? We outline a method for
achieving this goal in two steps. First, we identify the most effective
perturbation sites, or hubs, only based on short observations of spontaneous
neural activity. Second, we provide an efficient method to design multi-site
stimulation patterns by combining approaches from nonlinear dynamical systems,
control theory and data-driven methods. We demonstrate the feasibility of our
approach using multi-site stimulation patterns in recurrent network models.
","['Anandita De', 'Roozbeh Kiani', 'Luca Mazzucato']"
http://arxiv.org/abs/2504.15291v1,Reusable launch vehicle,2025-04-08T22:15:13Z,2025-04-08T22:15:13Z,"Greenhouse Gas (GHG) Emissions Poised to Rocket: Modeling the
  Environmental Impact of LEO Satellite Constellations","  The proliferation of satellite megaconstellations in low Earth orbit (LEO)
represents a significant advancement in global broadband connectivity. However,
we urgently need to understand the potential environmental impacts,
particularly greenhouse gas (GHG) emissions associated with these
constellations. This study addresses a critical gap in modeling current and
future GHG emissions by developing a comprehensive open-source life cycle
assessment (LCA) methodology, applied to 10 launch vehicles and 15
megaconstellations. Our analysis reveals that the production of launch vehicles
and propellant combustion during launch events contribute most significantly to
overall GHG emissions, accounting for 72.6% of life cycle emissions. Among the
rockets analyzed, reusable vehicles like Falcon-9 and Starship demonstrate
95.4% lower production emissions compared to non-reusable alternatives,
highlighting the environmental benefits of reusability in space technology. The
findings underscore the importance of launch vehicle and satellite design
choices to minimize potential environmental impacts. The Open-source Rocket and
Constellation Lifecycle Emissions (ORACLE) repository is freely available and
aims to facilitate further research in this field. This study provides a
critical baseline for policymakers and industry stakeholders to develop
strategies for reducing the carbon footprint of the space industry, especially
satellite megaconstellations.
","['Rushil Kukreja', 'Edward J. Oughton', 'Richard Linares']"
http://arxiv.org/abs/2107.13513v2,Reusable launch vehicle,2021-04-19T00:15:27Z,2021-12-21T07:53:19Z,Feasibility Study For Multiply Reusable Space Launch System,"  A novel concept of orbital launch system in which all stages are reusable is
presented. The first two stages called Midpoint Delivery System (MPDS) deliver
the next stages to a midpoint. A midpoint is defined by an altitude of 100 $km$
to 120 $km$ and horizontal velocity of 2.8 $km/s$ to 3.2 $km/s$. MPDS stages
decelerate in the atmosphere and perform vertical landing on barges. These
stages can be reused daily for many years. The payload is delivered from the
midpoint to a 400 $km$ Low Earth Orbit by one or two stage rocket called
Midpoint to Orbit Delivery System (MPTO). All of MPTO engines are delivered to
LEO. These engines do not return to Earth themselves. They are returned to
Earth in packs of 50 to 100 by a Reentry Vehicle. Overall, the fully and
multiply reusable launch system should deliver payload to LEO for \$300 to
\$400 per $kg$
",['Mikhail Shubov']
http://arxiv.org/abs/2009.01664v1,Reusable launch vehicle,2020-09-03T13:48:54Z,2020-09-03T13:48:54Z,"Multidisciplinary Design Optimization of Reusable Launch Vehicles for
  Different Propellants and Objectives","  Identifying the optimal design of a new launch vehicle is most important
since design decisions made in the early development phase limit the vehicles'
later performance and determines the associated costs. Reusing the first stage
via retro-propulsive landing increases the complexity even more. Therefore, we
develop an optimization framework for partially reusable launch vehicles, which
enables multidisciplinary design studies. The framework contains suitable mass
estimates of all essential subsystems and a routine to calculate the needed
propellant for the ascent and landing maneuvers. For design optimization, the
framework can be coupled with a genetic algorithm. The overall goal is to
reveal the implications of different propellant combinations and objective
functions on the launcher's optimal design for various mission scenarios. The
results show that the optimization objective influences the most suitable
propellant choice and the overall launcher design, concerning staging, weight,
size, and rocket engine parameters. In terms of gross lift-off weight, liquid
hydrogen seems to be favorable. When optimizing for a minimum structural mass
or an expandable structural mass, hydrocarbon-based solutions show better
results. Finally, launch vehicles using a hydrocarbon fuel in the first stage
and liquid hydrogen in the upper stage are an appealing alternative, combining
both fuels' benefits.
","['Kai Dresia', 'Simon Jentzsch', 'Günther Waxenegger-Wilfing', 'Robson Hahn', 'Jan Deeken', 'Michael Oschwald', 'Fabio Mota']"
http://arxiv.org/abs/2405.01264v1,Reusable launch vehicle,2024-05-02T13:13:35Z,2024-05-02T13:13:35Z,"Model Predictive Guidance for Fuel-Optimal Landing of Reusable Launch
  Vehicles","  This paper introduces a landing guidance strategy for reusable launch
vehicles (RLVs) using a model predictive approach based on sequential convex
programming (SCP). The proposed approach devises two distinct optimal control
problems (OCPs): planning a fuel-optimal landing trajectory that accommodates
practical path constraints specific to RLVs, and determining real-time optimal
tracking commands. This dual optimization strategy allows for reduced
computational load through adjustable prediction horizon lengths in the
tracking task, achieving near closed-loop performance. Enhancements in model
fidelity for the tracking task are achieved through an alternative rotational
dynamics representation, enabling a more stable numerical solution of the OCP
and accounting for vehicle transient dynamics. Furthermore, modifications of
aerodynamic force in both planning and tracking phases are proposed, tailored
for thrust-vector-controlled RLVs, to reduce the fidelity gap without adding
computational complexity. Extensive 6-DOF simulation experiments validate the
effectiveness and improved guidance performance of the proposed algorithm.
","['Ki-Wook Jung', 'Sang-Don Lee', 'Cheol-Goo Jung', 'Chang-Hun Lee']"
http://arxiv.org/abs/2406.04185v1,Reusable launch vehicle,2024-06-06T15:41:12Z,2024-06-06T15:41:12Z,Numerical Optimization Study of a Constrained Hypersonic Reentry Vehicle,"  The trajectory optimization of the atmospheric entry of a reusable launch
vehicle is studied. The objective is to maximize the crossrange of the vehicle
subject to two control-inequality path constraints, two state-inequality path
constraints, and one mixed state-and-control inequality path constraint. In
order to determine the complex switching structure in the activity of the path
constraints, a recently developed method for solving state-path constrained
optimal control problems is used. This recently developed method is designed to
algorithmically locate the points of activation and deactivation in the path
constraints and partition the domain of the independent variable into
subdomains based on these activation and deactivation points. Additionally, in
a domain where a state-inequality path constraint is found to be active, the
method algorithmically determines and enforces the additional necessary
conditions that apply on the constrained arc. A multiple-domain formulation of
Legendre-Gauss-Radau direct collocation is then employed to transcribe the
optimal control problem into a large sparse nonlinear programming problem. Two
studies are performed which analyze a variety of problem formulations of the
hypersonic reusable launch vehicle. Key features of the constrained
trajectories are presented, and the method used is shown to obtain highly
accurate solutions with minimal user intervention.
","['Cale A. Byczkowski', 'Anil V. Rao']"
http://arxiv.org/abs/2503.11862v1,Reusable launch vehicle,2025-03-14T20:43:58Z,2025-03-14T20:43:58Z,"Ignition Point Reachability for Aerodynamically-Controlled Reusable
  Launch Vehicles","  We describe a successive convex programming (Sequential Convex Programming
(SCP)) based approach for estimate the set of points where a 5-degree of
freedom (5-DoF) reusable launch vehicle (RLV) returning to a landing site can
transition from aerodynamic to propulsive descent. Determining the set of
feasible ignition points that a RLV can use and then safely land is important
for mission planning and range safety. However, past trajectory optimization
approaches for RLVs consider substantially simplified versions of the vehicle
dynamics. Furthermore, prior reachability analysis methods either do not extend
to the full constraint set needed for an RLV or are too beset by the curse of
dimensionality to handle the full 5-DoF dynamics. To solve this problem, we
describe an algorithm that approximates the projection of a high dimensional
reachable set onto a low dimensional space. Instead of computing all parts of
the reachable space, we only calculate reachability in the projected space of
interest by using repeated trajectory optimization to sample the reachable
polytope in the reduced space. The optimization can take into account initial
and terminal constraints as well as state and control constraints. We show that
our algorithm is able to compute the projection of a reachable set into a low
dimensional space by calculating the feasible ignition points for a two-phase
aerodynamic/propulsive RLV landing trajectory, while also demonstrating the
aerodynamic divert enabled by our body and fin actuator model.
","['Benjamin Chung', 'Kazuya Echigo', 'Behçet Açıkmeşe']"
http://arxiv.org/abs/1409.1036v2,Reusable launch vehicle,2014-09-03T11:14:38Z,2015-02-20T08:26:39Z,EMMI - Electric Solar Wind Sail Facilitated Manned Mars Initiative,"  The novel propellantless electric solar wind sail concept promises efficient
low thrust transportation in the Solar System outside Earth's magnetosphere.
Combined with asteroid mining to provide water and synthetic cryogenic rocket
fuel in orbits of Earth and Mars, possibilities for affordable continuous
manned presence on Mars open up. Orbital fuel and water enable reusable
bidirectional Earth-Mars vehicles for continuous manned presence on Mars and
allow smaller fuel fraction of spacecraft than what is achievable by
traditional means. Water can also be used as radiation shielding of the manned
compartment, thus reducing the launch mass further. In addition, the presence
of fuel in the orbit of Mars provides the option for an all-propulsive landing,
thus potentially eliminating issues of heavy heat shields and augmenting the
capability of pinpoint landing. With this E-sail enabled scheme, the recurrent
cost of continuous bidirectional traffic between Earth and Mars might
ultimately approach the recurrent cost of running the International Space
Station, ISS.
","['Pekka Janhunen', 'Sini Merikallio', 'Mark Paton']"
http://arxiv.org/abs/1606.02387v1,Reusable launch vehicle,2016-06-08T03:42:41Z,2016-06-08T03:42:41Z,"Angle-of-Attack Modulation in Trajectory Tracking for a Reusable Launch
  Vehicle","  This paper deals with the problem of angle-of-attack modulation with the aim
of enhancing transient performance of entry guidance during bank reversals,
while compensating adverse effects of fast time-varying transient disturbances.
An extended single-input/single-output system is developed in the velocity
domain by means of a dynamic extension technique, and explicitly captures the
trajectory dynamics of angle-of-attack modulation. A normal form for this
extended system is derived for the sake of employing a feedback linearization
controller. Further, the control characteristics of angle-of-attack modulation
is found to be a non-minimum phase behavior under two common conditions in a
near- equilibrium glide flight. Therefore, the issue of angle-of-attack
modulation is formulated as robust output stabilization of the non-minimum
phase system. A disturbance observer-based feedback linearization technique is
used to design a robustly dynamical output-feedback controller for
angle-of-attack modulation, and an internal-state feedback controller for
bank-angle modulation is used to stabilize the unstable internal dynamics.
Numerical simulations are conducted to demonstrate that the performance of the
proposed method of angle-of-attack modulation is enhanced compared to the
existing shuttle method.
","['Ran Zhang', 'Huifeng Li', 'Rui Zhang']"
http://arxiv.org/abs/2310.05994v1,Reusable launch vehicle,2023-10-09T00:41:01Z,2023-10-09T00:41:01Z,Launch Vehicle High-Energy Performance Dataset,"  The choice of the launch vehicle is an important consideration during the
preliminary planning of interplanetary missions. The launch vehicle must be
highly reliable, capable of imparting sufficient energy to the spacecraft to
inject it on to an Earth-escape trajectory, and must fit within the cost
constraints of the mission. Over the recent past, the most commonly used
launchers for interplanetary missions include the Atlas V401, Atlas V551, Delta
IVH, and Falcon Heavy expendable version. The NASA Launch Vehicle Performance
website maintains a tool to help mission planners evaluate various launch
vehicles during mission studies. However, there is no comprehensive dataset
which can be used to quickly compare the launch performance and launch cost of
various options. The present study compiles a dataset of the high energy
performance of existing and planned launchers from open-source data and
performs a quantitative comparison of the launch performance and the launch
cost per kg. The Falcon Heavy expendable offers the lowest cost-per-kg for
high-energy launches, with only $0.075M per kg. The Vulcan Centaur offers
comparable performance to the Falcon Heavy. The results indicate Falcon Heavy
Expendable and the Vulcan Centaur will be the likely choice for several future
missions.
",['Athul Pradeepkumar Girija']
http://arxiv.org/abs/2310.06541v1,Reusable launch vehicle,2023-10-10T11:40:20Z,2023-10-10T11:40:20Z,"Realizing Stabilized Landing for Computation-Limited Reusable Rockets: A
  Quantum Reinforcement Learning Approach","  The advent of reusable rockets has heralded a new era in space exploration,
reducing the costs of launching satellites by a significant factor. Traditional
rockets were disposable, but the design of reusable rockets for repeated use
has revolutionized the financial dynamics of space missions. The most critical
phase of reusable rockets is the landing stage, which involves managing the
tremendous speed and attitude for safe recovery. The complexity of this task
presents new challenges for control systems, specifically in terms of precision
and adaptability. Classical control systems like the
proportional-integral-derivative (PID) controller lack the flexibility to adapt
to dynamic system changes, making them costly and time-consuming to redesign of
controller. This paper explores the integration of quantum reinforcement
learning into the control systems of reusable rockets as a promising
alternative. Unlike classical reinforcement learning, quantum reinforcement
learning uses quantum bits that can exist in superposition, allowing for more
efficient information encoding and reducing the number of parameters required.
This leads to increased computational efficiency, reduced memory requirements,
and more stable and predictable performance. Due to the nature of reusable
rockets, which must be light, heavy computers cannot fit into them. In the
reusable rocket scenario, quantum reinforcement learning, which has reduced
memory requirements due to fewer parameters, is a good solution.
","['Gyu Seon Kim', 'JaeHyun Chung', 'Soohyun Park']"
http://arxiv.org/abs/2411.04073v1,Reusable launch vehicle,2024-11-06T17:50:32Z,2024-11-06T17:50:32Z,"Rescheduling after vehicle failures in the multi-depot rural postman
  problem with rechargeable and reusable vehicles","  We present a centralized auction algorithm to solve the Multi-Depot Rural
Postman Problem with Rechargeable and Reusable Vehicles (MD-RPP-RRV), focusing
on rescheduling arc routing after vehicle failures. The problem involves
finding heuristically obtained best feasible routes for multiple rechargeable
and reusable vehicles with capacity constraints capable of performing multiple
trips from multiple depots, with the possibility of vehicle failures. Our
algorithm auctions the failed trips to active (non-failed) vehicles through
local auctioning, modifying initial routes to handle dynamic vehicle failures
efficiently. When a failure occurs, the algorithm searches for the best active
vehicle to perform the failed trip and inserts the trip into that vehicle's
route, which avoids a complete rescheduling and reduces the computational
effort. We compare the algorithm's solutions against offline optimal solutions
obtained from solving a Mixed Integer Linear Programming (MILP) formulation
using the Gurobi solver; this formulation assumes that perfect information
about the vehicle failures and failure times is given. The results demonstrate
that the centralized auction algorithm produces solutions that are, in some
cases, near optimal; moreover, the execution time for the proposed approach is
much more consistent and is, for some instances, orders of magnitude less than
the execution time of the Gurobi solver. The theoretical analysis provides an
upper bound for the competitive ratio and computational complexity of our
algorithm, offering a formal performance guarantee in dynamic failure
scenarios.
","['Eashwar Sathyamurthy', 'Jeffrey W. Herrmann', 'Shapour Azarm']"
http://arxiv.org/abs/2009.06495v1,Reusable launch vehicle,2020-09-14T14:58:12Z,2020-09-14T14:58:12Z,"Assembled Kinetic Impactor for Deflecting Asteroids via Combining the
  Spacecraft with the Launch Vehicle Final Stage","  Asteroid Impacts pose a major threat to all life on the Earth. Deflecting the
asteroid from the impact trajectory is an important way to mitigate the threat.
A kinetic impactor remains to be the most feasible method to deflect the
asteroid. However, due to the constraint of the launch capability, an impactor
with the limited mass can only produce a very limited amount of velocity
increment for the asteroid. In order to improve the deflection efficiency of
the kinetic impactor strategy, this paper proposed a new concept called the
Assembled Kinetic Impactor (AKI), which is combining the spacecraft with the
launch vehicle final stage. By making full use of the mass of the launch
vehicle final stage, the mass of the impactor will be increased, which will
cause the improvement of the deflection efficiency. According to the technical
data of Long March 5 (CZ-5) launch vehicle, the missions of deflecting Bennu
are designed to demonstrate the power of the AKI concept. Simulation results
show that, compared with the Classic Kinetic Impactor (CKI, performs
spacecraft-rocket separation), the addition of the mass of the launch vehicle
final stage can increase the deflection distance to more than 3 times, and
reduce the launch lead-time by at least 15 years. With the requirement of the
same deflection distance, the addition of the mass of the launch vehicle final
stage can reduce the number of launches to 1/3 of that of the number of CKI
launches. The AKI concept makes it possible to defend Bennu-like large
asteroids by a no-nuclear technique within 10-year launch lead-time. At the
same time, for a single CZ-5, the deflection distance of a 140 m diameter
asteroid within 10-year launch lead-time, can be increased from less than 1
Earth radii to more than 1 Earth radii.
","['Yirui Wang', 'Mingtao Li', 'Zizheng Gong', 'Jianming Wang', 'Chuankui Wang', 'Binghong Zhou']"
http://arxiv.org/abs/2303.17869v1,Reusable launch vehicle,2023-03-31T08:06:20Z,2023-03-31T08:06:20Z,"Numerical Modelling and GNSS Observations of Ionospheric Depletions due
  to a Small-Lift Launch Vehicle","  Space launches produce ionospheric disturbances which can be observed through
measurements such as Global Navigation Satellite System signal delays. Here we
report observations and numerical simulations of the ionospheric depletion due
to a Small-Lift Launch Vehicle. The case examined was the launch of a Rocket
Lab Electron at 22:30 UTC on March 22, 2021. Despite the very small launch
vehicle, ground stations in the Chatham Islands measured decreases in
line-of-sight total electron content for navigation satellite signals following
the launch. General Circulation Model results indicated ionospheric depletions
which were comparable with these measurements. Line-of-sight measurements
showed a maximum decrease of $2.7$~TECU in vertical total electron content,
compared with a simulated decrease of $2.6$~TECU. Advection of the exhaust
plume due to its initial velocity and subsequent effects of neutral winds are
identified as some remaining challenges for this form of modelling.
","['G. W. Bowden', 'M. Brown']"
http://arxiv.org/abs/2205.05205v1,Reusable launch vehicle,2022-05-10T22:56:49Z,2022-05-10T22:56:49Z,An integrated debris environment assessment model,"  Launch behaviors are a key determinant of the orbital environment. Physical
and economic forces such as fragmentations and changing launch costs, or
policies like post-mission disposal (PMD) compliance requirements, will alter
the relative attractiveness of different orbits and lead operators to adjust
their launch behaviors. However, integrating models of adaptive launch behavior
with models of the debris environment remains an open challenge. We present a
statistical framework for integrating theoretically-grounded models of launch
behavior with evolutionary models of the low-Earth orbit (LEO) environment. We
implement this framework using data on satellite launches, the orbital
environment, launch vehicle prices, sectoral revenues, and government budgets
over 2007-2020. The data are combined with a multi-shell and multi-species
Particle-in-a-Box (PIB) model of the debris environment and a two-stage
budgeting model of commercial, civil government, and defense decisions to
allocate new launches across orbital shells. We demonstrate the framework's
capabilities in three counterfactual scenarios: unexpected fragmentation events
in highly-used regions, a sharp decrease in the cost of accessing lower parts
of LEO, and increasing compliance with 25-year PMD guidelines. Substitution
across orbits based on their evolving characteristics and the behavior of other
operators induces notable changes in the debris environment relative to models
without behavioral channels.
","['Akhil Rao', 'Francesca Letizia']"
http://arxiv.org/abs/2307.12642v1,Reusable launch vehicle,2023-07-24T09:32:54Z,2023-07-24T09:32:54Z,"Simultaneous Optimization of Launch Vehicle Stage and Trajectory
  Considering Operational Safety Constraints","  A conceptual design of a launch vehicle involves the optimization of
trajectory and stages considering its launch operations. This process
encompasses various disciplines, such as structural design, aerodynamics,
propulsion systems, flight control, and stage sizing. Traditional approaches
used for the conceptual design of a launch vehicle conduct the stage and
trajectory designs sequentially, often leading to high computational complexity
and suboptimal results. This paper presents an optimization framework that
addresses both trajectory optimization and staging in an integrated way. The
proposed framework aims to maximize the payload-to-liftoff mass ratio while
satisfying the constraints required for safe launch operations (e.g., the
impact points of burnt stages and fairing). A case study demonstrates the
advantage of the proposed framework compared to the traditional sequential
optimization approach.
","['Jaeyoul Ko', 'Jaewoo Kim', 'Jimin Choi', 'Jaemyung Ahn']"
http://arxiv.org/abs/2008.13239v1,Reusable launch vehicle,2020-08-30T18:44:18Z,2020-08-30T18:44:18Z,"Convex Optimization of Launch Vehicle Ascent Trajectory with Heat-Flux
  and Splash-Down Constraints","  This paper presents a convex programming approach to the optimization of a
multistage launch vehicle ascent trajectory, from the liftoff to the payload
injection into the target orbit, taking into account multiple nonconvex
constraints, such as the maximum heat flux after fairing jettisoning and the
splash-down of the burned-out stages. Lossless and successive convexification
are employed to convert the problem into a sequence of convex subproblems.
Virtual controls and buffer zones are included to ensure the recursive
feasibility of the process and a state-of-the-art method for updating the
reference solution is implemented to filter out undesired phenomena that may
hinder convergence. A hp pseudospectral discretization scheme is used to
accurately capture the complex ascent and return dynamics with a limited
computational effort. The convergence properties, computational efficiency, and
robustness of the algorithm are discussed on the basis of numerical results.
The ascent of the VEGA launch vehicle toward a polar orbit is used as case
study to discuss the interaction between the heat flux and splash-down
constraints. Finally, a sensitivity analysis of the launch vehicle carrying
capacity to different splash-down locations is presented.
","['Boris Benedikter', 'Alessandro Zavoli', 'Guido Colasurdo', 'Simone Pizzurro', 'Enrico Cavallini']"
http://arxiv.org/abs/1611.06925v1,Reusable launch vehicle,2016-11-21T18:13:27Z,2016-11-21T18:13:27Z,"Robust Design of H-infinity Controller for a Launch Vehicle Autopilot
  against Disturbances","  Atmospheric flight phase of a launch vehicle is utilized to evaluate the
performance of an H-infinity controller in the presence of disturbances.
Dynamics of the vehicle is linearly modeled using time-varying parameters. An
operating point was found to design a robust command tracker using H-infinity
control theory that guarantees a stable maneuver. At the end, the controller
was employed on the launch vehicle to assess the capability of control design
on the linearized aerospace vehicle. Experimental results illustrate the
excellent performance of the H-infinity controller and accurate tracking
implemented by the autopilot. Also the robustness of the entire system against
disturbances is demonstrated to be acceptable.
","['Antonio Graells', 'Francisco Carrabina']"
http://arxiv.org/abs/1611.05512v1,Reusable launch vehicle,2016-11-17T00:13:45Z,2016-11-17T00:13:45Z,"Unmatched Perturbation Accommodation for an Aerospace Launch Vehicle
  Autopilot Using Dynamic Sliding Manifolds","  Sliding mode control of a launch vehicle during its atmospheric flight phase
is studied in the presence of unmatched disturbances. Linear time-varying
dynamics of the aerospace vehicle is converted into a systematic formula and
then dynamic sliding manifold as an advanced method is used in order to
overcome the limited capability of conventional sliding manifolds in minimizing
the undesired effects of unmatched perturbations on the control system. At the
end, simulation results are evaluated and the performance of two approaches are
compared in terms of stability and robustness of the autopilot.
",['Mohammad Reza Saniee']
http://arxiv.org/abs/2307.16788v1,Reusable launch vehicle,2023-07-31T15:55:50Z,2023-07-31T15:55:50Z,Congestion Analysis for the DARPA OFFSET CCAST Swarm,"  The Defense Advanced Research Projects Agency (DARPA) OFFensive Swarm-Enabled
Tactics program's goal of launching 250 unmanned aerial and ground vehicles
from a limited sized launch zone was a daunting challenge. The swarm's aerial
vehicles were primarily multirotor platforms, which can efficiently be launched
en masse. Each field exercise expected the deployment of an even larger swarm.
While the launch zone's spatial area increased with each field exercise, the
relative space for each vehicle was not necessarily increased, considering the
increasing size of the swarm and the vehicles' associated GPS error; however,
safe mission deployment and execution were expected. At the same time,
achieving the mission goals required maximizing efficiency of the swarm's
performance by reducing congestion that blocked vehicles from completing tactic
assignments. Congestion analysis conducted before the final field exercise
focused on adjusting various constraints to optimize the swarm's deployment
without reducing safety. During the field exercise, data was collected that
permitted analyzing the number and durations of individual vehicle blockages'
impact on the resulting congestion. After the field exercise, additional
analyses used the mission plan to validate the use of simulation for analyzing
congestion.
","['Robert Brown', 'Julie A. Adams']"
http://arxiv.org/abs/1911.05639v1,Reusable launch vehicle,2019-11-13T17:16:51Z,2019-11-13T17:16:51Z,Design of a Ballistically-Launched Foldable Multirotor,"  The operation of multirotors in crowded environments requires a highly
reliable takeoff method, as failures during takeoff can damage more valuable
assets nearby. The addition of a ballistic launch system imposes a
deterministic path for the multirotor to prevent collisions with its
environment, as well as increases the multirotor's range of operation and
allows deployment from an unsteady platform. In addition, outfitting planetary
rovers or entry vehicles with such deployable multirotors has the potential to
greatly extend the data collection capabilities of a mission. A
proof-of-concept multirotor aircraft has been developed, capable of
transitioning from a ballistic launch configuration to a fully controllable
flight configuration in midair after launch. The transition is accomplished via
passive unfolding of the multirotor arms, triggered by a nichrome burn wire
release mechanism. The design is 3D printable, launches from a three-inch
diameter barrel, and has sufficient thrust to carry a significant payload. The
system has been fabricated and field tested from a moving vehicle up to 50mph
to successfully demonstrate the feasibility of the concept and experimentally
validate the design's aerodynamic stability and deployment reliability.
","['Daniel Pastor', 'Jacob Izraelevitz', 'Paul Nadan', 'Amanda Bouman', 'Joel Burdick', 'Brett Kennedy']"
http://arxiv.org/abs/1907.13114v1,Robotics,2019-07-30T17:56:17Z,2019-07-30T17:56:17Z,The Use of Agricultural Robots in Orchard Management,"  Book chapter that summarizes recent research on agricultural robotics in
orchard management, including Robotic pruning, Robotic thinning, Robotic
spraying, Robotic harvesting, Robotic fruit transportation, and future trends.
","['Qin Zhang', 'Manoj Karkee', 'Amy Tabb']"
http://arxiv.org/abs/2208.05095v1,Robotics,2022-08-10T01:02:57Z,2022-08-10T01:02:57Z,Robotics in Snow and Ice,"  Definition: The terms ""robotics in snow and ice"" refers to robotic systems
being studied, developed, and used in areas where water can be found in its
solid state. This specialized branch of field robotics investigates the impact
of extreme conditions related to cold environments on autonomous vehicles.
",['François Pomerleau']
http://arxiv.org/abs/2005.07474v1,Robotics,2020-05-15T11:31:54Z,2020-05-15T11:31:54Z,Robot Accident Investigation: a case study in Responsible Robotics,"  Robot accidents are inevitable. Although rare, they have been happening since
assembly-line robots were first introduced in the 1960s. But a new generation
of social robots are now becoming commonplace. Often with sophisticated
embedded artificial intelligence (AI) social robots might be deployed as care
robots to assist elderly or disabled people to live independently. Smart robot
toys offer a compelling interactive play experience for children and
increasingly capable autonomous vehicles (AVs) the promise of hands-free
personal transport and fully autonomous taxis. Unlike industrial robots which
are deployed in safety cages, social robots are designed to operate in human
environments and interact closely with humans; the likelihood of robot
accidents is therefore much greater for social robots than industrial robots.
This paper sets out a draft framework for social robot accident investigation;
a framework which proposes both the technology and processes that would allow
social robot accidents to be investigated with no less rigour than we expect of
air or rail accident investigations. The paper also places accident
investigation within the practice of responsible robotics, and makes the case
that social robotics without accident investigation would be no less
irresponsible than aviation without air accident investigation.
","['Alan F. T. Winfield', 'Katie Winkle', 'Helena Webb', 'Ulrik Lyngs', 'Marina Jirotka', 'Carl Macrae']"
http://arxiv.org/abs/1403.2625v1,Robotics,2014-03-11T16:12:58Z,2014-03-11T16:12:58Z,Pattern Formation for Asynchronous Robots without Agreement in Chirality,"  This paper presents a deterministic algorithm for forming a given asymmetric
pattern in finite time by a set of autonomous, homogeneous, oblivious mobile
robots under the CORDA model. The robots are represented as points on the 2D
plane. There is no explicit communication between the robots. The robots
coordinate among themselves by observing the positions of the other robots on
the plane. Initially all the robots are assumed to be stationary. The robots
have local coordinate systems defined by Sense of Direction (SoD), orientation
or chirality and scale. Initially the robots are in asymmetric configuration.
We show that these robots can form any given asymmetric pattern in finite time.
","['Sruti Gan Chaudhuri', 'Swapnil Ghike', 'Shrainik Jain', 'Krishnendu Mukhopadhyaya']"
http://arxiv.org/abs/1408.2072v1,Robotics,2014-08-09T07:43:54Z,2014-08-09T07:43:54Z,Formation of General Position by Asynchronous Mobile Robots,"  The traditional distributed model of autonomous, homogeneous, mobile point
robots usually assumes that the robots do not create any visual obstruction for
the other robots, i.e., the robots are see through. In this paper, we consider
a slightly more realistic model, by incorporating the notion of obstructed
visibility (i.e., robots are not see through) for other robots. Under the new
model of visibility, a robot may not have the full view of its surroundings.
Many of the existing algorithms demand that each robot should have the complete
knowledge of the positions of other robots. Since, vision is the only mean of
their communication, it is required that the robots are in general position
(i.e., no three robots are collinear). We consider asynchronous robots. They
also do not have common chirality (or any agreement on a global coordinate
system). In this paper, we present a distributed algorithm for obtaining a
general position for the robots in finite time from any arbitrary
configuration. The algorithm also assures collision free motion for each robot.
This algorithm may also be used as a preprocessing module for many other
subsequent tasks performed by the robots.
","['S. Bhagat', 'S. Gan Chaudhuri', 'K. Mukhopadhyaya']"
http://arxiv.org/abs/2210.05204v1,Robotics,2022-10-11T07:19:04Z,2022-10-11T07:19:04Z,A review of cuspidal serial and parallel manipulators,"  Cuspidal robots can move from one inverse or direct kinematic solution to
another without ever passing through a singularity. These robots have remained
unknown because almost all industrial robots do not have this feature. However,
in fact, industrial robots are the exceptions. Some robots appeared recently in
the industrial market can be shown to be cuspidal but, surprisingly, almost
nobody knows it and robot users meet difficulties in planning trajectories with
these robots. This paper proposes a review on the fundamental and application
aspects of cuspidal robots. It addresses the important issues raised by these
robots for the design and planning of trajectories. The identification of all
cuspidal robots is still an open issue. This paper recalls in details the case
of serial robots with three joints but it also addresses robots with more
complex architectures such as 6-revolute-jointed robot and parallel robots. We
hope that this paper will help disseminate more widely knowledge on cuspidal
robots.
","['Philippe Wenger', 'Damien Chablat']"
http://arxiv.org/abs/2408.05491v1,Robotics,2024-08-10T08:43:07Z,2024-08-10T08:43:07Z,Optimal Dispersion of Silent Robots in a Ring,"  Given a set of co-located mobile robots in an unknown anonymous graph, the
robots must relocate themselves in distinct graph nodes to solve the dispersion
problem. In this paper, we consider the dispersion problem for silent robots
\cite{gorain2024collaborative}, i.e., no direct, explicit communication between
any two robots placed in the nodes of an oriented $n$ node ring network. The
robots operate in synchronous rounds. The dispersion problem for silent mobile
robots has been studied in arbitrary graphs where the robots start from a
single source. In this paper, we focus on the dispersion problem for silent
mobile robots where robots can start from multiple sources. The robots have
unique labels from a range $[0,\;L]$ for some positive integer $L$. Any two
co-located robots do not have the information about the label of the other
robot. The robots have weak multiplicity detection capability, which means they
can determine if it is alone on a node. The robots are assumed to be able to
identify an increase or decrease in the number of robots present on a node in a
particular round. However, the robots can not get the exact number of increase
or decrease in the number of robots. We have proposed a deterministic
distributed algorithm that solves the dispersion of $k$ robots in an oriented
ring in $O(\log L+k)$ synchronous rounds with $O(\log L)$ bits of memory for
each robot. A lower bound $\Omega(\log L+k)$ on time for the dispersion of $k$
robots on a ring network is presented to establish the optimality of the
proposed algorithm.
","['Bibhuti Das', 'Barun Gorain', 'Kaushik Mondal', 'Krishnendu Mukhopadhyaya', 'Supantha Pandit']"
http://arxiv.org/abs/cs/0411018v1,Robotics,2004-11-08T20:41:44Z,2004-11-08T20:41:44Z,"Artificial Intelligence and Systems Theory: Applied to Cooperative
  Robots","  This paper describes an approach to the design of a population of cooperative
robots based on concepts borrowed from Systems Theory and Artificial
Intelligence. The research has been developed under the SocRob project, carried
out by the Intelligent Systems Laboratory at the Institute for Systems and
Robotics - Instituto Superior Tecnico (ISR/IST) in Lisbon. The acronym of the
project stands both for ""Society of Robots"" and ""Soccer Robots"", the case study
where we are testing our population of robots. Designing soccer robots is a
very challenging problem, where the robots must act not only to shoot a ball
towards the goal, but also to detect and avoid static (walls, stopped robots)
and dynamic (moving robots) obstacles. Furthermore, they must cooperate to
defeat an opposing team. Our past and current research in soccer robotics
includes cooperative sensor fusion for world modeling, object recognition and
tracking, robot navigation, multi-robot distributed task planning and
coordination, including cooperative reinforcement learning in cooperative and
adversarial environments, and behavior-based architectures for real time task
execution of cooperating robot teams.
","['Pedro U. Lima', 'Luis M. M. Custodio']"
http://arxiv.org/abs/0808.1661v1,Robotics,2008-08-12T13:21:52Z,2008-08-12T13:21:52Z,"Medical robotics: where we come from, where we are and where we could go","  This short note presents a viewpoint about medical robotics.
",['Jocelyne Troccaz']
http://arxiv.org/abs/1812.06784v4,Robotics,2018-12-17T14:21:37Z,2019-04-24T08:44:46Z,"Animation Techniques in Human-Robot Interaction User Studies: a
  Systematic Literature Review","  There are many different ways a robot can move in Human-Robot Interaction.
One way is to use techniques from film animation to instruct the robot to move.
This article is a systematic literature review of human-robot trials, pilots,
and evaluations that have applied techniques from animation to move a robot.
Through 27 articles, we find that animation techniques improves individual's
interaction with robots, improving individual's perception of qualities of a
robot, understanding what a robot intends to do, and showing the robot's state,
or possible emotion. Animation techniques also help people relate to robots
that do not resemble a human or robot. The studies in the articles show further
areas for research, such as applying animation principles in other types of
robots and situations, combining animation techniques with other modalities,
and testing robots moving with animation techniques over the long term.
","['Trenton Schulz', 'Jim Torresen', 'Jo Herstad']"
http://arxiv.org/abs/1904.03049v2,Robotics,2019-04-05T13:17:27Z,2019-09-08T09:23:21Z,Loosely Coupled Payload Transport System with Robot Replacement,"  In this work, we present an algorithm for robot replacement to increase the
operational time of a multi-robot payload transport system. Our system
comprises a group of nonholonomic wheeled mobile robots traversing on a known
trajectory. We design a multi-robot system with loosely coupled robots that
ensures the system lasts much longer than the battery life of an individual
robot. A system level optimization is presented, to decide on the operational
state (charging or discharging) of each robot in the system. The charging state
implies that the robot is not in a formation and is kept on charge whereas the
discharging state implies that the robot is a part of the formation. Robot
battery recharge hubs are present along the trajectory. Robots in the formation
can be replaced at these hub locations with charged robots using a replacement
mechanism. We showcase the efficacy of the proposed scheduling framework
through simulations and experiments with real robots.
","['Pulkit Verma', 'Rahul Tallamraju', 'Abhay Rawat', 'Subhasis Chand', 'Kamalakar Karlapalem']"
http://arxiv.org/abs/1909.05777v1,Robotics,2019-09-12T16:16:21Z,2019-09-12T16:16:21Z,Robots that Take Advantage of Human Trust,"  Humans often assume that robots are rational. We believe robots take optimal
actions given their objective; hence, when we are uncertain about what the
robot's objective is, we interpret the robot's actions as optimal with respect
to our estimate of its objective. This approach makes sense when robots
straightforwardly optimize their objective, and enables humans to learn what
the robot is trying to achieve. However, our insight is that---when robots are
aware that humans learn by trusting that the robot actions are
rational---intelligent robots do not act as the human expects; instead, they
take advantage of the human's trust, and exploit this trust to more efficiently
optimize their own objective. In this paper, we formally model instances of
human-robot interaction (HRI) where the human does not know the robot's
objective using a two-player game. We formulate different ways in which the
robot can model the uncertain human, and compare solutions of this game when
the robot has conservative, optimistic, rational, and trusting human models. In
an offline linear-quadratic case study and a real-time user study, we show that
trusting human models can naturally lead to communicative robot behavior, which
influences end-users and increases their involvement.
","['Dylan P. Losey', 'Dorsa Sadigh']"
http://arxiv.org/abs/1701.07790v2,Robotics,2017-01-26T17:45:47Z,2017-04-06T02:26:42Z,Game-Theoretic Modeling of Human Adaptation in Human-Robot Collaboration,"  In human-robot teams, humans often start with an inaccurate model of the
robot capabilities. As they interact with the robot, they infer the robot's
capabilities and partially adapt to the robot, i.e., they might change their
actions based on the observed outcomes and the robot's actions, without
replicating the robot's policy. We present a game-theoretic model of human
partial adaptation to the robot, where the human responds to the robot's
actions by maximizing a reward function that changes stochastically over time,
capturing the evolution of their expectations of the robot's capabilities. The
robot can then use this model to decide optimally between taking actions that
reveal its capabilities to the human and taking the best action given the
information that the human currently has. We prove that under certain
observability assumptions, the optimal policy can be computed efficiently. We
demonstrate through a human subject experiment that the proposed model
significantly improves human-robot team performance, compared to policies that
assume complete adaptation of the human to the robot.
","['Stefanos Nikolaidis', 'Swaprava Nath', 'Ariel D. Procaccia', 'Siddhartha Srinivasa']"
http://arxiv.org/abs/2207.01684v1,Robotics,2022-07-04T19:26:13Z,2022-07-04T19:26:13Z,"Robot Vitals and Robot Health: Towards Systematically Quantifying
  Runtime Performance Degradation in Robots Under Adverse Conditions","  This paper addresses the problem of automatically detecting and quantifying
performance degradation in remote mobile robots during task execution. A robot
may encounter a variety of uncertainties and adversities during task execution,
which can impair its ability to carry out tasks effectively and cause its
performance to degrade. Such situations can be mitigated or averted by timely
detection and intervention (e.g., by a remote human supervisor taking over
control in teleoperation mode). Inspired by patient triaging systems in
hospitals, we introduce the framework of ""robot vitals"" for estimating overall
""robot health"". A robot's vitals are a set of indicators that estimate the
extent of performance degradation faced by a robot at a given point in time.
Robot health is a metric that combines robot vitals into a single scalar value
estimate of performance degradation. Experiments, both in simulation and on a
real mobile robot, demonstrate that the proposed robot vitals and robot health
can be used effectively to estimate robot performance degradation during
runtime.
","['Aniketh Ramesh', 'Rustam Stolkin', 'Manolis Chiou']"
http://arxiv.org/abs/2309.02979v1,Robotics,2023-09-06T13:24:45Z,2023-09-06T13:24:45Z,"Come Closer: The Effects of Robot Personality on Human Proxemics
  Behaviours","  Social Robots in human environments need to be able to reason about their
physical surroundings while interacting with people. Furthermore, human
proxemics behaviours around robots can indicate how people perceive the robots
and can inform robot personality and interaction design. Here, we introduce
Charlie, a situated robot receptionist that can interact with people using
verbal and non-verbal communication in a dynamic environment, where users might
enter or leave the scene at any time. The robot receptionist is stationary and
cannot navigate. Therefore, people have full control over their personal space
as they are the ones approaching the robot. We investigated the influence of
different apparent robot personalities on the proxemics behaviours of the
humans. The results indicate that different types of robot personalities,
specifically introversion and extroversion, can influence human proxemics
behaviours. Participants maintained shorter distances with the introvert robot
receptionist, compared to the extrovert robot. Interestingly, we observed that
human-robot proxemics were not the same as typical human-human interpersonal
distances, as defined in the literature. We therefore propose new proxemics
zones for human-robot interaction.
","['Meriam Moujahid', 'David A. Robb', 'Christian Dondrup', 'Helen Hastie']"
http://arxiv.org/abs/2502.01256v1,Robotics,2025-02-03T11:26:32Z,2025-02-03T11:26:32Z,Soft is Safe: Human-Robot Interaction for Soft Robots,"  With the presence of robots increasing in the society, the need for
interacting with robots is becoming necessary. The field of Human-Robot
Interaction (HRI) has emerged important since more repetitive and tiresome jobs
are being done by robots. In the recent times, the field of soft robotics has
seen a boom in the field of research and commercialization. The Industry 5.0
focuses on human robot collaboration which also spurs the field of soft
robotics. However the HRI for soft robotics is still in the nascent stage. In
this work we review and then discuss how HRI is done for soft robots. We first
discuss the control, design, materials and manufacturing of soft robots. This
will provide an understanding of what is being interacted with. Then we discuss
about the various input and output modalities that are used in HRI. The
applications where the HRI for soft robots are found in the literature are
discussed in detail. Then the limitations of HRI for soft robots and various
research opportunities that exist in this field are discussed in detail. It is
concluded that there is a huge scope for development for HRI for soft robots.
","['Rajashekhar V S', 'Gowdham Prabhakar']"
http://arxiv.org/abs/2211.05572v1,Robotics,2022-10-24T13:26:18Z,2022-10-24T13:26:18Z,Modular Robots: extending the capabilities of one robot,"  For a robot to be perfect and enter the everyday life of humans,like
computers did, it needs to move from special-purpose robots to general-purpose.
So, the idea of modularity is considered in this project.Thus, any type of task
that falls in the 4 D's of Robotization: Dull, Dirty, Dangerous and Dear can be
achieved by adding a module to the robot.
","['Aymen Rachdi', 'Fedi Zrelli', 'Amine Kammmoun']"
http://arxiv.org/abs/1610.04080v2,Robotics,2016-10-13T13:58:59Z,2016-12-08T13:26:59Z,Cuspidal Robots,"  This chapter is dedicated to the so-called cuspidal robots, i.e. those robots
that can move from one inverse geometric solution to another without meeting a
singular confuguration. This feature was discovered quite recently and has then
been fascinating a lot of researchers. After a brief history of cuspidal
robots, the chapter provides the main features of cuspidal robots: explanation
of the non-singular change of posture, uniqueness domains, regions of feasible
paths, identification and classification of cuspidal robots. The chapter
focuses on 3-R orthogonal serial robots. The case of 6-dof robots and parallel
robots is discussed in the end of this chapter.
",['Philippe Wenger']
http://arxiv.org/abs/1805.03737v2,Robotics,2018-05-09T21:24:50Z,2019-01-27T13:42:51Z,Graph Neural Networks for Learning Robot Team Coordination,"  This paper shows how Graph Neural Networks can be used for learning
distributed coordination mechanisms in connected teams of robots. We capture
the relational aspect of robot coordination by modeling the robot team as a
graph, where each robot is a node, and edges represent communication links.
During training, robots learn how to pass messages and update internal states,
so that a target behavior is reached. As a proxy for more complex problems,
this short paper considers the problem where each robot must locally estimate
the algebraic connectivity of the team's network topology.
",['Amanda Prorok']
http://arxiv.org/abs/1808.01666v1,Robotics,2018-08-05T18:26:34Z,2018-08-05T18:26:34Z,On Robot Revolution and Taxation,"  Advances in artificial intelligence are resulting in the rapid automation of
the work force. The tools that are used to automate are called robots. Bill
Gates proposed that in order to deal with the problem of the loss of jobs and
reduction of the tax revenue we ought to tax the robots. The problem with
taxing the robots is that it is not easy to know what a robot is. This article
studies the definition of a robot and the implication of advances in robotics
on taxation. It is evident from this article that it is a difficult task to
establish what a robot is and what is not a robot. It concludes that taxing
robots is the same as increasing corporate tax.
",['Tshilidzi Marwala']
http://arxiv.org/abs/2304.06568v1,Smart contracts,2023-04-13T14:26:12Z,2023-04-13T14:26:12Z,"Smart Contract Upgradeability on the Ethereum Blockchain Platform: An
  Exploratory Study","  Context: Smart contracts are computerized self-executing contracts that
contain clauses, which are enforced once certain conditions are met. Smart
contracts are immutable by design and cannot be modified once deployed, which
ensures trustlessness. Despite smart contracts' immutability benefits,
upgrading contract code is still necessary for bug fixes and potential feature
improvements. In the past few years, the smart contract community introduced
several practices for upgrading smart contracts. Upgradeable contracts are
smart contracts that exhibit these practices and are designed with
upgradeability in mind. During the upgrade process, a new smart contract
version is deployed with the desired modification, and subsequent user requests
will be forwarded to the latest version (upgraded contract). Nevertheless,
little is known about the characteristics of the upgrading practices, how
developers apply them, and how upgrading impacts contract usage.
  Objectives: This paper aims to characterize smart contract upgrading patterns
and analyze their prevalence based on the deployed contracts that exhibit these
patterns. Furthermore, we intend to investigate the reasons why developers
upgrade contracts (e.g., introduce features, fix vulnerabilities) and how
upgrades affect the adoption and life span of a contract in practice.
  Method: We collect deployed smart contracts metadata and source codes to
identify contracts that exhibit certain upgrade patterns (upgradeable
contracts) based on a set of policies. Then we trace smart contract versions
for each upgradable contract and identify the changes in contract versions
using similarity and vulnerabilities detection tools. Finally, we plan to
analyze the impact of upgrading on contract usage based on the number of
transactions received and the lifetime of the contract version.
","['Ilham Qasse', 'Mohammad Hamdaqa', 'Björn Þór Jónsson']"
http://arxiv.org/abs/1912.04780v2,Smart contracts,2019-12-10T15:52:52Z,2019-12-24T09:04:27Z,Testing Smart Contracts Gets Smarter,"  Smart contracts are immutable, verifiable, and autonomous pieces of code that
can be deployed and ran on blockchain networks like Ethereum. Due to the
immutability nature of blockchain, no change is possible on a deployed smart
contract or a verified transaction. On the other hand, there are millions of
dollars carried by smart contracts in Ethereum blockchain, and hence, a faulty
smart contract can lead to a huge monetary loss. Therefore, it is important for
smart contract developers to fully test and check the correctness of their code
before deploying it on the blockchain. In this paper, we propose a testing
mechanism for smart contracts in Solidity language, based on mutation testing.
We analyzed a comprehensive list of known bugs in Solidity smart contracts, and
designed 10 classes of mutation operators inspired by the real faults. Our
experimental results show that our proposed mutation operators can regenerate
10 of 15 famous faulty smart contracts, which have resulted in millions of
dollars loss. The results show the effectiveness of our proposed mutation
operators in detecting real faults in Solidity smart contracts. We have also
extended {\em Universal Mutator } tool with our mutation operators, so that it
can automatically generate mutants for smart contracts written in Solidity.
","['Erfan Andesta', 'Fathiyeh Faghih', 'Mahdi Fooladgar']"
http://arxiv.org/abs/2001.10589v1,Smart contracts,2020-01-21T03:48:46Z,2020-01-21T03:48:46Z,"Blockchain Enabled Smart Contract Based Applications: Deficiencies with
  the Software Development Life Cycle Models","  With the recent popularity of Blockchain and other Distributed Ledger
Technologies (DLT), blockchain enabled smart contract applications has
attracted increased research focus. However, the immutability of the blocks,
where the smart contracts are stored, causes conflicts with the traditional
Software Development Life Cycle (SDLC) models usually followed by software
engineers. This clearly shows the unsuitability of the application of SDLC in
designing blockchain enabled smart contract based applications. This research
article addresses this current problem by first exploring the six traditional
SDLC models, clearly identifying the conflicts in a table with the application
of smart contracts and advocates that there is an urgent need to develop new
standard model(s) to address the arising issues. The concept of both block
immutability and contract is introduced. This is further set in a historical
context from legacy smart contracts and blockchain enabled smart contracts
extending to the difference between ""shallow smart contracts"" and ""deep smart
contracts"". To conclude, the traditional SDLC models are unsuitable for
blockchain enabled smart contract-based applications.
","['Mahdi H. Miraz', 'Maaruf Ali']"
http://arxiv.org/abs/1912.10370v1,Smart contracts,2019-12-22T01:52:54Z,2019-12-22T01:52:54Z,"An Overview on Smart Contracts: Challenges, Advances and Platforms","  Smart contract technology is reshaping conventional industry and business
processes. Being embedded in blockchains, smart contracts enable the
contractual terms of an agreement to be enforced automatically without the
intervention of a trusted third party. As a result, smart contracts can cut
down administration and save services costs, improve the efficiency of business
processes and reduce the risks. Although smart contracts are promising to drive
the new wave of innovation in business processes, there are a number of
challenges to be tackled.This paper presents a survey on smart contracts. We
first introduce blockchains and smart contracts. We then present the challenges
in smart contracts as well as recent technical advances. We also compare
typical smart contract platforms and give a categorization of smart contract
applications along with some representative examples.
","['Zibin Zheng', 'Shaoan Xie', 'Hong-Ning Dai', 'Weili Chen', 'Xiangping Chen', 'Jian Weng', 'Muhammad Imran']"
http://arxiv.org/abs/2101.08964v1,Smart contracts,2021-01-22T06:24:08Z,2021-01-22T06:24:08Z,Probabilistic Framework For Loss Distribution Of Smart Contract Risk,"  Smart contract risk can be defined as a financial risk of loss due to cyber
attacks on or contagious failures of smart contracts. Its quantification is of
paramount importance to technology platform providers as well as companies and
individuals when considering the deployment of this new technology. That is
why, as our primary contribution, we propose a structural framework of
aggregate loss distribution for smart contract risk under the assumption of a
tree-stars graph topology representing the network of interactions among smart
contracts and their users. Up to our knowledge, there exist no theoretical
frameworks or models of an aggregate loss distribution for smart contracts in
this setting. To achieve our goal, we contextualize the problem in the
probabilistic graph-theoretical framework using bond percolation models. We
assume that the smart contract network topology is represented by a random tree
graph of finite size, and that each smart contract is the center of a {random}
star graph whose leaves represent the users of the smart contract. We allow for
heterogeneous loss topology superimposed on this smart contract and user
topology and provide analytical results and instructive numerical examples.
","['Petar Jevtic', 'Nicolas Lanchier']"
http://arxiv.org/abs/2505.22619v1,Smart contracts,2025-05-28T17:40:21Z,2025-05-28T17:40:21Z,Smart Contracts for SMEs and Large Companies,"  Research on blockchains addresses multiple issues, with one being writing
smart contracts. In our previous research we described methodology and a tool
to generate, in automated fashion, smart contracts from BPMN models. The
generated smart contracts provide support for multi-step transactions that
facilitate repair/upgrade of smart contracts. In this paper we show how the
approach is used to support collaborations via smart contracts for companies
ranging from SMEs with little IT capabilities to companies with IT using
blockchain smart contracts. Furthermore, we also show how the approach is used
for certain applications to generate smart contracts by a BPMN modeler who does
not need any knowledge of blockchain technology or smart contract development -
thus we are hoping to facilitate democratization of smart contracts and
blockchain technology.
","['C. G. Liu', 'P. Bodorik', 'D. Jutla']"
http://arxiv.org/abs/1702.04467v1,Smart contracts,2017-02-15T05:38:37Z,2017-02-15T05:38:37Z,Adding Concurrency to Smart Contracts,"  Modern cryptocurrency systems, such as Ethereum, permit complex financial
transactions through scripts called smart contracts. These smart contracts are
executed many, many times, always without real concurrency. First, all smart
contracts are serially executed by miners before appending them to the
blockchain. Later, those contracts are serially re-executed by validators to
verify that the smart contracts were executed correctly by miners.
  Serial execution limits system throughput and fails to exploit today's
concurrent multicore and cluster architectures. Nevertheless, serial execution
appears to be required: contracts share state, and contract programming
languages have a serial semantics.
  This paper presents a novel way to permit miners and validators to execute
smart contracts in parallel, based on techniques adapted from software
transactional memory. Miners execute smart contracts speculatively in parallel,
allowing non-conflicting contracts to proceed concurrently, and ""discovering"" a
serializable concurrent schedule for a block's transactions, This schedule is
captured and encoded as a deterministic fork-join program used by validators to
re-execute the miner's parallel schedule deterministically but concurrently.
  Smart contract benchmarks run on a JVM with ScalaSTM show that a speedup of
of 1.33x can be obtained for miners and 1.69x for validators with just three
concurrent threads.
","['Thomas Dickerson', 'Paul Gazzillo', 'Maurice Herlihy', 'Eric Koskinen']"
http://arxiv.org/abs/1905.01467v3,Smart contracts,2019-05-04T09:58:49Z,2020-04-17T05:18:51Z,Defining Smart Contract Defects on Ethereum,"  Smart contracts are programs running on a blockchain. They are immutable to
change, and hence can not be patched for bugs once deployed. Thus it is
critical to ensure they are bug-free and well-designed before deployment. A
Contract defect is an error, flaw or fault in a smart contract that causes it
to produce an incorrect or unexpected result, or to behave in unintended ways.
The detection of contract defects is a method to avoid potential bugs and
improve the design of existing code. Since smart contracts contain numerous
distinctive features, such as the gas system. decentralized, it is important to
find smart contract specified defects. To fill this gap, we collected
smart-contract-related posts from Ethereum StackExchange, as well as real-world
smart contracts. We manually analyzed these posts and contracts; using them to
define 20 kinds of contract defects. We categorized them into indicating
potential security, availability, performance, maintainability and reusability
problems. To validate if practitioners consider these contract as harmful, we
created an online survey and received 138 responses from 32 different
countries. Feedback showed these contract defects are harmful and removing them
would improve the quality and robustness of smart contracts. We manually
identified our defined contract defects in 587 real world smart contract and
publicly released our dataset. Finally, we summarized 5 impacts caused by
contract defects. These help developers better understand the symptoms of the
defects and removal priority.
","['Jiachi Chen', 'Xin Xia', 'David Lo', 'John Grundy', 'Daniel Xiapu Luo', 'Ting Chen']"
http://arxiv.org/abs/2009.02663v2,Smart contracts,2020-09-06T07:38:45Z,2021-03-23T03:02:43Z,"DEFECTCHECKER: Automated Smart Contract Defect Detection by Analyzing
  EVM Bytecode","  Smart contracts are Turing-complete programs running on the blockchain. They
are immutable and cannot be modified, even when bugs are detected. Therefore,
ensuring smart contracts are bug-free and well-designed before deploying them
to the blockchain is extremely important. A contract defect is an error, flaw
or fault in a smart contract that causes it to produce an incorrect or
unexpected result, or to behave in unintended ways. Detecting and removing
contract defects can avoid potential bugs and make programs more robust. Our
previous work defined 20 contract defects for smart contracts and divided them
into five impact levels. According to our classification, contract defects with
seriousness level between 1-3 can lead to unwanted behaviors, e.g., a contract
being controlled by attackers. In this paper, we propose DefectChecker, a
symbolic execution-based approach and tool to detect eight contract defects
that can cause unwanted behaviors of smart contracts on the Ethereum blockchain
platform. DefectChecker can detect contract defects from smart contracts
bytecode. We compare DefectChecker with key previous works, including Oyente,
Mythril and Securify by using an open-source dataset. Our experimental results
show that DefectChecker performs much better than these tools in terms of both
speed and accuracy. We also applied DefectChecker to 165,621 distinct smart
contracts on the Ethereum platform. We found that 25,815 of these smart
contracts contain at least one of the contract defects that belongs to impact
level 1-3, including some real-world attacks.
","['Jiachi Chen', 'Xin Xia', 'David Lo', 'John Grundy', 'Xiapu Luo', 'Ting Chen']"
http://arxiv.org/abs/2009.02066v1,Smart contracts,2020-09-04T08:37:58Z,2020-09-04T08:37:58Z,A Framework and DataSet for Bugs in Ethereum Smart Contracts,"  Ethereum is the largest blockchain platform that supports smart contracts.
Users deploy smart contracts by publishing the smart contract's bytecode to the
blockchain. Since the data in the blockchain cannot be modified, even if these
contracts contain bugs, it is not possible to patch deployed smart contracts
with code updates. Moreover, there is currently neither a comprehensive
classification framework for Ethereum smart contract bugs, nor detailed
criteria for detecting bugs in smart contracts, making it difficult for
developers to fully understand the negative effects of bugs and design new
approaches to detect bugs. In this paper, to fill the gap, we first collect as
many smart contract bugs as possible from multiple sources and divide these
bugs into 9 categories by extending the IEEE Standard Classification for
Software Anomalies. Then, we design the criteria for detecting each kind of
bugs, and construct a dataset of smart contracts covering all kinds of bugs.
With our framework and dataset, developers can learn smart contract bugs and
develop new tools to detect and locate bugs in smart contracts. Moreover, we
evaluate the state-of-the-art tools for smart contract analysis with our
dataset and obtain some interesting findings: 1) Mythril, Slither and Remix are
the most worthwhile combination of analysis tools. 2) There are still 10 kinds
of bugs that cannot be detected by any analysis tool.
","['Pengcheng Zhang', 'Feng Xiao', 'Xiapu Luo']"
http://arxiv.org/abs/2403.19805v2,Smart contracts,2024-03-28T19:36:53Z,2024-04-08T18:33:46Z,"Vulnerabilities of smart contracts and mitigation schemes: A
  Comprehensive Survey","  Ethereum smart contracts are highly powerful, immutable, and able to retain
massive amounts of tokens. However, smart contracts keep attracting attackers
to benefit from smart contract flaws and Ethereum unexpected behavior. Thus,
methodologies and tools have been proposed to help implement secure smart
contracts and to evaluate the security of smart contracts already deployed.
Most related surveys focus on tools without discussing the logic behind them.
in addition, they assess the tools based on papers rather than testing the
tools and collecting community feedback. Other surveys lack guidelines on how
to use tools specific to smart contract functionalities. This paper presents a
literature review combined with an experimental report that aims to assist
developers in developing secure smarts, with a novel emphasis on the challenges
and vulnerabilities introduced by NFT fractionalization by addressing the
unique risks of dividing NFT ownership into tradeable units called fractions.
It provides a list of frequent vulnerabilities and corresponding mitigation
solutions. In addition, it evaluates the community most widely used tools by
executing and testing them on sample smart contracts. Finally, a comprehensive
guide on implementing secure smart contracts is presented.
","['Wejdene Haouari', 'Abdelhakim Senhaji Hafid', 'Marios Fokaefs']"
http://arxiv.org/abs/1807.03932v2,Smart contracts,2018-07-11T02:32:54Z,2018-08-03T01:03:39Z,ContractFuzzer: Fuzzing Smart Contracts for Vulnerability Detection,"  Decentralized cryptocurrencies feature the use of blockchain to transfer
values among peers on networks without central agency. Smart contracts are
programs running on top of the blockchain consensus protocol to enable people
make agreements while minimizing trusts. Millions of smart contracts have been
deployed in various decentralized applications. The security vulnerabilities
within those smart contracts pose significant threats to their applications.
Indeed, many critical security vulnerabilities within smart contracts on
Ethereum platform have caused huge financial losses to their users. In this
work, we present ContractFuzzer, a novel fuzzer to test Ethereum smart
contracts for security vulnerabilities. ContractFuzzer generates fuzzing inputs
based on the ABI specifications of smart contracts, defines test oracles to
detect security vulnerabilities, instruments the EVM to log smart contracts
runtime behaviors, and analyzes these logs to report security vulnerabilities.
Our fuzzing of 6991 smart contracts has flagged more than 459 vulnerabilities
with high precision. In particular, our fuzzing tool successfully detects the
vulnerability of the DAO contract that leads to USD 60 million loss and the
vulnerabilities of Parity Wallet that have led to the loss of $30 million and
the freezing of USD 150 million worth of Ether.
","['Bo Jiang', 'Ye Liu', 'W. K. Chan']"
http://arxiv.org/abs/2005.11839v1,Smart contracts,2020-05-24T20:49:13Z,2020-05-24T20:49:13Z,"Tezla, an Intermediate Representation for Static Analysis of Michelson
  Smart Contracts","  This paper introduces Tezla, an intermediate representation of Michelson
smart contracts that eases the design of static smart contract analysers. This
intermediate representation uses a store and preserves the semantics, ow and
resource usage of the original smart contract. This enables properties like gas
consumption to be statically verified. We provide an automated decompiler of
Michelson smart contracts to Tezla. In order to support our claim about the
adequacy of Tezla, we develop a static analyser that takes advantage of the
Tezla representation of Michelson smart contracts to prove simple but
non-trivial properties.
","['João Santos Reis', 'Paul Crocker', 'Simão Melo de Sousa']"
http://arxiv.org/abs/2110.08983v1,Smart contracts,2021-10-18T02:25:54Z,2021-10-18T02:25:54Z,An Empirical Study of Protocols in Smart Contracts,"  Smart contracts are programs that are executed on a blockhain. They have been
used for applications in voting, decentralized finance, and supply chain
management. However, vulnerabilities in smart contracts have been abused by
hackers, leading to financial losses. Understanding state machine protocols in
smart contracts has been identified as important to catching common bugs,
improving documentation, and optimizing smart contracts. We analyze Solidity
smart contracts deployed on the Ethereum blockchain and study the prevalence of
protocols and protocol-based bugs, as well as opportunities for gas
optimizations.
","['Timothy Mou', 'Michael Coblenz', 'Jonathan Aldrich']"
http://arxiv.org/abs/1907.09208v1,Smart contracts,2019-07-22T10:03:23Z,2019-07-22T10:03:23Z,"Truffle tests for free -- Replaying Ethereum smart contracts for
  transparency","  The Ethereum blockchain is essentially a globally replicated public database.
Programs called smart contracts can access this database. Over 10 million smart
contracts have been deployed on the Ethereum blockchain. Executing a method of
a smart contract generates a transaction that is also stored on the blockchain.
There are over 1 billion Ethereum transactions to date. Smart contracts that
are transparent about their function are more successful than opaque contracts.
We have therefore developed a tool (ContractVis) to explore the transparency of
smart contracts. The tool generates a replay script for the historic
transactions of a smart contract. The script executes the transactions with the
same arguments as recorded on the blockchain, but in a minimal test
environment. Running a replay script provides insights into the contract, and
insights into the blockchain explorer that was used to retrieve the contract
and its history. We provide five concrete recommendations for blockchain
explorers like Etherscan to improve the transparency of smart contracts.
","['Pieter Hartel', 'Mark van Staalduinen']"
http://arxiv.org/abs/2412.20866v1,Smart contracts,2024-12-30T11:10:22Z,2024-12-30T11:10:22Z,"An Infrastructure for Systematically Collecting Smart Contract Lineages
  for Analyses","  Tracking the evolution of smart contracts is a significant challenge,
impeding on the advancement of research on smart contract analysis. Indeed, due
to the inherent immutability of the underlying blockchain technology, each
smart contract update results in a deployment at a new address, breaking the
links between versions. Existing platforms like Etherscan lack the capability
to trace the predecessor-successor relationships within a smart contract
lineage, further hindering empirical research on contract evolution.
  We address this challenge for the research community towards building a
reliable dataset of linked versions for various smart contracts, i.e.,
lineages: we introduce SCLineage, an automated infrastructure that accurately
identifies and collects smart contract lineages by leveraging proxy contracts.
We present SCLineageSet, an up-to-date, open-source dataset that facilitates
extensive research on smart contract evolution. We illustrate the applicability
of our proposal in software engineering research through a case study that
explores the evaluation of Locality-Sensitive Hashing (LSH) for forming
contract lineages. This example underscores how SCLineage provides valuable
insights for future research in the field.
","['Fatou Ndiaye Mbodji', 'Vinny Adjibi', 'Gervais Mendy', 'Moustapha Awwalou Diouf', 'Jacques Klein', 'Tegawende Bissyande']"
http://arxiv.org/abs/2207.13827v1,Smart contracts,2022-07-27T23:36:22Z,2022-07-27T23:36:22Z,Declarative Smart Contracts,"  This paper presents DeCon, a declarative programming language for
implementing smart contracts and specifying contract-level properties. Driven
by the observation that smart contract operations and contract-level properties
can be naturally expressed as relational constraints, DeCon models each smart
contract as a set of relational tables that store transaction records. This
relational representation of smart contracts enables convenient specification
of contract properties, facilitates run-time monitoring of potential property
violations, and brings clarity to contract debugging via data provenance.
Specifically, a DeCon program consists of a set of declarative rules and
violation query rules over the relational representation, describing the smart
contract implementation and contract-level properties, respectively. We have
developed a tool that can compile DeCon programs into executable Solidity
programs, with instrumentation for run-time property monitoring. Our case
studies demonstrate that DeCon can implement realistic smart contracts such as
ERC20 and ERC721 digital tokens. Our evaluation results reveal the marginal
overhead of DeCon compared to the open-source reference implementation,
incurring 14% median gas overhead for execution, and another 16% median gas
overhead for run-time verification.
","['Haoxian Chen', 'Gerald Whitters', 'Mohammad Javad Amiri', 'Yuepeng Wang', 'Boon Thau Loo']"
http://arxiv.org/abs/2307.00549v1,Smart contracts,2023-07-02T12:05:43Z,2023-07-02T12:05:43Z,"Abusing the Ethereum Smart Contract Verification Services for Fun and
  Profit","  Smart contracts play a vital role in the Ethereum ecosystem. Due to the
prevalence of kinds of security issues in smart contracts, the smart contract
verification is urgently needed, which is the process of matching a smart
contract's source code to its on-chain bytecode for gaining mutual trust
between smart contract developers and users. Although smart contract
verification services are embedded in both popular Ethereum browsers (e.g.,
Etherscan and Blockscout) and official platforms (i.e., Sourcify), and gain
great popularity in the ecosystem, their security and trustworthiness remain
unclear. To fill the void, we present the first comprehensive security analysis
of smart contract verification services in the wild. By diving into the
detailed workflow of existing verifiers, we have summarized the key security
properties that should be met, and observed eight types of vulnerabilities that
can break the verification. Further, we propose a series of detection and
exploitation methods to reveal the presence of vulnerabilities in the most
popular services, and uncover 19 exploitable vulnerabilities in total. All the
studied smart contract verification services can be abused to help spread
malicious smart contracts, and we have already observed the presence of using
this kind of tricks for scamming by attackers. It is hence urgent for our
community to take actions to detect and mitigate security issues related to
smart contract verification, a key component of the Ethereum smart contract
ecosystem.
","['Pengxiang Ma', 'Ningyu He', 'Yuhua Huang', 'Haoyu Wang', 'Xiapu Luo']"
http://arxiv.org/abs/1710.06372v1,Smart contracts,2017-10-17T16:39:23Z,2017-10-17T16:39:23Z,Blockchain-based Smart Contracts: A Systematic Mapping Study,"  An appealing feature of blockchain technology is smart contracts. A smart
contract is executable code that runs on top of the blockchain to facilitate,
execute and enforce an agreement between untrusted parties without the
involvement of a trusted third party. In this paper, we conduct a systematic
mapping study to collect all research that is relevant to smart contracts from
a technical perspective. The aim of doing so is to identify current research
topics and open challenges for future studies in smart contract research. We
extract 24 papers from different scientific databases. The results show that
about two thirds of the papers focus on identifying and tackling smart contract
issues. Four key issues are identified, namely, codifying, security, privacy
and performance issues. The rest of the papers focuses on smart contract
applications or other smart contract related topics. Research gaps that need to
be addressed in future studies are provided.
","['Maher Alharby', 'Aad van Moorsel']"
http://arxiv.org/abs/1909.06494v1,Smart contracts,2019-09-14T00:36:13Z,2019-09-14T00:36:13Z,Transactional Smart Contracts in Blockchain Systems,"  This paper presents TXSC, a framework that provides smart contract developers
with transaction primitives. These primitives allow developers to write smart
contracts without the need to reason about the anomalies that can arise due to
concurrent smart contract function executions.
","['Victor Zakhary', 'Divyakant Agrawal', 'Amr El Abbadi']"
