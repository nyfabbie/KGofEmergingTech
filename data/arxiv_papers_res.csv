id,technology,published,updated,title,summary,authors
http://arxiv.org/abs/2406.04641v1,3D printing,2024-06-07T04:56:05Z,2024-06-07T04:56:05Z,"Preparation of high precision aspherical lenses based on micro
  stereolithography technology","  The 3D printing technology based on digital light processing (DLP) has
highlighted its powerful manufacturing capabilities for optical components.
However, the printing structure obtained by DLP based down projection printing
is easily adhered to the printing window below, and the printed lens surface
will have a step effect. This article uses DLP 3D printing technology to print
non spherical lenses. During the printing process, a new type of inert liquid
fluoride solution was used as the isolation layer, which can more effectively
and conveniently prevent the printing structure from sticking to the printing
window. At the same time, a vertical lifting immersion method was proposed to
smooth the step effect on the surface of the lens.
","['Xiaoying Lu', 'Hua Liu']"
http://arxiv.org/abs/1405.0199v1,3D printing,2014-02-25T04:43:22Z,2014-02-25T04:43:22Z,"Liquid Phase 3D Printing for Quickly Manufacturing Metal Objects with
  Low Melting Point Alloy Ink","  Conventional 3D printings are generally time-consuming and printable metal
inks are rather limited. From an alternative way, we proposed a liquid phase 3D
printing for quickly making metal objects. Through introducing metal alloys
whose melting point is slightly above room temperature as printing inks,
several representative structures spanning from one, two and three dimension to
more complex patterns were demonstrated to be quickly fabricated. Compared with
the air cooling in a conventional 3D printing, the liquid-phase-manufacturing
offers a much higher cooling rate and thus significantly improves the speed in
fabricating metal objects. This unique strategy also efficiently prevents the
liquid metal inks from air oxidation which is hard to avoid otherwise in an
ordinary 3D printing. Several key physical factors (like properties of the
cooling fluid, injection speed and needle diameter, types and properties of the
printing ink, etc.) were disclosed which would evidently affect the printing
quality. In addition, a basic route to make future liquid phase 3D printer
incorporated with both syringe pump and needle arrays was also suggested. The
liquid phase 3D printing method, which owns potential values not available in a
conventional modality, opens an efficient way for quickly making metal objects
in the coming time.
","['Lei Wang', 'Jing Liu']"
http://arxiv.org/abs/2202.11426v2,3D printing,2022-02-23T11:14:24Z,2022-03-29T16:06:20Z,Open5x: Accessible 5-axis 3D printing and conformal slicing,"  The common layer-by-layer deposition of regular, 3-axis 3D printing
simplifies both the fabrication process and the 3D printer's mechanical design.
However, the resulting 3D printed objects have some unfavourable
characteristics including visible layers, uneven structural strength and
support material. To overcome these, researchers have employed robotic arms and
multi-axis CNCs to deposit materials in conformal layers. Conformal deposition
improves the quality of the 3D printed parts through support-less printing and
curved layer deposition. However, such multi-axis 3D printing is inaccessible
to many individuals due to high costs and technical complexities. Furthermore,
the limited GUI support for conformal slicers creates an additional barrier for
users. To open multi-axis 3D printing up to more makers and researchers, we
present a cheap and accessible way to upgrade a regular 3D printer to 5 axes.
We have also developed a GUI-based conformal slicer, integrated within a
popular CAD package. Together, these deliver an accessible workflow for
designing, simulating and creating conformally-printed 3D models.
","['Freddie Hong', 'Steve Hodges', 'Connor Myant', 'David Boyle']"
http://arxiv.org/abs/2401.11778v1,3D printing,2024-01-22T09:17:24Z,2024-01-22T09:17:24Z,All Inkjet-printed Organic Solar Cells on 3D Objects,"  Drop-on-demand inkjet printing is a promising and commercially relevant
technology for producing organic electronic devices of arbitrary shape on a
wide variety of different substrates. In this work we transfer the inkjet
printing process of organic photovoltaic devices from 2D to 3D substrates,
using a 5-axis robot system equipped with a multi nozzle inkjet printing unit.
We present a ready-to-use 3D printing system for industrial application, using
a 5-axis motion system controlled by commercial 3D motion software, combined
with a commonly used multi-nozzle inkjet print head controlled by the
corresponding printing software. The very first time inkjet-printed solar cells
on glass/ITO with power conversion efficiencies (PCE) of up to 7% are realized
on a 3D object with surfaces tilted by angles of up to 60{\deg} against the
horizontal direction. Undesired ink flow during deposition of the
inkjet-printed layers was avoided by proper ink formulation. In order to be
able to print organic (opto-)electronic devices also on substrates without
sputtered indium tin oxide bottom electrode, the bottom electrode was
inkjet-printed from silver nanoparticle (AgNP) ink, resulting in the first all
inkjet-printed (i.e., including bottom electrode) solar cell on a 3D object
ever with a record PCE of 2.5%. This work paves the way for functionalizing
even complex objects, such as cars, mobile phones, or Internet of Things (IoT)
applications with inkjet-printed (opto-)electronic devices.
","['Marc Steinberger', 'Andreas Distler', 'Johannes Hörber', 'Kai Cheong Tam', 'Christoph J. Brabec', 'Hans-Joachim Egelhaaf']"
http://arxiv.org/abs/2305.09394v1,3D printing,2023-05-16T12:28:15Z,2023-05-16T12:28:15Z,"3D Printing and Design in Isolation: A Case from a Simulated Lunar
  Mission","  Despite the decades-long history of 3D printing, it is not used to its full
potential. Yet 3D printing holds promise for isolated communities, aiming for
self-sufficiency. In this experiential study conducted in an analog space
habitat we evaluated challenges and opportunities of using 3D printing. Our
study revealed barriers such as: 1) setting up and maintaining the 3D printing
equipment while minding different kinds of pollution, that is air, temperature
and sound, 2) design skill and familiarity with specialized software as well as
materials and 3) the awareness of what can be achieved to meet community needs.
We observed that in-community experience and know-how are reliable sources of
3D print ideas, that improve quality of life of community members if they are
encouraged and supported by participatory design. Co-design of 3D prints in
small, specialized communities is a promising area of study, that can bring new
applications of 3D print technology.
","['Wiktor Stawski', 'Kinga Skorupska', 'Wiesław Kopeć']"
http://arxiv.org/abs/2103.02063v1,3D printing,2021-03-02T22:25:34Z,2021-03-02T22:25:34Z,A 3D Printing Hexacopter: Design and Demonstration,"  3D printing using robots has garnered significant interest in manufacturing
and construction in recent years. A robot's versatility paired with the design
freedom of 3D printing offers promising opportunities for how parts and
structures are built in the future. However, 3D printed objects are still
limited in size and location due to a lack of vertical mobility of ground
robots. These limitations severely restrict the potential of the 3D printing
process. To overcome these limitations, we develop a hexacopter testbed that
can print via fused deposition modeling during flight. We discuss the design of
this testbed and develop a simple control strategy for initial print tests. By
successfully performing these initial print tests, we demonstrate the
feasibility of this approach and lay the groundwork for printing 3D parts and
structures with drones.
","['Alexander Nettekoven', 'Ufuk Topcu']"
http://arxiv.org/abs/2105.10943v1,3D printing,2021-05-23T14:25:34Z,2021-05-23T14:25:34Z,4D printing of mechanical metamaterials,"  Mechanical metamaterials owe their extraordinary properties and
functionalities to their micro-/nanoscale design of which shape, including both
geometry and topology, is perhaps the most important aspect. 4D printing
enables programmed, predictable, and precise change in the shape of mechanical
metamaterials to achieve multi-functionality, adaptive properties, and the
other types of desired behaviors that cannot be achieved using simple 3D
printing. This paper presents an overview of 4D printing as applied to
mechanical metamaterials. It starts by presenting a systematic definition of
what 4D printing is and what shape aspects (e.g., geometry, topology) are
relevant for the 4D printing of mechanical metamaterials. Instead of focusing
on different printing processes and materials, the paper addresses the most
fundamental aspects of the shapeshifting behaviors required for transforming a
flat construct to a target 3D shape (i.e., 2D to 3D shapeshifting) or
transforming a 3D shape to another 3D shape (i.e., 3D to 3D shapeshifting). In
either case, we will discuss the rigid-body shape morphing (e.g., rigid
origami) as well as deformable-body shapeshifting. The paper concludes with a
discussion of the major challenges ahead of us for applying 4D printing to
mechanical metamaterials and suggests several areas for future research.
",['Amir A. Zadpoor']
http://arxiv.org/abs/2403.16470v1,3D printing,2024-03-25T06:52:26Z,2024-03-25T06:52:26Z,Data-Driven Extrusion Force Control Tuning for 3D Printing,"  The quality of 3D prints often varies due to different conditions inherent to
each print, such as filament type, print speed, and nozzle size. Closed-loop
process control methods improve the accuracy and repeatability of 3D prints.
However, optimal tuning of controllers for given process parameters and design
geometry is often a challenge with manually tuned controllers resulting in
inconsistent and suboptimal results. This work employs Bayesian optimization to
identify the optimal controller parameters. Additionally, we explore transfer
learning in the context of 3D printing by leveraging prior information from
past trials. By integrating optimized extrusion force control and transfer
learning, we provide a novel framework for closed-loop 3D printing and propose
an automated calibration routine that produces high-quality prints for a
desired combination of print settings, material, and shape.
","['Xavier Guidetti', 'Ankita Mukne', 'Marvin Rueppel', 'Yannick Nagel', 'Efe C. Balta', 'John Lygeros']"
http://arxiv.org/abs/1705.05893v1,3D printing,2017-05-16T19:56:58Z,2017-05-16T19:56:58Z,"Computed Axial Lithography (CAL): Toward Single Step 3D Printing of
  Arbitrary Geometries","  Most additive manufacturing processes today operate by printing voxels (3D
pixels) serially point-by-point to build up a 3D part. In some more
recently-developed techniques, for example optical printing methods such as
projection stereolithography [Zheng et al. 2012], [Tumbleston et al. 2015],
parts are printed layer-by-layer by curing full 2d (very thin in one dimension)
layers of the 3d part in each print step. There does not yet exist a technique
which is able to print arbitrarily-defined 3D geometries in a single print
step. If such a technique existed, it could be used to expand the range of
printable geometries in additive manufacturing and relax constraints on factors
such as overhangs in topology optimization. It could also vastly increase print
speed for 3D parts. In this work, we develop the principles for an approach for
single exposure 3D printing of arbitrarily defined geometries. The approach,
termed Computed Axial Lithgography (CAL), is based on tomographic
reconstruction, with mathematical optimization to generate a set of projections
to optically define an arbitrary dose distribution within a target volume. We
demonstrate the potential ability of the technique to print 3D parts using a
prototype CAL system based on sequential illumination from many angles. We also
propose new hardware designs which will help us to realize true single-shot
arbitrary-geometry 3D CAL.
","['Brett Kelly', 'Indrasen Bhattacharya', 'Maxim Shusteff', 'Robert M. Panas', 'Hayden K. Taylor', 'Christopher M. Spadaccini']"
http://arxiv.org/abs/1406.4817v1,3D printing,2014-06-15T06:28:17Z,2014-06-15T06:28:17Z,3D Printing of Scintillating Materials,"  We demonstrate, for the first time, the applicability of 3D printing
technique to the manufacture of scintillation detectors. We report of a
formulation, usable in stereolithographic printing, that exhibits scintillation
efficiency on the order of 30\% of that of commercial polystyrene based
scintillators. We discuss the applicability of these techniques and propose
future enhancements that will allow tailoring the printed scintillation
detectors to various application.
","['Y. Mishnayot', 'M. Layani', 'I. Cooperstein', 'S. Magdassi', 'G. Ron']"
http://arxiv.org/abs/1809.07940v1,3D printing,2018-09-21T04:28:49Z,2018-09-21T04:28:49Z,"Printing-while-moving: a new paradigm for large-scale robotic 3D
  Printing","  Building and Construction have recently become an exciting application ground
for robotics. In particular, rapid progress in materials formulation and in
robotics technology has made robotic 3D Printing of concrete a promising
technique for in-situ construction. Yet, scalability remains an important
hurdle to widespread adoption: the printing systems (gantry- based or
arm-based) are often much larger than the structure to be printed, hence
cumbersome. Recently, a mobile printing system - a manipulator mounted on a
mobile base - was proposed to alleviate this issue: such a system, by moving
its base, can potentially print a structure larger than itself. However, the
proposed system could only print while being stationary, imposing thereby a
limit on the size of structures that can be printed in a single take. Here, we
develop a system that implements the printing-while-moving paradigm, which
enables printing single-piece structures of arbitrary sizes with a single
robot. This development requires solving motion planning, localization, and
motion control problems that are specific to mobile 3D Printing. We report our
framework to address those problems, and demonstrate, for the first time, a
printing-while-moving experiment, wherein a 210 cm x 45 cm x 10 cm concrete
structure is printed by a robot arm that has a reach of 87 cm.
","['Mehmet Efe Tiryaki', 'Xu Zhang', 'Quang-Cuong Pham']"
http://arxiv.org/abs/1806.00394v1,3D printing,2018-06-01T15:28:58Z,2018-06-01T15:28:58Z,3D Conductive Polymer Printed Metasurface Antenna for Fresnel Focusing,"  We demonstrate a 3D printed holographic metasurface antenna for beam-focusing
applications at 10 GHz within the X-band frequency regime. The metasurface
antenna is printed using a dual-material 3D printer leveraging a biodegradable
conductive polymer material (Electrifi) to print the conductive parts and
polylactic acid (PLA) to print the dielectric substrate. The entire metasurface
antenna is 3D printed at once; no additional techniques, such as metal-plating
and laser etching, are required. It is demonstrated that using the 3D printed
conductive polymer metasurface antenna, high-fidelity beam focusing can be
achieved within the Fresnel region of the antenna. It is also shown that the
material conductivity for 3D printing has a substantial effect on the radiation
characteristics of the metasurface antenna.
","['Okan Yurduseven', 'Shengrong Ye', 'Thomas Fromenteze', 'Daniel L. Marks', 'Benjamin J. Wiley', 'David R. Smith']"
http://arxiv.org/abs/2404.11776v1,3D printing,2024-04-17T21:57:29Z,2024-04-17T21:57:29Z,"3D object quality prediction for Metal Jet Printer with Multimodal
  thermal encoder","  With the advancements in 3D printing technologies, it is extremely important
that the quality of 3D printed objects, and dimensional accuracies should meet
the customer's specifications. Various factors during metal printing affect the
printed parts' quality, including the power quality, the printing stage
parameters, the print part's location inside the print bed, the curing stage
parameters, and the metal sintering process. With the large data gathered from
HP's MetJet printing process, AI techniques can be used to analyze, learn, and
effectively infer the printed part quality metrics, as well as assist in
improving the print yield. In-situ thermal sensing data captured by
printer-installed thermal sensors contains the part thermal signature of fusing
layers. Such part thermal signature contains a convoluted impact from various
factors. In this paper, we use a multimodal thermal encoder network to fuse
data of a different nature including the video data vectorized printer control
data, and exact part thermal signatures with a trained encoder-decoder module.
We explored the data fusing techniques and stages for data fusing, the
optimized end-to-end model architecture indicates an improved part quality
prediction accuracy.
","[' Rachel', ' Chen', 'Wenjia Zheng', 'Sandeep Jalui', 'Pavan Suri', 'Jun Zeng']"
http://arxiv.org/abs/1605.03246v1,3D printing,2016-05-10T23:41:51Z,2016-05-10T23:41:51Z,"Analysis of 3D-printed metal for rapid-prototyped reflective terahertz
  optics","  We explore the potential of 3D metal printing to realize complex conductive
terahertz devices. Factors impacting performance such as printing resolution,
surface roughness, oxidation, and material loss are investigated via
analytical, numerical, and experimental approaches. The high degree of control
offered by a 3D-printed topology is exploited to realize a zone plate operating
at 530 GHz. Reflection efficiency at this frequency is found to be over 90%.
The high-performance of this preliminary device suggest that 3D metal printing
can play a strong role in guided-wave and general beam control devices in the
terahertz range.
","['Daniel Headland', 'Withawat Withayachumnankul', 'Michael Webb', 'Heike Ebendorff-Heidepriem', 'Andre Luiten', 'Derek Abbott']"
http://arxiv.org/abs/2501.11995v1,3D printing,2025-01-21T09:34:37Z,2025-01-21T09:34:37Z,"Fabrication of Poly (ε-Caprolactone) 3D scaffolds with
  controllable porosity using ultrasound","  3D printing has progressed significantly, allowing objects to be produced
using a wide variety of materials. Recent advances have employed focused
ultrasound in 3D printing, to allow printing inside acoustically transparent
materials. Here we introduce a Selective Ultrasonic Melting (SUM) method for 3D
printing of poly ({\epsilon}-caprolactone) (PCL) powder mixed with water. The
printing was done by mechanically moving a focused ultrasound transducer. The
microstructure and porosity of the prints were analyzed with micro-computed
tomography ({\mu}CT). The open porosity of the printed samples was determined
using the water intrusion method and by passing fluorescent microspheres
through the structure. The cytocompatibility of the printed structures was
confirmed by seeding NIH-3T3 fibroblast cells on the scaffolds, followed by
analysis using live/dead fluorescent assay. and visualization using scanning
electron microscopy (SEM). We demonstrated that SUM is a viable technique to
print structures with active control of their porosity This method provides an
alternative to methods such as fused deposition modelling (FDM) and material
jetting.
","['Martin Weber', 'Dmitry Nikolaev', 'Mikko Koskenniemi', 'Jere Hyvönen', 'Joel Jääskeläinen', 'Armand Navarre', 'Ekaterina Takmakova', 'Arun Teotia', 'Pekka Katajisto', 'Robert Luxenhofer', 'Edward Hæggström', 'Ari Salmi']"
http://arxiv.org/abs/2401.08982v1,3D printing,2024-01-17T05:26:30Z,2024-01-17T05:26:30Z,Robot Tape Manipulation for 3D Printing,"  3D printing has enabled various applications using different forms of
materials, such as filaments, sheets, and inks. Typically, during 3D printing,
feedstocks are transformed into discrete building blocks and placed or
deposited in a designated location similar to the manipulation and assembly of
discrete objects. However, 3D printing of continuous and flexible tape (with
the geometry between filaments and sheets) without breaking or transformation
remains underexplored and challenging. Here, we report the design and
implementation of a customized end-effector, i.e., tape print module (TPM), to
realize robot tape manipulation for 3D printing by leveraging the tension
formed on the tape between two endpoints. We showcase the feasibility of
manufacturing representative 2D and 3D structures while utilizing conductive
copper tape for various electronic applications, such as circuits and sensors.
We believe this manipulation strategy could unlock the potential of other tape
materials for manufacturing, including packaging tape and carbon fiber prepreg
tape, and inspire new mechanisms for robot manipulation, 3D printing, and
packaging.
","['Nahid Tushar', 'Rencheng Wu', 'Yu She', 'Wenchao Zhou', 'Wan Shou']"
http://arxiv.org/abs/1807.02921v1,3D printing,2018-07-09T02:52:01Z,2018-07-09T02:52:01Z,"Inferring Quality in Point Cloud-based 3D Printed Objects using
  Topological Data Analysis","  Assessing the quality of 3D printed models before they are printed remains a
challeng- ing problem, particularly when considering point cloud-based models.
This paper introduces an approach to quality assessment, which uses techniques
from the field of Topological Data Analy- sis (TDA) to compute a topological
abstraction of the eventual printed model. Two main tools of TDA, Mapper and
persistent homology, are used to analyze both the printed space and empty space
created by the model. This abstraction enables investigating certain qualities
of the model, with respect to print quality, and identifies potential anomalies
that may appear in the final product.
","['Paul Rosen', 'Mustafa Hajij', 'Junyi Tu', 'Tanvirul Arafin', 'Les Piegl']"
http://arxiv.org/abs/1605.09737v1,3D printing,2016-05-31T17:39:49Z,2016-05-31T17:39:49Z,3D Printed Stencils for Texturing Flat Surfaces,"  We address the problem of texturing flat surfaces by spray-painting through
3D printed stencils. We propose a system that (1) decomposes an image into
alpha-blended layers; (2) computes a stippling given a transparency channel;
(3) generates a 3D printed stencil given a stippling and (4) simulates the
effects of spray-painting through the stencil.
",['Vaibhav Vavilala']
http://arxiv.org/abs/2004.12471v2,3D printing,2020-04-26T20:22:31Z,2020-07-11T14:12:22Z,3D Printed Lightweight Composite Foams,"  The goal of this paper is to enable 3D printed lightweight composite foams by
blending hollow glass micro balloons (GMB) with high density polyethylene
(HDPE). To that end, lightweight feedstock for printing syntactic foam
composites is developed. The blend for this is prepared by varying GMB content
(20, 40, and 60 volume %) in HDPE for filament extrusion, which is subsequently
used for three-dimensional printing (3DP). The rheological properties and the
melt flow index (MFI) of blends are investigated for identifying suitable
printing parameters. It is observed that the storage and loss modulus, as well
as complex viscosity, increases with increasing GMB content, whereas MFI
decreases. Further, the coefficient of thermal expansion of HDPE and foam
filaments decreases with increasing GMB content, thereby lowering the thermal
stresses in prints, which promotes the reduction in warpage. The mechanical
properties of filaments are determined by subjecting them to tensile tests,
whereas 3D printed samples are tested under tensile and flexure tests. The
tensile modulus of the filament increases with increasing GMB content (8-47%)
as compared to HDPE and exhibit comparable filament strength. 3D printed foams
show higher specific tensile and flexural modulus as compared to neat HDPE,
making them suitable candidate materials for weight sensitive applications.
HDPE having 60% by volume GMB exhibited the highest modulus and is 48.02%
higher than the printed HDPE. Finally, the property map reveals higher modulus
and comparable strength against injection and compression molded foams. Printed
foam registered 1.8 times higher modulus than molded samples. Hence, 3D printed
foams have the potential for replacing components processed through
conventional manufacturing processes that have limitations on geometrically
complex designs, lead time, and associated costs.
","['Bharath H S', 'Dileep Bonthu', 'Pavana Prabhakar', 'Mrityunjay Doddamani']"
http://arxiv.org/abs/1605.04797v2,3D printing,2016-05-16T15:09:19Z,2016-07-02T03:15:10Z,"Thingi10K: A Dataset of 10,000 3D-Printing Models","  Empirically validating new 3D-printing related algorithms and implementations
requires testing data representative of inputs encountered \emph{in the wild}.
An ideal benchmarking dataset should not only draw from the same distribution
of shapes people print in terms of class (e.g., toys, mechanisms, jewelry),
representation type (e.g., triangle soup meshes) and complexity (e.g., number
of facets), but should also capture problems and artifacts endemic to 3D
printing models (e.g., self-intersections, non-manifoldness). We observe that
the contextual and geometric characteristics of 3D printing models differ
significantly from those used for computer graphics applications, not to
mention standard models (e.g., Stanford bunny, Armadillo, Fertility). We
present a new dataset of 10,000 models collected from an online 3D printing
model-sharing database. Via analysis of both geometric (e.g., triangle aspect
ratios, manifoldness) and contextual (e.g., licenses, tags, classes)
characteristics, we demonstrate that this dataset represents a more concise
summary of real-world models used for 3D printing compared to existing
datasets. To facilitate future research endeavors, we also present an online
query interface to select subsets of the dataset according to project-specific
characteristics. The complete dataset and per-model statistical data are freely
available to the public.
","['Qingnan Zhou', 'Alec Jacobson']"
http://arxiv.org/abs/2304.02924v1,Artificial intelligence,2023-04-06T08:26:38Z,2023-04-06T08:26:38Z,The Governance of Physical Artificial Intelligence,"  Physical artificial intelligence can prove to be one of the most important
challenges of the artificial intelligence. The governance of physical
artificial intelligence would define its responsible intelligent application in
the society.
","['Yingbo Li', 'Anamaria-Beatrice Spulber', 'Yucong Duan']"
http://arxiv.org/abs/2005.10488v1,Artificial intelligence,2020-05-21T07:00:31Z,2020-05-21T07:00:31Z,"Does an artificial intelligence perform market manipulation with its own
  discretion? -- A genetic algorithm learns in an artificial market simulation","  Who should be charged with responsibility for an artificial intelligence
performing market manipulation have been discussed. In this study, I
constructed an artificial intelligence using a genetic algorithm that learns in
an artificial market simulation, and investigated whether the artificial
intelligence discovers market manipulation through learning with an artificial
market simulation despite a builder of artificial intelligence has no intention
of market manipulation. As a result, the artificial intelligence discovered
market manipulation as an optimal investment strategy. This result suggests
necessity of regulation, such as obligating builders of artificial intelligence
to prevent artificial intelligence from performing market manipulation.
",['Takanobu Mizuta']
http://arxiv.org/abs/1509.01213v1,Artificial intelligence,2015-07-01T16:26:21Z,2015-07-01T16:26:21Z,Impact of Artificial Intelligence on Economic Theory,"  Artificial intelligence has impacted many aspects of human life. This paper
studies the impact of artificial intelligence on economic theory. In particular
we study the impact of artificial intelligence on the theory of bounded
rationality, efficient market hypothesis and prospect theory.
",['Tshilidzi Marwala']
http://arxiv.org/abs/2101.02179v1,Artificial intelligence,2020-12-27T23:45:03Z,2020-12-27T23:45:03Z,The case for psychometric artificial general intelligence,"  A short review of the literature on measurement and detection of artificial
general intelligence is made. Proposed benchmarks and tests for artificial
general intelligence are critically evaluated against multiple criteria. Based
on the findings, the most promising approaches are identified and some useful
directions for future work are proposed.
",['Mark McPherson']
http://arxiv.org/abs/1304.3846v1,Artificial intelligence,2013-04-13T20:44:25Z,2013-04-13T20:44:25Z,"Proceedings of the Thirteenth Conference on Uncertainty in Artificial
  Intelligence (1997)","  This is the Proceedings of the Thirteenth Conference on Uncertainty in
Artificial Intelligence, which was held in Providence, RI, August 1-3, 1997
","['Dan Geiger', 'Prakash Shenoy']"
http://arxiv.org/abs/1304.3851v1,Artificial intelligence,2013-04-13T21:03:12Z,2013-04-13T21:03:12Z,"Proceedings of the Ninth Conference on Uncertainty in Artificial
  Intelligence (1993)","  This is the Proceedings of the Ninth Conference on Uncertainty in Artificial
Intelligence, which was held in Washington, DC, July 9-11, 1993
","['David Heckerman', 'E. Mamdani']"
http://arxiv.org/abs/1304.3859v1,Artificial intelligence,2013-04-13T21:37:12Z,2013-04-13T21:37:12Z,"Proceedings of the Second Conference on Uncertainty in Artificial
  Intelligence (1986)","  This is the Proceedings of the Second Conference on Uncertainty in Artificial
Intelligence, which was held in Philadelphia, PA, August 8-10, 1986
","['Laveen Kanal', 'John Lemmer']"
http://arxiv.org/abs/1311.0716v1,Artificial intelligence,2013-10-30T14:19:49Z,2013-10-30T14:19:49Z,Artificial Intelligence in Humans,"  In this paper, I put forward that in many instances, thinking mechanisms are
equivalent to artificial intelligence modules programmed into the human mind.
",['Michael Swan Laufer']
http://arxiv.org/abs/1810.06018v1,Artificial intelligence,2018-10-14T11:40:30Z,2018-10-14T11:40:30Z,"AAAI FSS-18: Artificial Intelligence in Government and Public Sector
  Proceedings","  Proceedings of the AAAI Fall Symposium on Artificial Intelligence in
Government and Public Sector, Arlington, Virginia, USA, October 18-20, 2018
","['Frank Stein', 'Alun Preece', 'Mihai Boicu']"
http://arxiv.org/abs/2104.13155v2,Artificial intelligence,2021-04-27T13:03:25Z,2021-05-07T18:34:10Z,"Watershed of Artificial Intelligence: Human Intelligence, Machine
  Intelligence, and Biological Intelligence","  This article reviews the ""Once learning"" mechanism that was proposed 23 years
ago and the subsequent successes of ""One-shot learning"" in image classification
and ""You Only Look Once - YOLO"" in objective detection. Analyzing the current
development of Artificial Intelligence (AI), the proposal is that AI should be
clearly divided into the following categories: Artificial Human Intelligence
(AHI), Artificial Machine Intelligence (AMI), and Artificial Biological
Intelligence (ABI), which will also be the main directions of theory and
application development for AI. As a watershed for the branches of AI, some
classification standards and methods are discussed: 1) Human-oriented,
machine-oriented, and biological-oriented AI R&D; 2) Information input
processed by Dimensionality-up or Dimensionality-reduction; 3) The use of
one/few or large samples for knowledge learning.
","['Li Weigang', 'Liriam Enamoto', 'Denise Leyi Li', 'Geraldo Pereira Rocha Filho']"
http://arxiv.org/abs/2102.12076v1,Artificial intelligence,2021-02-24T05:43:44Z,2021-02-24T05:43:44Z,"Perspective: Purposeful Failure in Artificial Life and Artificial
  Intelligence","  Complex systems fail. I argue that failures can be a blueprint characterizing
living organisms and biological intelligence, a control mechanism to increase
complexity in evolutionary simulations, and an alternative to classical fitness
optimization. Imitating biological successes in Artificial Life and Artificial
Intelligence can be misleading; imitating failures offers a path towards
understanding and emulating life it in artificial systems.
",['Lana Sinapayen']
http://arxiv.org/abs/2404.03499v1,Artificial intelligence,2024-04-04T14:57:32Z,2024-04-04T14:57:32Z,Comprehensible Artificial Intelligence on Knowledge Graphs: A survey,"  Artificial Intelligence applications gradually move outside the safe walls of
research labs and invade our daily lives. This is also true for Machine
Learning methods on Knowledge Graphs, which has led to a steady increase in
their application since the beginning of the 21st century. However, in many
applications, users require an explanation of the Artificial Intelligences
decision. This led to increased demand for Comprehensible Artificial
Intelligence. Knowledge Graphs epitomize fertile soil for Comprehensible
Artificial Intelligence, due to their ability to display connected data, i.e.
knowledge, in a human- as well as machine-readable way. This survey gives a
short history to Comprehensible Artificial Intelligence on Knowledge Graphs.
Furthermore, we contribute by arguing that the concept Explainable Artificial
Intelligence is overloaded and overlapping with Interpretable Machine Learning.
By introducing the parent concept Comprehensible Artificial Intelligence, we
provide a clear-cut distinction of both concepts while accounting for their
similarities. Thus, we provide in this survey a case for Comprehensible
Artificial Intelligence on Knowledge Graphs consisting of Interpretable Machine
Learning on Knowledge Graphs and Explainable Artificial Intelligence on
Knowledge Graphs. This leads to the introduction of a novel taxonomy for
Comprehensible Artificial Intelligence on Knowledge Graphs. In addition, a
comprehensive overview of the research on Comprehensible Artificial
Intelligence on Knowledge Graphs is presented and put into the context of the
taxonomy. Finally, research gaps in the field of Comprehensible Artificial
Intelligence on Knowledge Graphs are identified for future research.
","['Simon Schramm', 'Christoph Wehner', 'Ute Schmid']"
http://arxiv.org/abs/2007.07710v1,Artificial intelligence,2020-07-11T14:06:13Z,2020-07-11T14:06:13Z,Human $\neq$ AGI,"  Terms Artificial General Intelligence (AGI) and Human-Level Artificial
Intelligence (HLAI) have been used interchangeably to refer to the Holy Grail
of Artificial Intelligence (AI) research, creation of a machine capable of
achieving goals in a wide range of environments. However, widespread implicit
assumption of equivalence between capabilities of AGI and HLAI appears to be
unjustified, as humans are not general intelligences. In this paper, we will
prove this distinction.
",['Roman V. Yampolskiy']
http://arxiv.org/abs/2111.11295v1,Artificial intelligence,2021-11-08T00:10:49Z,2021-11-08T00:10:49Z,"Artificial Intelligence Technology analysis using Artificial
  Intelligence patent through Deep Learning model and vector space model","  Thanks to rapid development of artificial intelligence technology in recent
years, the current artificial intelligence technology is contributing to many
part of society. Education, environment, medical care, military, tourism,
economy, politics, etc. are having a very large impact on society as a whole.
For example, in the field of education, there is an artificial intelligence
tutoring system that automatically assigns tutors based on student's level. In
the field of economics, there are quantitative investment methods that
automatically analyze large amounts of data to find investment laws to create
investment models or predict changes in financial markets. As such, artificial
intelligence technology is being used in various fields. So, it is very
important to know exactly what factors have an important influence on each
field of artificial intelligence technology and how the relationship between
each field is connected. Therefore, it is necessary to analyze artificial
intelligence technology in each field. In this paper, we analyze patent
documents related to artificial intelligence technology. We propose a method
for keyword analysis within factors using artificial intelligence patent data
sets for artificial intelligence technology analysis. This is a model that
relies on feature engineering based on deep learning model named KeyBERT, and
using vector space model. A case study of collecting and analyzing artificial
intelligence patent data was conducted to show how the proposed model can be
applied to real world problems.
","['Yongmin Yoo', 'Dongjin Lim', 'Kyungsun Kim']"
http://arxiv.org/abs/1712.06440v1,Artificial intelligence,2017-12-14T17:49:04Z,2017-12-14T17:49:04Z,Three IQs of AI Systems and their Testing Methods,"  The rapid development of artificial intelligence has brought the artificial
intelligence threat theory as well as the problem about how to evaluate the
intelligence level of intelligent products. Both need to find a quantitative
method to evaluate the intelligence level of intelligence systems, including
human intelligence. Based on the standard intelligence system and the extended
Von Neumann architecture, this paper proposes General IQ, Service IQ and Value
IQ evaluation methods for intelligence systems, depending on different
evaluation purposes. Among them, the General IQ of intelligence systems is to
answer the question of whether the artificial intelligence can surpass the
human intelligence, which is reflected in putting the intelligence systems on
an equal status and conducting the unified evaluation. The Service IQ and Value
IQ of intelligence systems are used to answer the question of how the
intelligent products can better serve the human, reflecting the intelligence
and required cost of each intelligence system as a product in the process of
serving human.
","['Feng Liu', 'Yong Shi', 'Ying Liu']"
http://arxiv.org/abs/2108.04770v1,Artificial intelligence,2021-08-10T16:24:30Z,2021-08-10T16:24:30Z,"Examining correlation between trust and transparency with explainable
  artificial intelligence","  Trust between humans and artificial intelligence(AI) is an issue which has
implications in many fields of human computer interaction. The current issue
with artificial intelligence is a lack of transparency into its decision
making, and literature shows that increasing transparency increases trust.
Explainable artificial intelligence has the ability to increase transparency of
AI, which could potentially increase trust for humans. This paper attempts to
use the task of predicting yelp review star ratings with assistance from an
explainable and non explainable artificial intelligence to see if trust is
increased with increased transparency. Results show that for these tasks,
explainable artificial intelligence provided significant increase in trust as a
measure of influence.
",['Arnav Kartikeya']
http://arxiv.org/abs/2110.01831v1,Artificial intelligence,2021-10-05T05:58:23Z,2021-10-05T05:58:23Z,"The Artificial Scientist: Logicist, Emergentist, and Universalist
  Approaches to Artificial General Intelligence","  We attempt to define what is necessary to construct an Artificial Scientist,
explore and evaluate several approaches to artificial general intelligence
(AGI) which may facilitate this, conclude that a unified or hybrid approach is
necessary and explore two theories that satisfy this requirement to some
degree.
","['Michael Timothy Bennett', 'Yoshihiro Maruyama']"
http://arxiv.org/abs/1205.2596v2,Artificial intelligence,2012-05-11T18:35:50Z,2014-08-28T04:30:01Z,"Proceedings of the Twenty-Seventh Conference on Uncertainty in
  Artificial Intelligence (2011)","  This is the Proceedings of the Twenty-Seventh Conference on Uncertainty in
Artificial Intelligence, which was held in Barcelona, Spain, July 14 - 17 2011.
","['Fabio Cozman', 'Avi Pfeffer']"
http://arxiv.org/abs/1205.2597v2,Artificial intelligence,2012-05-11T18:40:29Z,2014-08-28T04:29:00Z,"Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial
  Intelligence (2010)","  This is the Proceedings of the Twenty-Sixth Conference on Uncertainty in
Artificial Intelligence, which was held on Catalina Island, CA, July 8 - 11
2010.
","['Peter Grunwald', 'Peter Spirtes']"
http://arxiv.org/abs/1206.3959v2,Artificial intelligence,2012-06-13T16:43:44Z,2014-08-28T04:27:28Z,"Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial
  Intelligence (2009)","  This is the Proceedings of the Twenty-Fifth Conference on Uncertainty in
Artificial Intelligence, which was held in Montreal, QC, Canada, June 18 - 21
2009.
","['Jeff Bilmes', 'Andrew Ng']"
http://arxiv.org/abs/1808.03413v1,Augmented reality,2018-08-10T05:23:37Z,2018-08-10T05:23:37Z,Inverse Augmented Reality: A Virtual Agent's Perspective,"  We propose a framework called inverse augmented reality (IAR) which describes
the scenario that a virtual agent living in the virtual world can observe both
virtual objects and real objects. This is different from the traditional
augmented reality. The traditional virtual reality, mixed reality and augmented
reality are all generated for humans, i.e., they are human-centered frameworks.
On the contrary, the proposed inverse augmented reality is a virtual
agent-centered framework, which represents and analyzes the reality from a
virtual agent's perspective. In this paper, we elaborate the framework of
inverse augmented reality to argue the equivalence of the virtual world and the
physical world regarding the whole physical structure.
","['Zhenliang Zhang', 'Dongdong Weng', 'Haiyan Jiang', 'Yue Liu', 'Yongtian Wang']"
http://arxiv.org/abs/1903.02723v1,Augmented reality,2019-03-07T04:29:50Z,2019-03-07T04:29:50Z,"Symmetrical Reality: Toward a Unified Framework for Physical and Virtual
  Reality","  In this paper, we review the background of physical reality, virtual reality,
and some traditional mixed forms of them. Based on the current knowledge, we
propose a new unified concept called symmetrical reality to describe the
physical and virtual world in a unified perspective. Under the framework of
symmetrical reality, the traditional virtual reality, augmented reality,
inverse virtual reality, and inverse augmented reality can be interpreted using
a unified presentation. We analyze the characteristics of symmetrical reality
from two different observation locations (i.e., from the physical world and
from the virtual world), where all other forms of physical and virtual reality
can be treated as special cases of symmetrical reality.
","['Zhenliang Zhang', 'Cong Wang', 'Dongdong Weng', 'Yue Liu', 'Yongtian Wang']"
http://arxiv.org/abs/2104.08579v2,Augmented reality,2021-04-17T15:47:48Z,2021-05-04T17:29:28Z,"SelectVisAR: Selective Visualisation of Virtual Environments in
  Augmented Reality","  When establishing a visual connection between a virtual reality user and an
augmented reality user, it is important to consider whether the augmented
reality user faces a surplus of information. Augmented reality, compared to
virtual reality, involves two, not one, planes of information: the physical and
the virtual. We propose SelectVisAR, a selective visualisation system of
virtual environments in augmented reality. Our system enables an augmented
reality spectator to perceive a co-located virtual reality user in the context
of four distinct visualisation conditions: Interactive, Proximity, Everything,
and Dollhouse. We explore an additional two conditions, Context and Spotlight,
in a follow-up study. Our design uses a human-centric approach to information
filtering, selectively visualising only parts of the virtual environment
related to the interactive possibilities of a virtual reality user. The
research investigates how selective visualisations can be helpful or trivial
for the augmented reality user when observing a virtual reality user.
","['Robbe Cools', 'Jihae Han', 'Adalberto L. Simeone']"
http://arxiv.org/abs/2101.02565v1,Augmented reality,2021-01-07T14:43:51Z,2021-01-07T14:43:51Z,Augmentix -- An Augmented Reality System for asymmetric Teleteaching,"  Using augmented reality in education is already a common concept, as it has
the potential to turn learning into a motivational learning experience.
However, current research only covers the students site of learning. Almost no
research focuses on the teachers' site and whether augmented reality could
potentially improve his/her workflow of teaching the students or not. Many
researchers do not differentiate between multiple user roles, like a student
and a teacher. To allow investigation into these lacks of research, a teaching
system ""Augmentix"" is presented, which includes a differentiation between the
two user roles ""teacher"" and ""student"" to potentially enhances the teachers
workflow by using augmented reality. In this system's setting the student can
explore a virtual city in virtual reality and the teacher can guide him with
augmented reality.
",['Nico Feld']
http://arxiv.org/abs/1106.5571v1,Augmented reality,2011-06-28T06:08:38Z,2011-06-28T06:08:38Z,Mobile Augmented Reality Applications,"  Augmented reality have undergone considerable improvement in past years. Many
special techniques and hardware devices were developed, but the crucial
breakthrough came with the spread of intelligent mobile phones. This enabled
mass spread of augmented reality applications. However mobile devices have
limited hardware capabilities, which narrows down the methods usable for scene
analysis. In this article we propose an augmented reality application which is
using cloud computing to enable using of more complex computational methods
such as neural networks. Our goal is to create an affordable augmented reality
application suitable which will help car designers in by 'virtualizing' car
modifications.
","['David Prochazka', 'Michael Stencl', 'Ondrej Popelka', 'Jiri Stastny']"
http://arxiv.org/abs/1807.00279v1,Augmented reality,2018-07-01T06:51:23Z,2018-07-01T06:51:23Z,"Using Blippar Augmented Reality Browser in the Practical Training of
  Mechanical Engineers","  The purpose of the study is to justify the expediency of using the Blippar
augmented reality browser for professional and practical training of future
mechanical engineers. Tasks of the research: to analyze the expediency of using
augmented reality tools in the professional training of bachelors of applied
mechanics; to carry out the selection of augmented reality tools, which is
expedient to use in the training of future engineer mechanics; to develop
educational materials using the chosen augmented reality tools. The object of
the study is the professional training of future mechanical engineers. The
subject of the study is the use of the augmented reality tools in the
professional training of bachelors of applied mechanics. The paper analyzes the
relevance and expediency of the use of the augmented reality tools in the
professional training of future mechanical engineers. It is determined that the
augmented reality tools will promote the development of ICT competence and
graphic competence of bachelors of applied mechanics The model of the use of
the augmented reality tools in the training of future mechanical engineers is
proposed. As the main tool, the Blippar browser and Blippbuilder's cloud-based
script development tool are chosen. An example of the creation of markers and
scenes of augmented reality using the selected tools is given. The advantages
and disadvantages of used tools are indicated. The proposed learning tools and
methods can be applied to vocational and practical training of mechanical
engineers.
","['Andrii Striuk', 'Maryna Rassovytska', 'Svitlana Shokaliuk']"
http://arxiv.org/abs/2112.11190v1,Augmented reality,2021-12-03T20:46:50Z,2021-12-03T20:46:50Z,"Augmented reality applications in manufacturing and its future scope in
  Industry 4.0","  Augmented reality technology is one of the leading technologies in the
context of Industry 4.0. The promising potential application of augmented
reality in industrial production systems has received much attention, which led
to the concept of industrial augmented reality. On the one hand, this
technology provides a suitable platform that facilitates the registration of
information and access to them to help make decisions and allows concurrent
training for the user while executing the production processes. This leads to
increased work speed and accuracy of the user as a process operator and
consequently offers economic benefits to the companies. Moreover, recent
advances in the internet of things, smart sensors, and advanced algorithms have
increased the possibility of widespread and more effective use of augmented
reality. Currently, many research pieces are being done to expand the
application of augmented reality and increase its effectiveness in industrial
production processes. This research demonstrates the influence of augmented
reality in Industry 4.0 while critically reviewing the industrial augmented
reality history. Afterward, the paper discusses the critical role of industrial
augmented reality by analyzing some use cases and their prospects. With a
systematic analysis, this paper discusses the main future directions for
industrial augmented reality applications in industry 4.0. The article
investigates various areas of application for this technology and its impact on
improving production conditions. Finally, the challenges that this technology
faces and its research opportunities are discussed.
","['Omid Ziaee', 'Mohsen Hamedi']"
http://arxiv.org/abs/1106.5569v1,Augmented reality,2011-06-28T05:57:37Z,2011-06-28T05:57:37Z,Augmented Reality Implementation Methods in Mainstream Applications,"  Augmented reality has became an useful tool in many areas from space
exploration to military applications. Although used theoretical principles are
well known for almost a decade, the augmented reality is almost exclusively
used in high budget solutions with a special hardware. However, in last few
years we could see rising popularity of many projects focused on deployment of
the augmented reality on different mobile devices. Our article is aimed on
developers who consider development of an augmented reality application for the
mainstream market. Such developers will be forced to keep the application
price, therefore also the development price, at reasonable level. Usage of
existing image processing software library could bring a significant cut-down
of the development costs. In the theoretical part of the article is presented
an overview of the augmented reality application structure. Further, an
approach for selection appropriate library as well as the review of the
existing software libraries focused in this area is described. The last part of
the article outlines our implementation of key parts of the augmented reality
application using the OpenCV library.
","['David Prochazka', 'Tomas Koubek']"
http://arxiv.org/abs/1807.10659v1,Augmented reality,2018-07-23T12:36:54Z,2018-07-23T12:36:54Z,"Using technology of augmented reality in a mobile-based learning
  environment of the higher educational institution","  The definition of the augmented reality concept is based on the analysis of
scientific publications. It is noted that online experiments with augmented
reality provide students with the opportunity to observe and describe the
operation with real systems by changing their parameters, and also partially
replace experimental installations with objects of augmented reality. The
scheme for realizing the augmented reality is considered. The possibilities of
working with augmented reality objects in teaching physics is highlighted. It
is indicated that the use of the augmented reality tools allows to increase the
realness of the research; provides emotional and cognitive experience, helps
attract students to systematic training; provides correct information about the
installation in the process of experimentation; creates new ways of
representing real objects in the learning process.
","['Yevhenii O. Modlo', 'Yuliia V. Yechkalo', 'Serhiy O. Semerikov', 'Viktoriia V. Tkachuk']"
http://arxiv.org/abs/1912.12101v1,Augmented reality,2019-12-27T13:56:13Z,2019-12-27T13:56:13Z,"A 3D-Deep-Learning-based Augmented Reality Calibration Method for
  Robotic Environments using Depth Sensor Data","  Augmented Reality and mobile robots are gaining much attention within
industries due to the high potential to make processes cost and time efficient.
To facilitate augmented reality, a calibration between the Augmented Reality
device and the environment is necessary. This is a challenge when dealing with
mobile robots due to the mobility of all entities making the environment
dynamic. On this account, we propose a novel approach to calibrate the
Augmented Reality device using 3D depth sensor data. We use the depth camera of
a cutting edge Augmented Reality Device - the Microsoft Hololens for deep
learning based calibration. Therefore, we modified a neural network based on
the recently published VoteNet architecture which works directly on the point
cloud input observed by the Hololens. We achieve satisfying results and
eliminate external tools like markers, thus enabling a more intuitive and
flexible work flow for Augmented Reality integration. The results are adaptable
to work with all depth cameras and are promising for further research.
Furthermore, we introduce an open source 3D point cloud labeling tool, which is
to our knowledge the first open source tool for labeling raw point cloud data.
","['Linh Kästner', 'Vlad Catalin Frasineanu', 'Jens Lambrecht']"
http://arxiv.org/abs/1708.05006v1,Augmented reality,2017-08-16T09:40:53Z,2017-08-16T09:40:53Z,A Survey of Augmented Reality Navigation,"  Navigation has been a popular area of research in both academia and industry.
Combined with maps, and different localization technologies, navigation systems
have become robust and more usable. By combining navigation with augmented
reality, it can be improved further to become realistic and user friendly. This
paper surveys existing researches carried out in this area, describes existing
techniques for building augmented reality navigation systems, and the problems
faced.
",['Gaurav Bhorkar']
http://arxiv.org/abs/2201.07003v1,Augmented reality,2022-01-13T16:54:36Z,2022-01-13T16:54:36Z,"Use of augmented and virtual reality tools in a general secondary
  education institution in the context of blended learning","  The study examines the problem of using augmented and virtual reality in the
process of blended learning in general secondary education. The study analyzes
the meaning of the concept of ""blended learning"". The conceptual principles of
blended learning are considered. The definition of augmented and virtual
reality is given. The mixed reality is considered as a separate kind of notion.
Separate applications of virtual and augmented reality that can be used in the
process of blended learning are considered. As a result of the study, the
authors propose possible ways to use augmented reality in the educational
process. The model of using augmented and virtual reality in blended learning
in general secondary education institutions was designed. It consists of the
following blocks: goal; teacher's activity; forms of education; teaching
methods; teaching aids; organizational forms of education; pupil activity and
results. Based on the model, the methodology of using augmented and virtual
reality in blended learning in general secondary education was developed. The
methodology contains the following components: target component, content
component, technological component and resultant component. The methodology is
quite universal and can be used for any subject in general secondary education.
The types of lessons in which it is expedient to use augmented (AR) and virtual
reality(VR) are determined. Recommendations are given at which stage of the
lesson it is better to use AR and VR tools (depending on the type of lesson).
","['Valentyna Kovalenko', 'Maiia Marienko', 'Alisa Sukhikh']"
http://arxiv.org/abs/1305.5534v1,Augmented reality,2013-05-23T20:00:00Z,2013-05-23T20:00:00Z,Augmented Reality in Astrophysics,"  Augmented Reality consists of merging live images with virtual layers of
information. The rapid growth in the popularity of smartphones and tablets over
recent years has provided a large base of potential users of Augmented Reality
technology, and virtual layers of information can now be attached to a wide
variety of physical objects. In this article, we explore the potential of
Augmented Reality for astrophysical research with two distinct experiments: (1)
Augmented Posters and (2) Augmented Articles. We demonstrate that the emerging
technology of Augmented Reality can already be used and implemented without
expert knowledge using currently available apps. Our experiments highlight the
potential of Augmented Reality to improve the communication of scientific
results in the field of astrophysics. We also present feedback gathered from
the Australian astrophysics community that reveals evidence of some interest in
this technology by astronomers who experimented with Augmented Posters. In
addition, we discuss possible future trends for Augmented Reality applications
in astrophysics, and explore the current limitations associated with the
technology. This Augmented Article, the first of its kind, is designed to allow
the reader to directly experiment with this technology.
","['Frédéric P. A. Vogt', 'Luke J. Shingles']"
http://arxiv.org/abs/1508.02606v1,Augmented reality,2015-08-11T14:17:28Z,2015-08-11T14:17:28Z,InAR:Inverse Augmented Reality,"  Augmented reality is the art to seamlessly fuse virtual objects into real
ones. In this short note, we address the opposite problem, the inverse
augmented reality, that is, given a perfectly augmented reality scene where
human is unable to distinguish real objects from virtual ones, how the machine
could help do the job. We show by structure from motion (SFM), a simple 3D
reconstruction technique from images in computer vision, the real and virtual
objects can be easily separated in the reconstructed 3D scene.
","['Hao Hu', 'Hainan Cui']"
http://arxiv.org/abs/1508.04238v1,Augmented reality,2015-08-18T08:18:55Z,2015-08-18T08:18:55Z,Preprint ARPPS Augmented Reality Pipeline Prospect System,"  This is the preprint version of our paper on ICONIP. Outdoor augmented
reality geographic information system (ARGIS) is the hot application of
augmented reality over recent years. This paper concludes the key solutions of
ARGIS, designs the mobile augmented reality pipeline prospect system (ARPPS),
and respectively realizes the machine vision based pipeline prospect system
(MVBPPS) and the sensor based pipeline prospect system (SBPPS). With the
MVBPPS's realization, this paper studies the neural network based 3D features
matching method.
","['Xiaolei Zhang', 'Yong Han', 'DongSheng Hao', 'Zhihan Lv']"
http://arxiv.org/abs/1806.09316v1,Augmented reality,2018-06-25T08:01:45Z,2018-06-25T08:01:45Z,Vision-based Pose Estimation for Augmented Reality : A Comparison Study,"  Augmented reality aims to enrich our real world by inserting 3D virtual
objects. In order to accomplish this goal, it is important that virtual
elements are rendered and aligned in the real scene in an accurate and visually
acceptable way. The solution of this problem can be related to a pose
estimation and 3D camera localization. This paper presents a survey on
different approaches of 3D pose estimation in augmented reality and gives
classification of key-points-based techniques. The study given in this paper
may help both developers and researchers in the field of augmented reality.
","['Hayet Belghit', 'Abdelkader Bellarbi', 'Nadia Zenati', 'Samir Otmane']"
http://arxiv.org/abs/2109.02386v1,Augmented reality,2021-08-07T17:27:13Z,2021-08-07T17:27:13Z,Augmented Reality for Education: A Review,"  Augmented Reality, or simply AR, is the incorporation of information in
digital format that includes live footage of a certain user's real-time
environment. Also now, various universities are using Augmented Reality.
Applying the technology in the education sector can result in having a smart
campus. In line with that, this paper will discuss how Augmented Reality is
being used now in different learning areas.
",['Carlo H. Godoy Jr']
http://arxiv.org/abs/1807.01966v2,Augmented reality,2018-07-05T12:42:24Z,2018-12-03T16:45:21Z,The Cloud Technologies and Augmented Reality: the Prospects of Use,"  The article discusses the prospects of the augmented reality using as a
component of a cloud-based environment. The research goals are the next: to
explore the possibility of the augmented reality using with the involvement of
the cloud-based environment components. The research objectives are the next:
to consider the notion of augmented reality; to analyze the experience the
augmented reality using within the cloud environment / system; to outline the
prospects of the augmented reality using in educational institutions; to
consider the technical conditions of the augmented reality use. The object of
research is: the educational process in educational institutions of Ukraine of
different levels of accreditation. The subject of research is: the educational
process in a cloud-based environment in educational institutions of Ukraine.
The research methods used are the next: analysis of scientific publications,
observations. The results of the research are the next: on the basis of the
analysis of scientific works, it has been established that the experience of
the augmented reality using in the systems based on cloud technologies already
exists. However, the success of such a combination has not yet been proven.
Currently, laboratory tests are known, while the experiment was not carried out
under natural conditions in control and experimental groups. It is revealed
that the attraction of the augmented reality for the educators requires the
development of new methodologies, didactic materials, updating and updating of
the curriculum. The main conclusions and recommendations: the main principles
of augmented reality use in the learning process are: designing of the
environment that is flexible enough, attention should be paid to the teaching
and didactic issues; adjusting the educational content for mastering the
material provided by the curriculum.
","['Maiia V. Popel', 'Mariya P. Shyshkina']"
http://arxiv.org/abs/1810.10206v1,Augmented reality,2018-10-24T06:23:46Z,2018-10-24T06:23:46Z,"Immercity: a curation content application in Virtual and Augmented
  reality","  When working with emergent and appealing technologies as Virtual Reality,
Mixed Reality and Augmented Reality, the issue of definitions appear very
often. Indeed, our experience with various publics allows us to notice that
technology definitions pose ambiguity and representation problems for informed
as well as novice users. In this paper we present Immercity, a content curation
system designed in the context of a collaboration between the University of
Montpellier and CapGemi-ni, to deliver a technology watch. It is also used as a
testbed for our experiences with Virtual, Mixed and Augmented reality to
explore new interaction techniques and devices, artificial intelligence
integration, visual affordances, performance , etc. But another, very
interesting goal appeared: use Immercity to communicate about Virtual, Mixed
and Augmented Reality by using them as a support.
","['Jean-Daniel Taupiac', 'Nancy Rodriguez', 'Olivier Strauss']"
http://arxiv.org/abs/1808.06465v3,Augmented reality,2018-08-08T05:46:18Z,2021-05-03T09:04:40Z,"The Potential of Using Google Expeditions and Google Lens Tools under
  STEM-education in Ukraine","  The expediency of using the augmented reality in the case of using of
STEM-education in Ukraine is shown. The features of the augmented reality and
its classification are described. The possibilities of using the Google
Expeditions and Google Lens as platforms of the augmented reality is analyzed.
A comparison, analysis, synthesis, induction and deduction was carried out to
study the potential of using augmented reality platforms in the educational
process. Main haracteristics of Google Expeditions and Google Lens are
described. There determined that augmented reality tools can improve students
motivation to learn and correspond to trends of STEM-education. However, there
problems of using of augmented reality platforms, such as the lack of awareness
of this system by teachers, the lack of guidance, the absence of the
Ukrainian-language interface and responding of educational programs of the
Ministry of Education and Science of Ukraine. There proposed to involve
methodical and pedagogical specialists to development of methodical provision
of the tools of augmented reality.
","['Yevhenii B. Shapovalov', 'Zhanna I. Bilyk', 'Artem I. Atamas', 'Viktor B. Shapovalov', 'Aleksandr D. Uchitel']"
http://arxiv.org/abs/2304.09965v1,Blockchain,2023-04-19T20:55:59Z,2023-04-19T20:55:59Z,Vulnerability of Finitely-long Blockchains in Securing Data,"  Recently, blockchain has been applied in various fields to secure data
exchanges and storage in decentralized systems. In a blockchain application
where the task of the application which makes use of the data stored in a
blockchain has to be accomplished by a time instant, the employed blockchain is
essentially finitely-long. In this paper, we consider a general finitely-long
blockchain model which is generalized from most existing works on finitely-long
blockchain applications, and take the first step towards characterizing the
vulnerability of finitely-long blockchains in securing data against
double-spending attacks. For the first time, we develop a general closed-form
expression for the probability of success in launching a double-spending attack
on a finitely-long blockchain. This probability essentially characterizes the
vulnerability of finitely-long blockchains. Then, we prove that the probability
of success in launching a double-spending attack on a finitely-long blockchain
is no greater than that on an infinitely-long blockchain, which implies that
finitely-long blockchains are less vulnerable to double-spending attacks than
infinitely-long blockchains. Moreover, we show that unlike infinitely-long
blockchains which can be surely paralyzed by a 51% attack, finitely-long
blockchains are more resistant to 51% attacks.
","['Yiming Jiang', 'Jiangfan Zhang']"
http://arxiv.org/abs/1905.07014v1,Blockchain,2019-05-15T13:42:46Z,2019-05-15T13:42:46Z,A Framework for Blockchain Interoperability and Runtime Selection,"  The suitability of a particular blockchain for a given use case depends
mainly on the blockchain's functional and non-functional properties. Such
properties may vary over time, and thus, a selected blockchain may become
unsuitable for a given use case. This uncertainty may hinder the widespread
adoption of blockchain technologies in general. To mitigate the impact of
volatile blockchain properties, we propose a framework that monitors several
blockchains, allows the user to define functional and non-functional
requirements, determines the most appropriate blockchain, and enables the
switchover to that chain at runtime. Our evaluation using a reference
implementation shows that switching to another blockchain can save cost and
enable users to benefit from better performance and a higher level of trust.
","['Philipp Frauenthaler', 'Michael Borkowski', 'Stefan Schulte']"
http://arxiv.org/abs/1909.02914v1,Blockchain,2019-09-06T13:55:14Z,2019-09-06T13:55:14Z,"Blockchain Technologies for Smart Energy Systems: Fundamentals,
  Challenges and Solutions","  In this paper, we discuss the integration of blockchain in smart energy
systems. We present various blockchain technology solutions, review important
blockchain platforms, and several blockchain based smart energy projects in
different smart energy domains. The majority of blockchain platforms with
embedded combination of blockchain technology solutions are computing- and
resource- intensive, and hence not entirely suitable for smart energy
applications. We consider the requirements of smart energy systems and
accordingly identify appropriate blockchain technology solutions for smart
energy applications. Our analysis can help in the development of flexible
blockchain platforms for smart energy systems.
","['Naveed UL Hassan', 'Chau Yuen', 'Dusit Niyato']"
http://arxiv.org/abs/2002.12837v1,Blockchain,2020-02-26T13:49:47Z,2020-02-26T13:49:47Z,Testimonium: A Cost-Efficient Blockchain Relay,"  Current blockchain technologies provide very limited means of
interoperability. In particular, solutions enabling blockchains to verify the
existence of data on other blockchains are either very costly or are not fully
decentralized. To overcome these limitations, we introduce Testimonium, a novel
blockchain relay scheme that applies a validation-on-demand pattern and the
on-chain execution of Simplified Payment Verifications to enable the
verification of data across blockchains while remaining fully decentralized.
Evaluating the scheme for Ethereum-based blockchains shows that Testimonium
achieves a cost reduction of up to 92% over existing solutions. As such, the
scheme lays a strong foundation for generic blockchain interoperability. For
instance, it enables the development of an atomic-commit protocol for
distributed transactions across blockchains.
","['Philipp Frauenthaler', 'Marten Sigwart', 'Christof Spanring', 'Stefan Schulte']"
http://arxiv.org/abs/1910.14614v1,Blockchain,2019-10-31T17:02:07Z,2019-10-31T17:02:07Z,"Selecting Reliable Blockchain Peers via Hybrid Blockchain Reliability
  Prediction","  Blockchain and blockchain-based decentralized applications are attracting
increasing attentions recently. In public blockchain systems, users usually
connect to third-party peers or run a peer to join the P2P blockchain network.
However, connecting to unreliable blockchain peers will make users waste
resources and even lose millions of dollars of cryptocurrencies. In order to
select the reliable blockchain peers, it is urgently needed to evaluate and
predict the reliability of them. Faced with this problem, we propose H-BRP,
Hybrid Blockchain Reliability Prediction model to extract the blockchain
reliability factors then make personalized prediction for each user.
Large-scale real-world experiments are conducted on 100 blockchain requesters
and 200 blockchain peers. The implement and dataset of 2,000,000 test cases are
released. The experimental results show that the proposed model obtains better
accuracy than other approaches.
","['Peilin Zheng', 'Zibin Zheng', 'Liang Chen']"
http://arxiv.org/abs/2105.02118v1,Blockchain,2021-04-16T14:49:38Z,2021-04-16T14:49:38Z,"Managing Blockchain Systems and Applications: A Process Model for
  Blockchain Configurations","  Blockchain is a radical innovation with a unique value proposition that
shifts trust from institutions to algorithms. Still, the potential of
blockchains remains elusive due to knowledge gaps between computer science
research and socio-economic research. Building on information technology
governance literature and the theory of coevolution, this study develops a
process model for blockchain configurations that captures blockchain capability
dimensions and application areas. We demonstrate the applicability of the
proposed blockchain configuration process model on four blockchain projects.
The proposed blockchain configuration process model assists with the selection
and configuration of blockchain systems based on a set of known requirements
for a blockchain project. Our findings contribute to research by bridging
knowledge gaps between computer science and socio-economic research on
blockchain. Specifically, we explore existing blockchain concepts and integrate
them in a process model for blockchain configurations.
","['Olga Labazova', 'Erol Kazan', 'Tobias Dehling', 'Tuure Tuunanen', 'Ali Sunyaev']"
http://arxiv.org/abs/1707.01766v1,Blockchain,2017-07-06T13:03:04Z,2017-07-06T13:03:04Z,A Logic of Blockchain Updates,"  Blockchains are distributed data structures that are used to achieve
consensus in systems for cryptocurrencies (like Bitcoin) or smart contracts
(like Ethereum). Although blockchains gained a lot of popularity recently,
there is no logic-based model for blockchains available. We introduce BCL, a
dynamic logic to reason about blockchain updates, and show that BCL is sound
and complete with respect to a simple blockchain model.
","['Kai Brünnler', 'Dandolo Flumini', 'Thomas Studer']"
http://arxiv.org/abs/1803.00892v1,Blockchain,2018-03-02T15:27:39Z,2018-03-02T15:27:39Z,A Framework for Blockchain-Based Applications,"  Blockchains have recently generated explosive interest from both academia and
industry, with many proposed applications. But descriptions of many these
proposals are more visionary projections than realizable proposals, and even
basic definitions are often missing. We define ""blockchain"" and ""blockchain
network"", and then discuss two very different, well known classes of blockchain
networks: cryptocurrencies and Git repositories. We identify common primitive
elements of both and use them to construct a framework for explicitly
articulating what characterizes blockchain networks. The framework consists of
a set of questions that every blockchain initiative should address at the very
outset. It is intended to help one decide whether or not blockchain is an
appropriate approach to a particular application, and if it is, to assist in
its initial design stage.
",['Ephraim Feig']
http://arxiv.org/abs/2112.11072v2,Blockchain,2021-12-21T10:10:51Z,2022-12-27T21:31:10Z,"Scalable Multi-Chain Coordination via the Hierarchical Longest Chain
  Rule","  This paper introduces BlockReduce, a Proof-of-Work (PoW) based blockchain
system which achieves high transaction throughput through a hierarchy of merged
mined blockchains, each operating in parallel on a partition the overall
application state. Most notably, the full PoW available within the network is
applied to all blockchains in BlockReduce, and cross-blockchain state
transitions are enabled seamlessly within the core protocol. This paper shows
that, given a hierarchy of blockchains and its associated security model, the
protocol scales superlinearly in transaction throughput with the number of
blockchains operated by the protocol.
","['Yanni Georghiades', 'Karl Kreder', 'Jonathan Downing', 'Alan Orwick', 'Sriram Vishwanath']"
http://arxiv.org/abs/2210.14888v1,Blockchain,2022-10-24T11:50:18Z,2022-10-24T11:50:18Z,A Decision Framework for Blockchain Adoption,"  Blockchain and distributed ledger technologies are gaining the interest of
the academy, companies, and institutions. Nonetheless, the path toward
blockchain adoption is not straightforward, as blockchain is a complex
technology that requires revisiting the standard way of addressing problems and
tackling them from a decentralized perspective. Thus, decision-makers adopt
blockchain technology for the wrong reasons or prefer it to more suitable ones.
This work presents a decision framework for blockchain adoption to help
decision-makers decide whether blockchain is applicable, valuable, and
preferable to other technologies. In particular, The decision framework is
composed of a small set of questions that can be answered from a managerial
standpoint and that do not require a deep technical knowledge of
blockchain-related topics.
","['Vittorio Capocasale', 'Guido Perboli']"
http://arxiv.org/abs/1910.00742v1,Blockchain,2019-10-02T01:37:20Z,2019-10-02T01:37:20Z,"ChainSplitter: Towards Blockchain-based Industrial IoT Architecture for
  Supporting Hierarchical Storage","  The fast developing Industrial Internet of Things (IIoT) technologies provide
a promising opportunity to build large-scale systems to connect numerous
heterogeneous devices into the Internet. Most existing IIoT infrastructures are
based on a centralized architecture, which is easier for management but cannot
effectively support immutable and verifiable services among multiple parties.
Blockchain technology provides many desired features for large-scale IIoT
infrastructures, such as decentralization, trustworthiness, trackability, and
immutability. This paper presents a blockchain-based IIoT architecture to
support immutable and verifiable services. However, when applying blockchain
technology to the IIoT infrastructure, the required storage space posts a grant
challenge to resource-constrained IIoT infrastructures. To address the storage
issue, this paper proposes a hierarchical blockchain storage structure,
\textit{ChainSplitter}. Specially, the proposed architecture features a
hierarchical storage structure where the majority of the blockchain is stored
in the clouds, while the most recent blocks are stored in the overlay network
of the individual IIoT networks. The proposed architecture seamlessly binds
local IIoT networks, the blockchain overlay network, and the cloud
infrastructure together through two connectors, the \textit{blockchain
connector} and the \textit{cloud connector}, to construct the hierarchical
blockchain storage. The blockchain connector in the overlay network builds
blocks in blockchain from data generated in IIoT networks, and the cloud
connector resolves the blockchain synchronization issues between the overlay
network and the clouds. We also provide a case study to show the efficiency of
the proposed hierarchical blockchain storage in a practical Industrial IoT
case.
","['Gang Wang', 'Zhijie Jerry Shi', 'Mark Nixon', 'Song Han']"
http://arxiv.org/abs/2207.07453v1,Blockchain,2022-07-15T13:01:00Z,2022-07-15T13:01:00Z,"A Consensus Algorithm Based on Risk Assessment Model for Permissioned
  Blockchain","  Blockchain technology enables stakeholders to conduct trusted data sharing
and exchange without a trusted centralized institution. These features make
blockchain applications attractive to enhance trustworthiness in very different
contexts. Due to unique design concepts and outstanding performance, blockchain
has become a popular research topic in industry and academia in recent years.
Every participant is anonymous in a permissionless blockchain represented by
cryptocurrency applications such as Bitcoin. In this situation, some special
incentive mechanisms are applied to permissionless blockchain, such as mined
native cryptocurrency to solve the trust issues of permissionless blockchain.
In many use cases, permissionless blockchain has bottlenecks in transaction
throughput performance, which restricts further application in the real world.
A permissioned blockchain can reach a consensus among a group of entities that
do not establish an entire trust relationship. Unlike permissionless
blockchains, the participants must be identified in permissioned blockchains.
By relying on the traditional crash fault-tolerant consensus protocols,
permissioned blockchains can achieve high transaction throughput and low
latency without sacrificing security. However, how to balance the security and
consensus efficiency is still the issue that needs to be solved urgently in
permissioned blockchains. As the core module of blockchain technology, the
consensus algorithm plays a vital role in the performance of the blockchain
system. Thus, this paper proposes a new consensus algorithm for permissioned
blockchain, the Risk Assessment-based Consensus protocol (RAC), combined with
the decentralized design concept and the risk-node assessment mechanism to
address the unbalance issues of performance in speed, scalability, and
security.
","['Xiaohui Zhang', 'Mingying Xue', 'Xianghua Miao']"
http://arxiv.org/abs/2111.13683v1,Blockchain,2021-11-25T07:13:15Z,2021-11-25T07:13:15Z,A Survey of Blockchain Data Management Systems,"  Blockchain has been widely deployed in various sectors, such as finance,
education, and public services. Since blockchain runs as an immutable
distributed ledger, it has decentralized mechanisms with persistency,
anonymity, and auditability, where transactions are jointly performed through
cryptocurrency-based consensus algorithms by worldwide distributed nodes. There
have been many survey papers reviewing the blockchain technologies from
different perspectives, e.g., digital currencies, consensus algorithms, and
smart contracts. However, none of them have focused on the blockchain data
management systems. To fill in this gap, we have conducted a comprehensive
survey on the data management systems, based on three typical types of
blockchain, i.e., standard blockchain, hybrid blockchain, and DAG (Directed
Acyclic Graph)-based blockchain. We categorize their data management mechanisms
into three layers: blockchain architecture, blockchain data structure, and
blockchain storage engine, where block architecture indicates how to record
transactions on a distributed ledger, blockchain data structure refers to the
internal structure of each block, and blockchain storage engine specifies the
storage form of data on the blockchain system. For each layer, the works
advancing the state-of-the-art are discussed together with technical
challenges. Furthermore, we lay out the future research directions for the
blockchain data management systems.
","['Qian Wei', 'Bingzhe Li', 'Wanli Chang', 'Zhiping Jia', 'Zhaoyan Shen', 'Zili Shao']"
http://arxiv.org/abs/2407.17761v1,Blockchain,2024-07-25T04:28:52Z,2024-07-25T04:28:52Z,Towards the Blockchain Massive Adoption with Permissionless Storage,"  Blockchain technology emerged with the advent of Bitcoin and rapidly
developed over the past few decades, becoming widely accepted and known by the
public. However, in the past decades, the massive adoption of blockchain
technology has yet to come. Rather than the scalability issue, the blockchain
application is challenged by its expensive usage cost. However, the high cost
of blockchain usage is deeply connected with the blockchain consensus and
security mechanism. The permissionless blockchain must maintain its high cost
for security against the 51% Attack. Chain users indirectly cover the cost as
coins are appointed for blockchain usage fees. This conflict prevents the
massive adoption of blockchain. Thus, blockchain must be improved to solve
those problems: 1. The cost of blockchain usage should be low enough. 2. The
blockchain should remain decentralized. 3. The scalability of blockchain must
meet the demand.
  In my thesis, new approaches are applied to solve the issues above. The key
contribution is the discovery of the useful PoW. It extends the Nakamoto PoW
with another usage of file data encoding during the same Nakamoto Consensus
computation to prove honest data preservation. Based on this theory, a
permissionless storage network is proposed as the new security engine for the
blockchain. It bridges the high blockchain security cost to the storage users
with real demands who are willing to pay for the storage resource. On the other
hand, the chain users can benefit from the low transaction fee. Meanwhile, we
also provide a scalability solution to shard the blockchain. It enables high
TPS and keeps decentralization. The solutions in this thesis provide the
answers to all the dependencies of the massive adoption.
",['Jia Kan']
http://arxiv.org/abs/1907.07099v1,Blockchain,2019-07-16T16:23:25Z,2019-07-16T16:23:25Z,Blockchain Mutability: Challenges and Proposed Solutions,"  Blockchain's evolution during the past decade is astonishing: from bitcoin to
over 2.000 altcoins, and from decentralised electronic payments to transactions
programmable by smart contracts and complex tokens governed by decentralised
organisations. While the new generation of blockchain applications is still
evolving, blockchain's technical characteristics are also advancing. Yet,
immutability, a hitherto indisputable property according to which blockchain
data cannot be edited nor deleted, remains the cornerstone of blockchain's
security. Nevertheless, blockchain's immutability is being called into question
lately in the light of the new erasing requirements imposed by the GDPR's
``\textit{Right to be Forgotten (RtbF)}'' provision. As the RtbF obliges
blockchain data to be editable in order restricted content redactions,
modifications or deletions to be applied when requested, blockchains compliance
with the regulation is indeed challenging, if not impracticable. Towards
resolving this contradiction, various methods and techniques for mutable
blockchains have been proposed in an effort to satisfy regulatory erasing
requirements while preserving blockchains' security. To this end, this work
aims to provide a comprehensive review on the state-of-the-art research
approaches, technical workarounds and advanced cryptographic techniques that
have been put forward to resolve this conflict and to discuss their potentials,
constraints and limitations when applied in the wild to either permissioned or
permissionless blockchains.
","['Eugenia Politou', 'Fran Casino', 'Efthimios Alepis', 'Constantinos Patsakis']"
http://arxiv.org/abs/2001.01174v1,Blockchain,2020-01-05T05:58:41Z,2020-01-05T05:58:41Z,"Distributed Nonblocking Commit Protocols for Many-Party Cross-Blockchain
  Transactions","  The interoperability across multiple blockchains would play a critical role
in future blockchain-based data management paradigm. Existing techniques either
work only for two blockchains or requires a centralized component to govern the
cross-blockchain transaction execution, neither of which would meet the
scalability requirement. This paper proposes a new distributed commit protocol,
namely \textit{cross-blockchain transaction} (CBT), for conducting transactions
across an arbitrary number of blockchains without any centralized component.
The key idea of CBT is to extend the two-phase commit protocol with a heartbeat
mechanism to ensure the liveness of CBT without introducing additional nodes or
blockchains. We have implemented CBT and compared it to the state-of-the-art
protocols, demonstrating CBT's low overhead (3.6\% between two blockchains,
less than $1\%$ among 32 or more blockchains) and high scalability (linear
scalability on up to 64-blockchain transactions). In addition, we developed a
graphic user interface for users to virtually monitor the status of the
cross-blockchain transactions.
","['Xinying Wang', 'Olamide Timothy Tawose', 'Feng Yan', 'Dongfang Zhao']"
http://arxiv.org/abs/2010.16034v1,Blockchain,2020-10-30T02:55:19Z,2020-10-30T02:55:19Z,State sharding model on the blockchain,"  Blockchain is an incrementally updated ledger maintained by distributed nodes
rather than centralized organizations. The current blockchain technology faces
scalability issues, which include two aspects: low transaction throughput and
high storage capacity costs. This paper studies the blockchain structure based
on state sharding technology, and mainly solves the problem of non-scalability
of block chain storage. This paper designs and implements the blockchain state
sharding scheme, proposes a specific state sharding data structure and
algorithm implementation, and realizes a complete blockchain structure so that
the blockchain has the advantages of high throughput, processing a large number
of transactions and saving storage costs. Experimental results show that a
blockchain network with more than 100,000 nodes can be divided into 1024
shards. A blockchain network with this structure can process 500,000
transactions in about 5 seconds. If the consensus time of the blockchain is
about 10 seconds, and the block generation time of the blockchain system of the
sharding mechanism is 15 seconds, the transaction throughput can reach 33,000
tx/sec. Experimental results show that the throughput of the proposed protocol
increases with the increase of the network node size. This confirms the
scalability of the blockchain structure based on sharding technology.
","['Xiangyu Wang', 'Ting Yang', 'Yu Wang']"
http://arxiv.org/abs/1912.05241v1,Blockchain,2019-12-11T11:33:36Z,2019-12-11T11:33:36Z,Performance Analysis of the Libra Blockchain: An Experimental Study,"  Since Bitcoin was first introduced in 2008, many types of cryptocurrencies
have been proposed based on blockchain. However, the performance of
permissionless blockchains restricts the widespread of cryptocurrency.
Recently, Libra was proposed by Facebook based on a permissioned blockchain,
i.e. the Libra blockchain. The vision of Libra is to become a global currency
supporting financial applications, but it is doubted whether the performance of
the Libra blockchain is able to support frequent micropayment scenarios. In
this paper, we propose a methodology to evaluate the performance of blockchain
platforms and conducted an experimental study on the Libra blockchain. The
results show that the Libra blockchain can only process about one thousand
transactions per second at most, and the performance drops significantly as the
number of validators increases. Although it outperforms permissionless
blockchain platforms, the performance of the Libra blockchain is still
unsatisfactory compared to other permissioned blockchains like Hyperledger
Fabric and needs to make effective improvements in order to support global
micropayment in the future.
","['Jiashuo Zhang', 'Jianbo Gao', 'Zhenhao Wu', 'Wentian Yan', 'Qize Wu', 'Qingshan Li', 'Zhong Chen']"
http://arxiv.org/abs/2212.14671v1,Blockchain,2022-12-12T02:05:59Z,2022-12-12T02:05:59Z,Novel Architecture to Create and Maintain Personal Blockchains,"  Blockchain has been touted as a revolutionary technology. However, despite
the excitement, blockchain has not been adopted in many fields. Many are
hesitant to adopt blockchain technology due to privacy concerns, barriers to
use, or lack of practical use cases. In this work, we outline a potential
blockchain use case for tracking financial transactions across multiple
financial institutions. We show the downsides of traditional centralized
approaches and that blockchain approaches fail to give all the privacy and
accessibility required for this use case. Thus we propose a novel blockchain
architecture to support our use case. This novel architecture combines the ease
of use of public blockchains with the privacy of private blockchains by
allowing users to create personal blockchains. We believe this novel personal
blockchain architecture will lead to more blockchain adoption, particularly in
use cases handling private data.
","['Collin Connors', 'Dilip Sarkar']"
http://arxiv.org/abs/2305.03895v1,Blockchain,2023-05-06T02:15:00Z,2023-05-06T02:15:00Z,Rateless Coded Blockchain for Dynamic IoT Networks,"  A key constraint that limits the implementation of blockchain in Internet of
Things (IoT) is its large storage requirement resulting from the fact that each
blockchain node has to store the entire blockchain. This increases the burden
on blockchain nodes, and increases the communication overhead for new nodes
joining the network since they have to copy the entire blockchain. In order to
reduce storage requirements without compromising on system security and
integrity, coded blockchains, based on error correcting codes with fixed rates
and lengths, have been recently proposed. This approach, however, does not fit
well with dynamic IoT networks in which nodes actively leave and join. In such
dynamic blockchains, the existing coded blockchain approaches lead to high
communication overheads for new joining nodes and may have high decoding
failure probability. This paper proposes a rateless coded blockchain with
coding parameters adjusted to network conditions. Our goals are to minimize
both the storage requirement at each blockchain node and the communication
overhead for each new joining node, subject to a target decoding failure
probability. We evaluate the proposed scheme in the context of real-world
Bitcoin blockchain and show that both storage and communication overhead are
reduced by 99.6\% with a maximum $10^{-12}$ decoding failure probability.
","['Changlin Yang', 'Alexei Ashikhmin', 'Xiaodong Wang', 'Zibin Zheng']"
http://arxiv.org/abs/2001.02306v1,Cancer vaccine,2020-01-07T22:33:09Z,2020-01-07T22:33:09Z,"Examining Potential Usability and Health Beliefs Among Young Adults
  Using a Conversational Agent for HPV Vaccine Counseling","  The human papillomavirus (HPV) vaccine is the most effective way to prevent
HPV-related cancers. Integrating provider vaccine counseling is crucial to
improving HPV vaccine completion rates. Automating the counseling experience
through a conversational agent could help improve HPV vaccine coverage and
reduce the burden of vaccine counseling for providers. In a previous study, we
tested a simulated conversational agent that provided HPV vaccine counseling
for parents using the Wizard of OZ protocol. In the current study, we assessed
the conversational agent among young college adults (n=24), a population that
may have missed the HPV vaccine during their adolescence when vaccination is
recommended. We also administered surveys for system and voice usability, and
for health beliefs concerning the HPV vaccine. Participants perceived the agent
to have high usability that is slightly better or equivalent to other voice
interactive interfaces, and there is some evidence that the agent impacted
their beliefs concerning the harms, uncertainty, and risk denials for the HPV
vaccine. Overall, this study demonstrates the potential for conversational
agents to be an impactful tool for health promotion endeavors.
","['Muhammad Amith', 'Rebecca Lin', 'Rachel Cunningham', 'Qiwei Luna Wu', 'Lara S. Savas', 'Yang Gong', 'Julie A. Boom', 'Lu Tang', 'Cui Tao']"
http://arxiv.org/abs/1504.05383v1,Cancer vaccine,2015-04-21T10:54:10Z,2015-04-21T10:54:10Z,"HPV and cervical cancer in Moldova, epidemiological model with
  intervention cost vs benefit and effectiveness analysis","  Human papillomavirus, or HPV, is a sexually transmittable virus infection,
which is necessary risk factor for developing cervical cancer, first most
common type of cancer in working age women in Moldova. We observe both
behavioral change (sexuality increase) and demographical change (population
ageing). We used data since 1998 (Moldovan peace treaty) to adjust model
parameter and we project till around 2030 (for vaccination till 2050).
According to provided information, interdisciplinary model was proposed. It iss
set of deterministic differential equations. Stochasticity was introduced in
sexual partner change rates. The model has aggregated the most important paths
of infection, cancer development and prevention scenarios (more than 100
equations and 200 parameters). Moldovan cervical cancer perspective looks much
better, than in central western Europe countries, because of relatively young
society. In our setup, obligatory vaccination seems to not be so crucial (for
none of realistic scenarios increase of cancer cases is possible) for public
health, as in most countries in European Union. However, screening practice
could be verified in terms of efficiency, when cost benefit calculation would
be done. We propose more optimal screening guidelines (with prevention cost 5
-10k EUR per QALY), which could provide saving perspective in 10-15 year in
range 150-300k EUR yearly. Targeted vaccination could be also consider, because
costs are similar to high frequencies screening schema with the same cancer
cases projection. However, some positive side effects of vaccination as
reduction of pathogen circulation in society, will cause decrease of other
pathologies related to HPV like genital warts and other cancer.
",['Andrzej Jarynowski']
http://arxiv.org/abs/q-bio/0605046v3,Cancer vaccine,2006-05-29T06:53:50Z,2008-10-15T08:12:44Z,Different Strategies for Cancer Treatment: Mathematical Modeling,"  We formulate and analyze a mathematical model describing immune response to
avascular tumor under the influence of immunotherapy and chemotherapy and their
combinations as well as vaccine treatments. The effect of vaccine therapy is
considered as a parametric perturbation of the model. In the case of a weak
immune response, neither immunotherapy nor chemotherapy is found to cause tumor
regression to a small size, which would be below the clinically detectable
threshold. Numerical simulations show that the efficiency of vaccine therapy
depends on both the tumor size and the condition of immune system as well as on
the response of the organism to vaccination. In particular, we found that
vaccine therapy becomes more effective when used without time delay from a
prescribed date of vaccination after surgery and is ineffective without
preliminary treatment. For a strong immune response, our model predicts the
tumor remission under vaccine therapy. Our study of successive chemo/immuno,
immuno/chemo and concurrent chemoimmunotherapy shows that the chemo/immuno
sequence is more effective while concurrent chemoimmunotherapy is more sparing.
","['O. G. Isaeva', 'V. A. Osipov']"
http://arxiv.org/abs/2207.06257v1,Cancer vaccine,2022-07-13T14:56:01Z,2022-07-13T14:56:01Z,Stochastic and parameter analysis for an integrative cancer model,"  In a previous work, we presented a model that integrates cancer cell
differentiation and immunotherapy, analysing a particular therapy against
cancer stem cells by cytotoxic cell vaccines. As every biological system is
exposed to random fluctuations, it is important to study its stochasticity. The
influence of demographic and multiplicative noise in the system is carry out on
the parameters of reproduction and death in cancer cells. On the other hand, we
incorporated fluctuations by adding multiplicative noise. In both cases, we
analysed the dynamics for different values of the parameters involved. The
final amount of cancer cells decreases for different combinations of these
parameters and noise intensity is found.
","['Marcela Reale', 'David Margarit', 'Ariel Scagliotti', 'Lilia Romanelli']"
http://arxiv.org/abs/2506.06405v1,Cancer vaccine,2025-06-06T07:16:28Z,2025-06-06T07:16:28Z,"Impact of the WHO's 90-70-90 Strategy on HPV-Related Cervical Cancer
  Control: A Mathematical Model Evaluation in China","  In August 2020, the World Health Assembly approved the Global Strategy to
eliminate cervical cancer, marking the first time that numerous countries
committed to eliminating a form of cancer. China introduced the HPV vaccine in
2016 and has made significant advancements in both prevention and treatment
strategies. However, due to the relatively late introduction of the vaccine,
the burden of cervical cancer in China continues to rise. In light of this, we
develop a compartmental model to assess the impact of the WHO's 90-70-90
strategy, along with adult catch-up vaccination, on the control of HPV-induced
cervical cancer in China. We analyze the basic properties of the model and
provide proofs of the local and global asymptotic stability of the equilibrium
points. Additionally, a sensitivity analysis is performed, and we use the MCMC
algorithm to fit the number of new cervical cancer cases and deaths in China
from 1990 to 2021. The estimated basic reproduction number before and after the
introduction of the HPV vaccine in China is 1.5026 (95% CI: 1.4051-1.6002) and
1.0726 (95% CI: 0.9384-1.2067), respectively. The sensitivity analysis reveals
that screening, as a non-pharmaceutical intervention, plays a crucial role in
controlling the spread of the disease. We apply the 90-70-90 strategy to
predict the future number of new cervical cancer cases and deaths in China. The
results indicate that prioritizing the 70-90 target combination is the most
cost-effective approach and can achieve the goal of zero new cervical cancer
cases by 2061. Finally, an optimal control model is developed to explore the
best implementation strategies for HPV vaccination and screening under various
plausible scenarios.
","['Hua Liu', 'Chunya Liu', 'Yumei Wei', 'Qibin Zhang', 'Jingyan Ma']"
http://arxiv.org/abs/2411.00885v1,Cancer vaccine,2024-10-31T18:11:57Z,2024-10-31T18:11:57Z,"Revolutionizing Personalized Cancer Vaccines with NEO: Novel Epitope
  Optimization Using an Aggregated Feed Forward and Recurrent Neural Network
  with LSTM Architecture","  As cancer cases continue to rise, with a 2023 study from Zhejiang and Harvard
predicting a 31 percent increase in cases and a 21 percent increase in deaths
by 2030, the need to find more effective treatments for cancer is greater than
ever before. Traditional approaches to treating cancer, such as chemotherapy,
often kill healthy cells because of their lack of targetability. In contrast,
personalized cancer vaccines can utilize neoepitopes - distinctive peptides on
cancer cells that are often missed by the body's immune system - that have
strong binding affinities to a patient's MHC to provide a more targeted
treatment approach. The selection of optimal neoepitopes that elicit an immune
response is a time-consuming and costly process due to the required inputs of
modern predictive methods. This project aims to facilitate faster, cheaper, and
more accurate neoepitope binding predictions using Feed Forward Neural Networks
(FFNN) and Recurrent Neural Networks (RNN).
  To address this, NEO was created. NEO requires next-generation sequencing
data and uses a stacking ensemble method by calculating scores from
state-of-the-art models (MHCFlurry 1.6, NetMHCstabpan 1.0, and IEDB). The
model's architecture includes an FFNN and an RNN with LSTM layers capable of
analyzing both sequential and non-sequential data. The results from both models
are aggregated to produce predictions. Using this model, personalized cancer
vaccines can be produced with improved results (AUC = 0.9166, recall = 91.67
percent).
",['Nishanth Basava']
http://arxiv.org/abs/1607.08656v1,Cancer vaccine,2016-07-28T22:35:20Z,2016-07-28T22:35:20Z,Identifying Unvaccinated Individuals in Canada: A Predictive Model,"  Recently, the media and public health officials have become increasingly
aware of the rise in anti-vaccine sentiment. Vaccinations have numerous health
benefits for immunized individuals as well as for the general public through
herd immunity. Given the rise in immunization-preventable diseases, a
consequence of people opting out of their routine vaccinations, we determined
that Canadian health data can identify individuals over the age of 60 who chose
not to get vaccinated (80.1% negative predictive value) and individuals under
the age of 60 who have recently been vaccinated (96.4% positive predictive
value). Using the 2009-2014 Canadian Community Health Surveys (CCHS), a probit
model identified the variables that were most commonly associated with flu
vaccination outcomes. Of 1,381 variables, 47 with the most significant marginal
effects were selected, including the presence of diseases (e.g. diabetes and
cancer), behavioral characteristics (e.g. smoking and exercise), exposure to
the medical system (e.g. whether the individual gets a regular check-up), and a
person's living situation (e.g. having young children in the household). These
variables were then used to generate a Random Forest classification model,
trained on the 2009-2013 dataset, and tested on the 2014 dataset. We achieved
an overall accuracy of 87.8% between the two final models, each using 25
classification trees with bounded depth of 20 nodes, randomly selecting from
all 47 variables. With the two proposed policies, this model can be leveraged
to efficiently allocate vaccination promotion efforts. Additionally, it can be
applied to future surveys, only requiring 3.6% of the variables in the CCHS for
successful prediction.
","['Kevin Dick', 'Ardyn Nordstrom']"
http://arxiv.org/abs/2502.09659v1,Cancer vaccine,2025-02-12T06:30:31Z,2025-02-12T06:30:31Z,"Cancer Vaccine Adjuvant Name Recognition from Biomedical Literature
  using Large Language Models","  Motivation: An adjuvant is a chemical incorporated into vaccines that
enhances their efficacy by improving the immune response. Identifying adjuvant
names from cancer vaccine studies is essential for furthering research and
enhancing immunotherapies. However, the manual curation from the constantly
expanding biomedical literature poses significant challenges. This study
explores the automated recognition of vaccine adjuvant names using Large
Language Models (LLMs), specifically Generative Pretrained Transformers (GPT)
and Large Language Model Meta AI (Llama). Methods: We utilized two datasets: 97
clinical trial records from AdjuvareDB and 290 abstracts annotated with the
Vaccine Adjuvant Compendium (VAC). GPT-4o and Llama 3.2 were employed in
zero-shot and few-shot learning paradigms with up to four examples per prompt.
Prompts explicitly targeted adjuvant names, testing the impact of contextual
information such as substances or interventions. Outputs underwent automated
and manual validation for accuracy and consistency. Results: GPT-4o attained
100% Precision across all situations while exhibiting notable improve in Recall
and F1-scores, particularly with incorporating interventions. On the VAC
dataset, GPT-4o achieved a maximum F1-score of 77.32% with interventions,
surpassing Llama-3.2-3B by approximately 2%. On the AdjuvareDB dataset, GPT-4o
reached an F1-score of 81.67% for three-shot prompting with interventions,
surpassing Llama-3.2-3 B's maximum F1-score of 65.62%. Conclusion: Our findings
demonstrate that LLMs excel at identifying adjuvant names, including rare
variations of naming representation. This study emphasizes the capability of
LLMs to enhance cancer vaccine development by efficiently extracting insights.
Future work aims to broaden the framework to encompass various biomedical
literature and enhance model generalizability across various vaccines and
adjuvants.
","['Hasin Rehana', 'Jie Zheng', 'Leo Yeh', 'Benu Bansal', 'Nur Bengisu Çam', 'Christianah Jemiyo', 'Brett McGregor', 'Arzucan Özgür', 'Yongqun He', 'Junguk Hur']"
http://arxiv.org/abs/1602.08111v1,Cancer vaccine,2015-12-15T05:15:51Z,2015-12-15T05:15:51Z,A Cancer Biotherapy Resource,"  Cancer Biotherapy (CB), as opposed to cancer chemotherapy, is the use of
macromolecular, biological agents instead of organic chemicals or drugs to
treat cancer. Biological agents usually have higher selectivity and have less
toxic side effects than chemical agents. The I.S.B.T.C., being the only major
information database for CB, seems lacking in some crucial information on
various cancer biotherapy regimens. It is thus necessary to have a
comprehensive curated CB database. The database accessible to cancer patients
and also should be a sounding board for scientific ideas by cancer researchers.
The database/web server has information about main families of cancer
biotherapy regimens to date, namely, Protein Kinase Inhibitors, Ras Pathway
Inhibitors, Cell-Cycle Active Agents, MAbs (monoclonal antibodies), ADEPT
(Antibody-Directed Enzyme Pro-Drug Therapy), Cytokines, Anti-Angiogenesis
Agents, Cancer Vaccines, Cell-based Immunotherapeutics, Gene Therapy,
Hematopoietic Growth Factors, Retinoids, and CAAT. For each biotherapy regimen,
we will extract the following attributes in populating the database: Cancer
type, Gene/s and gene product/s involved, Gene sequence, Organs affected,
Reference papers, Clinical phase/stage, Survival rate, Clinical test center
locations, Cost, Patient blogs, Researcher blogs, and Future work. The database
will be accessible to public through a website and had FAQs for making it
understandable to the laymen and discussion page for researchers to express
their views and ideas. In addition to information about the biotherapy
regimens, the website will link to other biologically significant databases
like structural proteomics, metabolomics, glycomics, and lipidomics databases,
as well as to news around the world regarding cancer therapy results. The
database attributes would be regularly updated for novel attributes as
discoveries are made.
","['Preety Priya', 'Vicente M. Reyes']"
http://arxiv.org/abs/1710.06817v1,Cancer vaccine,2017-10-18T16:33:33Z,2017-10-18T16:33:33Z,"Using MRI Cell Tracking to Monitor Immune Cell Recruitment in Response
  to a Peptide-Based Cancer Vaccine","  Purpose: MRI cell tracking can be used to monitor immune cells involved in
the immunotherapy response, providing insight into the mechanism of action,
temporal progression of tumour growth and individual potency of therapies. To
evaluate whether MRI could be used to track immune cell populations in response
to immunotherapy, CD8+ cytotoxic T cells (CTLs), CD4+CD25+FoxP3+ regulatory T
cells (Tregs) and myeloid derived suppressor cells (MDSCs) were labelled with
superparamagnetic iron oxide (SPIO) particles.
  Methods: SPIO-labelled cells were injected into mice (one cell type/mouse)
implanted with an HPV-based cervical cancer model. Half of these mice were also
vaccinated with DepoVaxTM, a lipid-based vaccine platform that was developed to
enhance the potency of peptide-based vaccines.
  Results: MRI visualization of CTLs, Tregs and MDSCs was apparent 24 hours
post-injection, with hypointensities due to iron labelled cells clearing
approximately 72 hours post-injection. Vaccination resulted in increased
recruitment of CTLs and decreased recruitment of MDSCs and Tregs to the tumour.
We also found that MDSC and Treg recruitment was positively correlated with
final tumour volume.
  Conclusion: This type of analysis can be used to non-invasively study changes
in immune cell recruitment in individual mice over time, potentially allowing
improved application and combination of immunotherapies.
","['Marie-Laurence Tremblay', 'Christa Davis', 'Chris V. Bowen', 'Olivia Stanley', 'Cathryn Parsons', 'Genevieve Weir', 'Mohan Karkada', 'Marianne M. Stanford', 'Kimberly D. Brewer']"
http://arxiv.org/abs/1303.4383v1,Cancer vaccine,2013-03-16T16:54:18Z,2013-03-16T16:54:18Z,"Hierarchical hydropathic evolution of influenza glycoproteins (N2, H3,
  A/H3N2) under relentless vaccination pressure","  Hemagglutinin (HA) and neuraminidase (NA) are highly variable envelope
glycoproteins. Here hydropathic analysis, previously applied to quantify common
flu (H1N1) evolution (1934-), is applied to the evolution of less common but
more virulent (avian derived) H3N2 (1968-), beginning with N2. Whereas N1
exhibited opposing migration and vaccination pressures, the dominant N2 trend
is due to vaccination, with only secondary migration interactions. Separation
and evaluation of these effects is made possible by the use of two distinct
hydropathic scales representing first-order and second-order thermodynamic
interactions. The evolutions of H1 and H3 are more complex, with larger
competing migration and vaccination effects. The linkages of H3 and N2
evolutionary trends are examined on two modular length scales, medium
(glycosidic) and large (corresponding to sialic acid interactions). The
hierarchical hydropathic results complement and greatly extend advanced
phylogenetic results obtained from similarity studies. They exhibit simple
quantitative trends that can be transferred to engineer oncolytic properties of
other viral proteins to treat recalcitrant cancers.
",['J. C. Phillips']
http://arxiv.org/abs/2209.07527v2,Cancer vaccine,2022-09-14T11:29:15Z,2022-10-28T07:42:08Z,"Improved proteasomal cleavage prediction with positive-unlabeled
  learning","  Accurate in silico modeling of the antigen processing pathway is crucial to
enable personalized epitope vaccine design for cancer. An important step of
such pathway is the degradation of the vaccine into smaller peptides by the
proteasome, some of which are going to be presented to T cells by the MHC
complex. While predicting MHC-peptide presentation has received a lot of
attention recently, proteasomal cleavage prediction remains a relatively
unexplored area in light of recent advancesin high-throughput mass
spectrometry-based MHC ligandomics. Moreover, as such experimental techniques
do not allow to identify regions that cannot be cleaved, the latest predictors
generate decoy negative samples and treat them as true negatives when training,
even though some of them could actually be positives. In this work, we thus
present a new predictor trained with an expanded dataset and the solid
theoretical underpinning of positive-unlabeled learning, achieving a new
state-of-the-art in proteasomal cleavage prediction. The improved predictive
capabilities will in turn enable more precise vaccine development improving the
efficacy of epitope-based vaccines. Pretrained models are available on GitHub
","['Emilio Dorigatti', 'Bernd Bischl', 'Benjamin Schubert']"
http://arxiv.org/abs/2306.13582v1,Cancer vaccine,2023-06-23T16:09:31Z,2023-06-23T16:09:31Z,"Heat shock proteins may be a missing link between febrile infection and
  cancer tumor rejection via autoantigen molecular mimicry","  Numerous epidemiological studies suggest febrile infections could confer
long-term immunity to certain types of cancers, though the precise mechanisms
for this phenomenon remain unclear. Systemic heat-shock responses to fever may
be key to understanding the overlapping outcomes of immune responses to
infection and cancer. To investigate this hypothesis, we performed epitope
discovery between heat-shock proteins (HSP) and cancer-associated antigens
(CAA) and annotated the results with experimentally validated epitopes in the
Immune Epitope Database (IEDB) (Vita et al., 2019). Further, epitopes were
matched with their homologs in human pathogens. Results identified 94 epitopes
shared between HSPs and CAAs, with experimental evidence of presentation at MHC
molecules and with high homology to several epitopes of human pathogens. The
identified epitopes can be used as candidates for designing cancer vaccines.
They may also be used to identify autoreactive antibodies or TCR specificities
that, as antibody drugs and cell therapies, would reproduce the effect of
febrile infection in conferring cancer immunity. Our results support the
hypothesis that the loss of self-tolerance to HSPs during febrile infection
confers tumor immunity through molecular mimicry.
",['Amin Zia']
http://arxiv.org/abs/1904.08514v2,Cancer vaccine,2019-04-17T21:50:03Z,2019-05-22T15:49:15Z,DeepNovoV2: Better de novo peptide sequencing with deep learning,"  Personalized cancer vaccines are envisioned as the next generation rational
cancer immunotherapy. The key step in developing personalized therapeutic
cancer vaccines is to identify tumor-specific neoantigens that are on the
surface of tumor cells. A promising method for this is through de novo peptide
sequencing from mass spectrometry data. In this paper we introduce DeepNovoV2,
the state-of-the-art model for peptide sequencing. In DeepNovoV2, a spectrum is
directly represented as a set of (m/z, intensity) pairs, therefore it does not
suffer from the accuracy-speed/memory trade-off problem. The model combines an
order invariant network structure (T-Net) and recurrent neural networks and
provides a complete end-to-end training and prediction framework to sequence
patterns of peptides. Our experiments on a wide variety of data from different
species show that DeepNovoV2 outperforms previous state-of-the-art methods,
achieving 13.01-23.95\% higher accuracy at the peptide level.
","['Rui Qiao', 'Ngoc Hieu Tran', 'Lei Xin', 'Baozhen Shan', 'Ming Li', 'Ali Ghodsi']"
http://arxiv.org/abs/1911.09765v1,Cancer vaccine,2019-11-21T21:49:16Z,2019-11-21T21:49:16Z,"Mixture survival models methodology: an application to cancer
  immunotherapy assessment in clinical trials","  Progress in immunotherapy revolutionized the treatment landscape for advanced
lung cancer, raising survival expectations beyond those that were historically
anticipated with this disease. In the present study, we describe the methods
for the adjustment of mixture parametric models of two populations for survival
analysis in the presence of long survivors. A methodology is proposed in
several five steps: first, it is proposed to use the multimodality test to
decide the number of subpopulations to be considered in the model, second to
adjust simple parametric survival models and mixture distribution models, to
estimate the parameters and to select the best model fitted the data, finally,
to test the hypotheses to compare the effectiveness of immunotherapies in the
context of randomized clinical trials. The methodology is illustrated with data
from a clinical trial that evaluates the effectiveness of the therapeutic
vaccine CIMAvaxEGF vs the best supportive care for the treatment of advanced
lung cancer. The mixture survival model allows estimating the presence of a
subpopulation of long survivors that is 44% for vaccinated patients. The
differences between the treated and control group were significant in both
subpopulations (population of short-term survival: p = 0.001, the population of
long-term survival: p = 0.0002). For cancer therapies, where a proportion of
patients achieves long-term control of the disease, the heterogeneity of the
population must be taken into account. Mixture parametric models may be more
suitable to detect the effectiveness of immunotherapies compared to standard
models.
","['Lizet Sanchez', 'Patricia Lorenzo-Luaces', 'Claudia Fonte', 'Agustin Lage']"
http://arxiv.org/abs/1607.07503v1,Cancer vaccine,2016-07-25T23:09:59Z,2016-07-25T23:09:59Z,Genomic data analysis in tree spaces,"  Recently, an elegant approach in phylogenetics was introduced by
Billera-Holmes-Vogtmann that allows a systematic comparison of different
evolutionary histories using the metric geometry of tree spaces. In many
problem settings one encounters heavily populated phylogenetic trees, where the
large number of leaves encumbers visualization and analysis in the relevant
evolutionary moduli spaces. To address this issue, we introduce tree
dimensionality reduction, a structured approach to reducing large phylogenetic
trees to a distribution of smaller trees. We prove a stability theorem ensuring
that small perturbations of the large trees are taken to small perturbations of
the resulting distributions.
  We then present a series of four biologically motivated applications to the
analysis of genomic data, spanning cancer and infectious disease. The first
quantifies how chemotherapy can disrupt the evolution of common leukemias. The
second examines a link between geometric information and the histologic grade
in relapsed gliomas, where longer relapse branches were specific to high grade
glioma. The third concerns genetic stability of xenograft models of cancer,
where heterogeneity at the single cell level increased with later mouse
passages. The last studies genetic diversity in seasonal influenza A virus. We
apply tree dimensionality reduction to 24 years of longitudinally collected
H3N2 hemagglutinin sequences, generating distributions of smaller trees
spanning between three and five seasons. A negative correlation is observed
between the influenza vaccine effectiveness during a season and the variance of
the distributions produced using preceding seasons' sequence data. We also show
how tree distributions relate to antigenic clusters and choice of influenza
vaccine. Our formalism exposes links between viral genomic data and clinical
observables such as vaccine selection and efficacy.
","['Sakellarios Zairis', 'Hossein Khiabanian', 'Andrew J. Blumberg', 'Raul Rabadan']"
http://arxiv.org/abs/1306.2898v1,Cancer vaccine,2013-06-12T17:06:40Z,2013-06-12T17:06:40Z,Defining a Simulation Strategy for Cancer Immunocompetence,"  Although there are various types of cancer treatments, none of these
currently take into account the effect of ageing of the immune system and hence
altered responses to cancer. Recent studies have shown that in vitro
stimulation of T cells can help in the treatment of patients. There are many
factors that have to be considered when simulating an organism's
immunocompetence. Our particular interest lies in the study of loss of
immunocompetence with age. We are trying to answer questions such as: Given a
certain age of a patient, how fit is their immune system to fight cancer? Would
an immune boost improve the effectiveness of a cancer treatment given the
patient's immune phenotype and age? We believe that understanding the processes
of immune system ageing and degradation through computer simulation may help in
answering these questions. Specifically, we have decided to look at the change
in numbers of naive T cells with age, as they play a important role in
responses to cancer and anti-tumour vaccination. In this work we present an
agent-based simulation model to understand the interactions which influence the
naive T cell populations over time. Our agent model is based on existing
mathematical system dynamic model, but in comparisons offers better scope for
customisation and detailed analysis. We believe that the results obtained can
in future help with the modelling of T cell populations inside tumours.
","['Grazziela P. Figueredo', 'Uwe Aickelin']"
http://arxiv.org/abs/1708.08160v1,Cancer vaccine,2017-08-28T01:38:06Z,2017-08-28T01:38:06Z,"Determining Positive Cancer Rescue Mutations in p53 Based Cancers by
  using Artificial Intelligence","  A mutation in a protein-coding gene in DNA can alter the protein structure
coded by the same gene. Structurally altered proteins usually lose their
functions and sometimes gain an undesirable function instead. These types of
mutations and their effects can result in genetic diseases or antibiotic
resistant bacteria, among other health issues. Important curing methods have
been developed for detecting mutations against AIDS as well as genetic
diseases. Another example is the influenza virus. The reasons why a vaccination
developed to fight against influenza does not work the following year are (a)
the mutation of its DNA and (b) the outbreak of the virus after it has been
mutated especially if it is a virus that escaped the vaccinations target. Due
to such reasons, it is highly important to know in advance the location of a
potential mutation in a protein as well as the problems it might cause the
medical sciences. In this study we have used artificial neural networks, which
are one of the latest artificial intelligence technologies, to determine the
effects of cancer mutations. The model we developed has given more successful
results compared to other methods. We foresee that our model will bring a new
dimension to medical research and the medical industry.
","['Kaan Aygen', 'Berkay Celik', 'Umut Eser']"
http://arxiv.org/abs/2505.06067v1,Cancer vaccine,2025-05-09T14:03:41Z,2025-05-09T14:03:41Z,"Oncolytic mechanisms and immunotherapeutic potential of Newcastle
  disease virus in cancer therapy","  Newcastle Disease Virus (NDV), classified as Avian orthoavulavirus 1 (avian
paramyxovirus type 1), is a promising oncolytic agent that selectively targets
and destroys cancer cells while sparing normal tissues. Its oncoselectivity
exploits cancer-specific defects in antiviral defenses, particularly impaired
Type I interferon signaling, and dysregulated apoptotic pathways, enabling
robust viral replication and cytotoxicity in malignancies such as breast,
colorectal, and melanoma. NDV induces intrinsic and extrinsic apoptosis through
caspase activation and triggers immunogenic cell death via damage-associated
molecular patterns, stimulating potent antitumours immune responses.
Additionally, NDVs potential as a vaccine vector, expressing tumours-associated
antigens, offers prospects for prophylactic and therapeutic cancer
applications. This review provides a comprehensive analysis of NDVs morphology,
classification, and molecular biology, focusing on its viral entry and
replication mechanisms in host cells. It explores NDVs interactions with cancer
cells, emphasizing its ability to induce cytotoxicity and immune activation.
Understanding these mechanisms is critical for optimizing NDVs oncolytic
potential and advancing its clinical translation. Future directions include
enhancing NDV through genetic engineering, combining it with therapies like
immune checkpoint inhibitors, and developing personalized medicine approaches
tailored to tumours genomic profiles. These advancements position NDV as a
versatile therapeutic agent in oncolytic virotherapy.
","['Umar Ahmad', 'Surializa Harun', 'Moussa Moise Diagne', 'Syahril Abdullah', 'Khatijah Yusoff', 'Abhi Veerakumarasivam']"
http://arxiv.org/abs/2207.05964v1,Cancer vaccine,2022-07-13T05:05:53Z,2022-07-13T05:05:53Z,"Co-evolution of Vaccination Behavior and Perceived Vaccination Risk can
  lead to a Stag-Hunt like Game","  Voluntary vaccination is effective to prevent infectious diseases from
spreading. Both vaccination behavior and cognition of the vaccination risk play
important roles in individual vaccination decision making. However, it is not
clear how the co-evolution of the two shapes the population-wide vaccination
behavior. We establish a coupled dynamics of epidemic, vaccination behavior and
perceived vaccination risk with three different time scales. We assume that the
increase of vaccination level inhibits the rise of perceived vaccination risk,
and the increase of perceived vaccination risk inhibits the rise of vaccination
level. It is shown that the resulting vaccination behavior is similar to the
stag-hunt game, provided that the basic reproductive ratio is moderate and that
the epidemic dynamics evolves fast. This is in contrast with the previous view
that vaccination is a snowdrift like game. Furthermore, we find that epidemic
breaks out repeatedly and eventually leads to vaccine scares if these three
dynamics evolve on a similar time scale. And we propose some ways to promote
vaccination behavior, such as controlling side-effect bias and perceived
vaccination costs. Our work sheds light on epidemic control via vaccination by
taking into account the co-evolutionary dynamics of cognition and behavior.
","['Yuan Liu', 'Bin Wu']"
http://arxiv.org/abs/2407.09982v1,Cultured meat,2024-04-30T13:35:18Z,2024-04-30T13:35:18Z,"Artificial intelligence and machine learning applications for cultured
  meat","  Cultured meat has the potential to provide a complementary meat industry with
reduced environmental, ethical, and health impacts. However, major
technological challenges remain which require time- and resource-intensive
research and development efforts. Machine learning has the potential to
accelerate cultured meat technology by streamlining experiments, predicting
optimal results, and reducing experimentation time and resources. However, the
use of machine learning in cultured meat is in its infancy. This review covers
the work available to date on the use of machine learning in cultured meat and
explores future possibilities. We address four major areas of cultured meat
research and development: establishing cell lines, cell culture media design,
microscopy and image analysis, and bioprocessing and food processing
optimization. This review aims to provide the foundation necessary for both
cultured meat and machine learning scientists to identify research
opportunities at the intersection between cultured meat and machine learning.
","['Michael E. Todhunter', 'Sheikh Jubair', 'Ruchika Verma', 'Rikard Saqe', 'Kevin Shen', 'Breanna Duffy']"
http://arxiv.org/abs/2401.02691v1,Cultured meat,2024-01-05T07:46:07Z,2024-01-05T07:46:07Z,"Scaffolding fundamentals and recent advances in sustainable scaffolding
  techniques for cultured meat development","  In cultured meat (CM) products the paramount significance lies in the
fundamental attributes like texture and sensory of the processed end product.
To cater to the tactile and gustatory preferences of real meat, the product
needs to be designed to incorporate its texture and sensory attributes.
Presently CM products are mainly grounded products like sausage, nugget,
frankfurter, burger patty, surimi, and steak with less sophistication and need
to mimic real meat to grapple with the traditional meat market. The existence
of fibrous microstructure in connective and muscle tissues has attracted
considerable interest in the realm of tissue engineering. Scaffolding plays an
important role in CM production by aiding cell adhesion, growth,
differentiation, and alignment. A wide array of scaffolding technologies has
been developed for implementation in the realm of biomedical research. In
recent years researchers also focus on edible scaffolding to ease the process
of CM. However, it is imperative to implement cutting edge technologies like 3D
scaffolds, 3D printing, electrospun nanofibers in order to advance the creation
of sustainable and edible scaffolding methods in CM production, with the
ultimate goal of replicating the sensory and nutritional attributes to mimic
real meat cut. This review discusses recent advances in scaffolding techniques
and biomaterials related to structured CM production and required advances to
create muscle fiber structures to mimic real meat.
  Keywords: Cultured meat, Scaffolding, Biomaterials, Edible scaffolding,
Electrospinning, 3D bioprinting, real meat.
","['AMM Nurul Alam', 'Chan-Jin Kim', 'So-Hee Kim', 'Swati Kumari', 'Eun-Yeong Lee', 'Young-Hwa Hwang', 'Seon-Tea Joo']"
http://arxiv.org/abs/1806.09912v1,Cultured meat,2018-06-26T11:16:15Z,2018-06-26T11:16:15Z,"Boiling, steaming or rinsing? (physics of the Chinese cuisine)","  Some physical aspects of Chinese cuisine are discussed. We start from the
cultural and historical particularities of the Chinese cuisine and technologies
of food production. What is the difference between raw and boiled meat? What is
the difference in the physical processes of heat transfer during steaming of
dumplings and their cooking in boiling water? Why is it possible to cook meat
stripes in a ""hot pot"" in ten seconds, while baking a turkey requires several
hours? This article is devoted to discussion of these questions.
","['Andrey Varlamov', 'Zheng Zhou', 'Yan Chen']"
http://arxiv.org/abs/1306.5104v1,Cultured meat,2013-06-21T11:30:13Z,2013-06-21T11:30:13Z,Preference for meat is not innate in dogs,"  Indian free ranging dogs live in a carbohydrate rich environment as
scavengers in and around human settlements. They rarely hunt and consequently
do not encounter rich sources of protein. Instead they have adapted to a diet
of primarily carbohydrates. As descendants of the exclusively carnivorous
wolves, they are subjected to the evolutionary load of a physiological demand
for proteins. To meet their protein needs they resort to a thumb rule, if it
smells like meat, eat it. Pups face high competition from group and non group
members and are in a phase of rapid growth with high protein demands. Following
the thumb rule, then they can acquire more protein at the cost of increased
competition and reduced supplementary non protein nutrition. However, if the
mother supplements their diet with protein rich regurgitates and milk, then the
pups can benefit by being generalists. Using a choice test in the field we show
that while adults have a clear preference for meat, pups have no such
preference, and they even eat degraded protein eagerly. Thus the thumb rule
used by adult dogs for efficient scavenging is not innate, and needs to be
learned. The thumb rule might be acquired by cultural transmission, through
exposure to meat in the regurgitate of the mother, or while accompanying her on
foraging trips.
","['Anandarup Bhadra', 'Anindita Bhadra']"
http://arxiv.org/abs/2308.02700v2,Cultured meat,2023-08-04T20:35:59Z,2023-08-23T20:01:55Z,"Simultaneous self-organization of arterial and venous networks driven by
  the physics of global power optimization","  Understanding of vascular organization is a long-standing problem in
quantitative biology and biophysics and is essential for the growth of large
cultured tissues. Approaches are needed that (1) make predictions of optimal
arteriovenous networks in order to understand the natural vasculatures that
originate from evolution (2) can design vasculature for 3D printing of cultured
tissues, meats, organoids and organs. I present a method for determining the
globally optimal structure of interlocking arterial and venous (arteriovenous)
networks. The core physics is comprised of the minimization of total power
associated with the whole vascular network, with penalties to stop arterial and
venous segments from intersecting. Specifically, the power needed for
Poiseuille flow through vessels and the metabolic power cost for blood
maintenance are optimized. Simultaneous determination of both arterial and
venous vasculatures is essential to avoid intersections between vessels that
would bypass the capillary network. As proof-of-concept, I examine the optimal
vascular structure for supplying square- and disk-like tissue shapes that would
be suitable for bioprinting in multi-well plates. Features in the trees are
driven by the bifurcation exponent and metabolic constant which affect whether
arteries and veins follow the same or different routes through the tissue. They
also affect the level of tortuosity in the vessels. The method could be used to
understand the distribution of blood vessels within organs, to form the core of
simulations, and combined with 3D printing to generate vasculatures for
arbitrary volumes of cultured tissue and cultured meat.
",['James P. Hague']
http://arxiv.org/abs/2306.13435v1,Cultured meat,2023-06-23T10:58:40Z,2023-06-23T10:58:40Z,"High-throughput design of cultured tissue moulds using a biophysical
  model","  The technique presented here identifies tethered mould designs, optimised for
growing cultured tissue with very highly-aligned cells. It is based on a
microscopic biophysical model for polarised cellular hydrogels. There is an
unmet need for tools to assist mould and scaffold designs for the growth of
cultured tissues with bespoke cell organisations, that can be used in
applications such as regenerative medicine, drug screening and cultured meat.
High-throughput biophysical calculations were made for a wide variety of
computer-generated moulds, with cell-matrix interactions and tissue-scale
forces simulated using a contractile-network dipole-orientation model.
Elongated moulds with central broadening and one of the following tethering
strategies are found to lead to highly-aligned cells: (1) tethers placed within
the bilateral protrusions resulting from an indentation on the short edge, to
guide alignment (2) tethers placed within a single vertex to shrink the
available space for misalignment. As such, proof-of-concept has been shown for
mould and tethered scaffold design based on a recently developed biophysical
model. The approach is applicable to a broad range of cell types that align in
tissues and is extensible for 3D scaffolds.
","['James P. Hague', 'Allison E. Andrews', 'Hugh Dickinson']"
http://arxiv.org/abs/2410.13685v1,Cultured meat,2024-10-17T15:47:12Z,2024-10-17T15:47:12Z,"Label-free prediction of fluorescence markers in bovine satellite cells
  using deep learning","  Assessing the quality of bovine satellite cells (BSCs) is essential for the
cultivated meat industry, which aims to address global food sustainability
challenges. This study aims to develop a label-free method for predicting
fluorescence markers in isolated BSCs using deep learning. We employed a
U-Net-based CNN model to predict multiple fluorescence signals from a single
bright-field microscopy image of cell culture. Two key biomarkers, DAPI and
Pax7, were used to determine the abundance and quality of BSCs. The image
pre-processing pipeline included fluorescence denoising to improve prediction
performance and consistency. A total of 48 biological replicates were used,
with statistical performance metrics such as Pearson correlation coefficient
and SSIM employed for model evaluation. The model exhibited better performance
with DAPI predictions due to uniform staining. Pax7 predictions were more
variable, reflecting biological heterogeneity. Enhanced visualization
techniques, including color mapping and image overlay, improved the
interpretability of the predictions by providing better contextual and
perceptual information. The findings highlight the importance of data
pre-processing and demonstrate the potential of deep learning to advance
non-invasive, label-free assessment techniques in the cultivated meat industry,
paving the way for reliable and actionable AI-driven evaluations.
","['Sania Sinha', 'Aarham Wasit', 'Won Seob Kim', 'Jongkyoo Kim', 'Jiyoon Yi']"
http://arxiv.org/abs/2202.13672v2,Cultured meat,2022-02-28T10:42:45Z,2022-06-08T06:23:38Z,Molecular and colloidal transport in bacterial cellulose hydrogels,"  Bacterial cellulose biofilms are complex networks of strong interwoven
nanofibers that control transport and protect bacterial colonies in the film.
Design of diverse applications of bacterial cellulose films also relies on
understanding and controlling transport through the fiber mesh, and transport
simulations of the films are most accurate when guided by experimental
characterization of the structures and the resultant diffusion inside.
Diffusion through such films is a function of their key microstructural length
scales, determining how molecules, as well as particles and microorganisms,
permeate them. We use microscopy to study the unique bacterial cellulose film
structure and quantify the mobility dynamics of various sizes of tracer
particles and macromolecules. Mobility is hindered within the films, as
confinement and local movement strongly depend on void size relative to
diffusing tracers. The biofilms have a naturally periodic structure of
alternating dense and porous layers of nanofiber mesh, and we tune the
magnitude of the spacing via fermentation conditions. Micron-sized particles
can diffuse through the porous layers, but can not penetrate the dense layers.
Tracer mobility in the porous layers is isotropic, indicating a largely random
pore structure there. Molecular diffusion through the whole film is only
slightly reduced by the structural tortuosity. Knowledge of transport
variations within bacterial cellulose networks can be used to guide design of
symbiotic cultures in these structures and enhance their use in applications
biomedical implants, wound dressings, lab-grown meat, and sensors.
","['Firoozeh Babayekhorasani', 'Maryam Hosseini', 'Patrick T. Spicer']"
http://arxiv.org/abs/2401.07875v1,Cultured meat,2024-01-15T18:08:54Z,2024-01-15T18:08:54Z,Safely and Autonomously Cutting Meat with a Collaborative Robot Arm,"  Labor shortages in the United States are impacting a number of industries
including the meat processing sector. Collaborative technologies that work
alongside humans while increasing production abilities may support the industry
by enhancing automation and improving job quality. However, existing automation
technologies used in the meat industry have limited collaboration potential,
low flexibility, and high cost. The objective of this work was to explore the
use of a robot arm to collaboratively work alongside a human and complete tasks
performed in a meat processing facility. Toward this objective, we demonstrated
proof-of-concept approaches to ensure human safety while exploring the capacity
of the robot arm to perform example meat processing tasks. In support of human
safety, we developed a knife instrumentation system to detect when the cutting
implement comes into contact with meat within the collaborative space. To
demonstrate the capability of the system to flexibly conduct a variety of basic
meat processing tasks, we developed vision and control protocols to execute
slicing, trimming, and cubing of pork loins. We also collected a subjective
evaluation of the actions from experts within the U.S. meat processing
industry. On average the experts rated the robot's performance as adequate.
Moreover, the experts generally preferred the cuts performed in collaboration
with a human worker to cuts completed autonomously, highlighting the benefits
of robotic technologies that assist human workers rather than replace them.
Video demonstrations of our proposed framework can be found here:
https://youtu.be/56mdHjjYMVc
","['Ryan Wright', 'Sagar Parekh', 'Robin White', 'Dylan P. Losey']"
http://arxiv.org/abs/2402.13439v1,Cultured meat,2024-02-21T00:16:08Z,2024-02-21T00:16:08Z,"Estimating Demand for Lamb, Beef, Pork, and Poultry in Canada","  This paper investigates the demand for lamb, beef, pork, and poultry in
Canada, both at the national level and in disaggregated provinces, to identify
meat consumption patterns in different provinces. Meat consumption plays a
significant role in Canada's economy and is an important source of calories for
the population. However, meat demand faces several consumption challenges due
to logistic constraints, as a significant portion of the supply is imported
from other countries. Therefore, there is a need for a better understanding of
the causal relationships underlying lamb, beef, pork, and poultry consumption
in Canada. Until recently, there have been no attempts to estimate meat
consumption at the provincial level in Canada. Different Almost Ideal Demand
System (AIDS) models have been applied for testing specifications to circumvent
several econometric and theoretical problems. In particular, generalized AIDS
and its Quadratic extension QUAIDS methods have been estimated across each
province using the Iterative Linear Least Squares Estimator (ILLE) estimation
Method. Weekly retail meat consumption price and quantity data from 2019 to
2022 have been used for Canada and for each province namely Quebec, Maritime
provinces (New Brunswick, Nova Scotia, and Prince Edward Island), Ontario,
total West (Yukon, Northwest Territory and Nunavut), Alberta,
Manitoba-Saskatchewan and Manitoba as well as British Columbia. Consistent
coefficients and demand elasticities estimates reveal patterns of substitution
and/or complementarity between the four categories of meat. Meat consumption
patterns differ across each province. Results show that the demand for the four
categories of meat is responsive to price changes. Overall, lamb expenditure
was found to be elastic and thus considered a luxury good during the study
period, while the other three categories are considered normal goods across
Canada.
",['Zakary Rodrigue Diakité']
http://arxiv.org/abs/2504.04872v1,Cultured meat,2025-04-07T09:27:37Z,2025-04-07T09:27:37Z,Simulating Persuasive Dialogues on Meat Reduction with Generative Agents,"  Meat reduction benefits human and planetary health, but social norms keep
meat central in shared meals. To date, the development of communication
strategies that promote meat reduction while minimizing social costs has
required the costly involvement of human participants at each stage of the
process. We present work in progress on simulating multi-round dialogues on
meat reduction between Generative Agents based on large language models (LLMs).
We measure our main outcome using established psychological questionnaires
based on the Theory of Planned Behavior and additionally investigate Social
Costs. We find evidence that our preliminary simulations produce outcomes that
are (i) consistent with theoretical expectations; and (ii) valid when compared
to data from previous studies with human participants. Generative agent-based
models are a promising tool for identifying novel communication strategies on
meat reduction-tailored to highly specific participant groups-to then be tested
in subsequent studies with human participants.
","['Georg Ahnert', 'Elena Wurth', 'Markus Strohmaier', 'Jutta Mata']"
http://arxiv.org/abs/2503.08664v1,Cultured meat,2025-03-11T17:50:59Z,2025-03-11T17:50:59Z,"MEAT: Multiview Diffusion Model for Human Generation on Megapixels with
  Mesh Attention","  Multiview diffusion models have shown considerable success in image-to-3D
generation for general objects. However, when applied to human data, existing
methods have yet to deliver promising results, largely due to the challenges of
scaling multiview attention to higher resolutions. In this paper, we explore
human multiview diffusion models at the megapixel level and introduce a
solution called mesh attention to enable training at 1024x1024 resolution.
Using a clothed human mesh as a central coarse geometric representation, the
proposed mesh attention leverages rasterization and projection to establish
direct cross-view coordinate correspondences. This approach significantly
reduces the complexity of multiview attention while maintaining cross-view
consistency. Building on this foundation, we devise a mesh attention block and
combine it with keypoint conditioning to create our human-specific multiview
diffusion model, MEAT. In addition, we present valuable insights into applying
multiview human motion videos for diffusion training, addressing the
longstanding issue of data scarcity. Extensive experiments show that MEAT
effectively generates dense, consistent multiview human images at the megapixel
level, outperforming existing multiview diffusion methods.
","['Yuhan Wang', 'Fangzhou Hong', 'Shuai Yang', 'Liming Jiang', 'Wayne Wu', 'Chen Change Loy']"
http://arxiv.org/abs/2208.13484v1,Cultured meat,2022-08-29T10:37:31Z,2022-08-29T10:37:31Z,"Pasture Intake Protects Against Commercial Diet-induced
  Lipopolysaccharide Production Facilitated by Gut Microbiota through
  Activating Intestinal Alkaline Phosphatase Enzyme in Meat Geese","  In-house feeding system (IHF, a low dietary fiber source) may cause altered
cecal microbiota composition and inflammatory responses in meat geese via
increased endotoxemia (lipopolysaccharides) with reduced intestinal alkaline
phosphatase (ALP) production. The effects of artificial pasture grazing system
(AGF, a high dietary fiber source) on modulating gut microbiota architecture
and gut barrier functions have not been investigated in meat geese. The
intestinal ALP functions to regulate gut microbial homeostasis and barrier
function appears to inhibit pro-inflammatory cytokines by reducing LPS-induced
reactive oxygen species (ROS) production. The purpose of our study was to
investigate whether this enzyme could play a critical role in attenuating ROS
generation and then ROS facilitated NF-\k{appa}B pathway-induced systemic
inflammation in meat geese. First, we assessed the impacts of IHF and AGF on
gut microbial composition via 16 sRNA sequencing in meat geese. In the gut
microbiota analysis, meat geese supplemented with pasture demonstrated a
significant reduction in microbial richness and diversity compared to IHF meat
geese demonstrating antimicrobial, antioxidation, and anti-inflammatory ability
of AGF system. Second host markers analysis through protein expression of serum
and cecal tissues and quantitative PCR of cecal tissues were evaluated. We
confirmed a significant increase in intestinal ALP-induced Nrf2 signaling
pathway representing LPS dephosphorylation mediated TLR4/MyD88 induced ROS
reduction mechanisms in AGF meat geese. Further, the correlation analysis of
top 44 host markers with gut microbiota shows that artificial pasture intake
induced gut barrier functions via reducing ROS-mediated NF-\k{appa}B
pathway-induced gut permeability, systemic inflammation, and aging phenotypes.
","['Qasim Ali', 'Sen Ma', 'Umar Farooq', 'Jiakuan Niu', 'Fen Li', 'Muhammad Abaidullah', 'Boshuai Liu', 'Shaokai La', 'Defeng Li', 'Zhichang Wang', 'Hao Sun', 'Yalei Cui', 'Yinghua Shi']"
http://arxiv.org/abs/2005.12671v1,Cultured meat,2020-04-12T15:43:14Z,2020-04-12T15:43:14Z,"Towards real time assessment of intramuscular fat content in meat using
  optical fibre-based optical coherence tomography","  We consider the use of optical coherence tomography (OCT) imaging to predict
the quality of meat. We find that intramuscular fat (IMF) absorbs infrared
light about nine times stronger than muscle, which enables us to estimate fat
content in intact meat samples. The method is made very efficient by extracting
relevant information from the three-dimensional high-resolution images
generated by OCT using principal component analysis (PCA). The principal
components are then used as regressors into a support vector regression (SVR)
prediction model. The SVR model is found to predict IMF content stably and
accurately, with an R^2 value of 0.94. Our study paves the way for automated,
contact-less, non-destructive, real time classification of the quality of meat
samples.
","['Abi Thampi', 'Sam Hitchman', 'Stéphane Coen', 'Frédérique Vanholsbeeck']"
http://arxiv.org/abs/2210.05358v2,Cultured meat,2022-10-06T15:03:23Z,2022-10-18T10:05:09Z,On estimating Armington elasticities for Japan's meat imports,"  By fully accounting for the distinct tariff regimes levied on imported meat,
we estimate substitution elasticities of Japan's two-stage import aggregation
functions for beef, chicken and pork. While the regression analysis crucially
depends on the price that consumers face, the post-tariff price of imported
meat depends not only on ad valorem duties but also on tariff rate quotas and
gate price system regimes. The effective tariff rate is consequently evaluated
by utilizing monthly transaction data. To address potential endogeneity
problems, we apply exchange rates that we believe to be independent of the
demand shocks for imported meat. The panel nature of the data allows us to
retrieve the first-stage aggregates via time dummy variables, free of demand
shocks, to be used as part of the explanatory variable and as an instrument in
the second-stage regression.
","['Satoshi Nakano', 'Kazuhiko Nishimura']"
http://arxiv.org/abs/2406.14259v1,Cultured meat,2024-06-20T12:28:47Z,2024-06-20T12:28:47Z,"MEAT: Median-Ensemble Adversarial Training for Improving Robustness and
  Generalization","  Self-ensemble adversarial training methods improve model robustness by
ensembling models at different training epochs, such as model weight averaging
(WA). However, previous research has shown that self-ensemble defense methods
in adversarial training (AT) still suffer from robust overfitting, which
severely affects the generalization performance. Empirically, in the late
phases of training, the AT becomes more overfitting to the extent that the
individuals for weight averaging also suffer from overfitting and produce
anomalous weight values, which causes the self-ensemble model to continue to
undergo robust overfitting due to the failure in removing the weight anomalies.
To solve this problem, we aim to tackle the influence of outliers in the weight
space in this work and propose an easy-to-operate and effective Median-Ensemble
Adversarial Training (MEAT) method to solve the robust overfitting phenomenon
existing in self-ensemble defense from the source by searching for the median
of the historical model weights. Experimental results show that MEAT achieves
the best robustness against the powerful AutoAttack and can effectively
allievate the robust overfitting. We further demonstrate that most defense
methods can improve robust generalization and robustness by combining with
MEAT.
","['Zhaozhe Hu', 'Jia-Li Yin', 'Bin Chen', 'Luojun Lin', 'Bo-Hao Chen', 'Ximeng Liu']"
http://arxiv.org/abs/2504.00066v1,Cultured meat,2025-03-31T16:16:58Z,2025-03-31T16:16:58Z,"Meat, Vegetable, Soup -- The First Successful Attempt to Classify
  Everything","  We present the results of a novel classification scheme for all items,
objects, concepts, and crucially -- things -- in the known and unknown
universe. Our definitions of meat, soup and vegetable are near-exhaustive and
represent a new era of scientific discovery within the rapidly-developing field
of Arbitrary Classification. While the definitions of vegetable (growing in the
ground), meat (growing in an animal) and soup (containing both vegetable and
meat) may appear simple at first, we discuss a range of complex cases in which
progress is rapidly being made, and provide definitions and clarifications for
as many objects as a weekend of typing will allow.
","['G. Weaver', 'M. J. Selfridge', 'J. M. Setchfield', 'F. Dresbach', 'V. Varma', 'J. Martinez Garcia', 'A. Moharana', 'J. Keegans', 'L. J. Adams']"
http://arxiv.org/abs/2203.11684v1,Cultured meat,2022-03-22T12:58:39Z,2022-03-22T12:58:39Z,Meta-attention for ViT-backed Continual Learning,"  Continual learning is a longstanding research topic due to its crucial role
in tackling continually arriving tasks. Up to now, the study of continual
learning in computer vision is mainly restricted to convolutional neural
networks (CNNs). However, recently there is a tendency that the newly emerging
vision transformers (ViTs) are gradually dominating the field of computer
vision, which leaves CNN-based continual learning lagging behind as they can
suffer from severe performance degradation if straightforwardly applied to
ViTs. In this paper, we study ViT-backed continual learning to strive for
higher performance riding on recent advances of ViTs. Inspired by mask-based
continual learning methods in CNNs, where a mask is learned per task to adapt
the pre-trained ViT to the new task, we propose MEta-ATtention (MEAT), i.e.,
attention to self-attention, to adapt a pre-trained ViT to new tasks without
sacrificing performance on already learned tasks. Unlike prior mask-based
methods like Piggyback, where all parameters are associated with corresponding
masks, MEAT leverages the characteristics of ViTs and only masks a portion of
its parameters. It renders MEAT more efficient and effective with less overhead
and higher accuracy. Extensive experiments demonstrate that MEAT exhibits
significant superiority to its state-of-the-art CNN counterparts, with 4.0~6.0%
absolute boosts in accuracy. Our code has been released at
https://github.com/zju-vipa/MEAT-TIL.
","['Mengqi Xue', 'Haofei Zhang', 'Jie Song', 'Mingli Song']"
http://arxiv.org/abs/2412.11167v2,Cultured meat,2024-12-15T12:30:52Z,2025-02-16T12:21:29Z,Cultural Palette: Pluralising Culture Alignment via Multi-agent Palette,"  Large language models (LLMs) face challenges in aligning with diverse
cultural values despite their remarkable performance in generation, which stems
from inherent monocultural biases and difficulties in capturing nuanced
cultural semantics. Existing methods struggle to adapt to unkown culture after
fine-tuning. Inspired by cultural geography across five continents, we propose
Cultural Palette, a multi-agent framework that redefines cultural alignment as
an adaptive ""color-blending"" process for country-specific adaptation. Our
approach harnesses cultural geography across five continents (Africa, America,
Asia, Europe, Oceania) through three key steps: First, we synthesize the
Pentachromatic Cultural Palette Dataset using GPT-4o, refining
continental-level dialogues with Hofstede cultural dimensions to establish
foundational cultural representations. Second, five continent-level alignment
agents form specialized cultural communities that generate region-specific
draft responses. Third, a Meta Agent employs Cultural MoErges to dynamically
blend these cultural ""colors"" through attention-gated parameter merging, akin
to mixing pigments on a palette, resolving conflicts while preserving cultural
nuances to produce the final culturally-aligned response. Extensive experiments
across various countries demonstrate that Cultural Palette surpasses existing
baselines in cultural alignment.
","['Jiahao Yuan', 'Zixiang Di', 'Shangzixin Zhao', 'Usman Naseem']"
http://arxiv.org/abs/1304.3546v1,Cultured meat,2013-04-12T06:30:33Z,2013-04-12T06:30:33Z,The Meat of the Matter: A thumb rule for scavenging dogs?,"  Animals that scavenge in and around human localities need to utilize a broad
range of resources. Preference for any one kind of food, under such
circumstances, might be inefficient. Indian free-ranging dogs, Canis lupus
familiaris are scavengers that are heavily dependent on humans for sustaining
their omnivorous diet. The current study suggests that because of evolutionary
load, these dogs, which are descendants of the decidedly carnivorous gray wolf,
still retain a preference for meat though they live on carbohydrate-rich
resources. The plasticity in their diet probably fosters efficient scavenging
in a competitive environment, while a thumb rule for preferentially acquiring
specific nutrients enables them to sequester proteins from the
carbohydrate-rich environment.
","['Anandarup Bhadra', 'Debottam Bhattacharjee', 'Manabi Paul', 'Anindita Bhadra']"
http://arxiv.org/abs/2403.00776v1,Data science,2024-02-14T15:55:40Z,2024-02-14T15:55:40Z,A framework for understanding data science,"  The objective of this research is to provide a framework with which the data
science community can understand, define, and develop data science as a field
of inquiry. The framework is based on the classical reference framework
(axiology, ontology, epistemology, methodology) used for 200 years to define
knowledge discovery paradigms and disciplines in the humanities, sciences,
algorithms, and now data science. I augmented it for automated problem-solving
with (methods, technology, community). The resulting data science reference
framework is used to define the data science knowledge discovery paradigm in
terms of the philosophy of data science addressed in previous papers and the
data science problem-solving paradigm, i.e., the data science method, and the
data science problem-solving workflow, both addressed in this paper. The
framework is a much called for unifying framework for data science as it
contains the components required to define data science. For insights to better
understand data science, this paper uses the framework to define the emerging,
often enigmatic, data science problem-solving paradigm and workflow, and to
compare them with their well-understood scientific counterparts, scientific
problem-solving paradigm and workflow.
",['Michael L Brodie']
http://arxiv.org/abs/1501.05039v1,Data science,2015-01-21T02:41:55Z,2015-01-21T02:41:55Z,Defining Data Science,"  Data science is gaining more and more and widespread attention, but no
consensus viewpoint on what data science is has emerged. As a new science, its
objects of study and scientific issues should not be covered by established
sciences. Data in cyberspace have formed what we call datanature. In the
present paper, data science is defined as the science of exploring datanature.
","['Yangyong Zhu', 'Yun Xiong']"
http://arxiv.org/abs/2201.05852v1,Data science,2022-01-15T13:51:12Z,2022-01-15T13:51:12Z,Data Science in Perspective,"  Data and Science has stood out in the generation of results, whether in the
projects of the scientific domain or business domain. CERN Project, Scientific
Institutes, companies like Walmart, Google, Apple, among others, need data to
present their results and make predictions in the competitive data world. Data
and Science are words that together culminated in a globally recognized term
called Data Science. Data Science is in its initial phase, possibly being part
of formal sciences and also being presented as part of applied sciences,
capable of generating value and supporting decision making. Data Science
considers science and, consequently, the scientific method to promote decision
making through data intelligence. In many cases, the application of the method
(or part of it) is considered in Data Science projects in scientific domain
(social sciences, bioinformatics, geospatial projects) or business domain
(finance, logistic, retail), among others. In this sense, this article
addresses the perspectives of Data Science as a multidisciplinary area,
considering science and the scientific method, and its formal structure which
integrate Statistics, Computer Science, and Business Science, also taking into
account Artificial Intelligence, emphasizing Machine Learning, among others.
The article also deals with the perspective of applied Data Science, since Data
Science is used for generating value through scientific and business projects.
Data Science persona is also discussed in the article, concerning the education
of Data Science professionals and its corresponding profiles, since its
projection changes the field of data in the world.
",['Rogerio Rossi']
http://arxiv.org/abs/2007.03606v1,Data science,2020-07-01T02:33:58Z,2020-07-01T02:33:58Z,Data Science: A Comprehensive Overview,"  The twenty-first century has ushered in the age of big data and data economy,
in which data DNA, which carries important knowledge, insights and potential,
has become an intrinsic constituent of all data-based organisms. An appropriate
understanding of data DNA and its organisms relies on the new field of data
science and its keystone, analytics. Although it is widely debated whether big
data is only hype and buzz, and data science is still in a very early phase,
significant challenges and opportunities are emerging or have been inspired by
the research, innovation, business, profession, and education of data science.
This paper provides a comprehensive survey and tutorial of the fundamental
aspects of data science: the evolution from data analysis to data science, the
data science concepts, a big picture of the era of data science, the major
challenges and directions in data innovation, the nature of data analytics, new
industrialization and service opportunities in the data economy, the profession
and competency of data education, and the future of data science. This article
is the first in the field to draw a comprehensive big picture, in addition to
offering rich observations, lessons and thinking about data science and
analytics.
",['Longbing Cao']
http://arxiv.org/abs/2002.05658v1,Data science,2020-01-27T21:39:57Z,2020-01-27T21:39:57Z,Ten Research Challenge Areas in Data Science,"  Although data science builds on knowledge from computer science, mathematics,
statistics, and other disciplines, data science is a unique field with many
mysteries to unlock: challenging scientific questions and pressing questions of
societal importance. This article starts with meta-questions about data science
as a discipline and then elaborates on ten ideas for the basis of a research
agenda for data science.
",['Jeannette M. Wing']
http://arxiv.org/abs/2112.01590v3,Data science,2021-12-02T20:16:03Z,2022-02-14T17:35:39Z,"The Art and Practice of Data Science Pipelines: A Comprehensive Study of
  Data Science Pipelines In Theory, In-The-Small, and In-The-Large","  Increasingly larger number of software systems today are including data
science components for descriptive, predictive, and prescriptive analytics. The
collection of data science stages from acquisition, to cleaning/curation, to
modeling, and so on are referred to as data science pipelines. To facilitate
research and practice on data science pipelines, it is essential to understand
their nature. What are the typical stages of a data science pipeline? How are
they connected? Do the pipelines differ in the theoretical representations and
that in the practice? Today we do not fully understand these architectural
characteristics of data science pipelines. In this work, we present a
three-pronged comprehensive study to answer this for the state-of-the-art, data
science in-the-small, and data science in-the-large. Our study analyzes three
datasets: a collection of 71 proposals for data science pipelines and related
concepts in theory, a collection of over 105 implementations of curated data
science pipelines from Kaggle competitions to understand data science
in-the-small, and a collection of 21 mature data science projects from GitHub
to understand data science in-the-large. Our study has led to three
representations of data science pipelines that capture the essence of our
subjects in theory, in-the-small, and in-the-large.
","['Sumon Biswas', 'Mohammad Wardat', 'Hridesh Rajan']"
http://arxiv.org/abs/2403.03387v2,Data science,2024-03-06T00:49:08Z,2025-01-03T21:46:40Z,"A Systematic Literature Review of Undergraduate Data Science Education
  Research","  The presence of data science has been profound in the scientific community in
almost every discipline. An important part of the data science education
expansion has been at the undergraduate level. We conducted a systematic
literature review to (1) portray current evidence and knowledge gaps in
self-proclaimed undergraduate data science education research and (2) inform
policymakers and the data science education community about what educators may
encounter when searching for literature using the general keyword 'data science
education.' While open-access publications that target a broader audience of
data science educators and include multiple examples of data science programs
and courses are a strength, significant knowledge gaps remain. The
undergraduate data science literature that we identified often lacks empirical
data, research questions and reproducibility. Certain disciplines are less
visible. We recommend that we should (1) cherish data science as an
interdisciplinary field; (2) adopt a consistent set of keywords/terminology to
ensure data science education literature is easily identifiable; (3) prioritize
investments in empirical studies.
","['Mine Dogucu', 'Sinem Demirci', 'Harry Bendekgey', 'Federica Zoe Ricci', 'Catalina M. Medina']"
http://arxiv.org/abs/2503.14937v1,Data science,2025-03-19T06:48:18Z,2025-03-19T06:48:18Z,"Proceedings of the 3rd Italian Conference on Big Data and Data Science
  (ITADATA2024)","  Proceedings of the 3rd Italian Conference on Big Data and Data Science
(ITADATA2024), held in Pisa, Italy, September 17-19, 2024.
  The Italian Conference on Big Data and Data Science (ITADATA2024) is the
annual event supported by the CINI Big Data National Laboratory and ISTI CNR
that aims to put together Italian researchers and professionals from academia,
industry, government, and public administration working in the field of big
data and data science, as well as related fields (e.g., security and privacy,
HPC, Cloud).
  ITADATA2024 covered research on all theoretical and practical aspects of Big
Data and data science including data governance, data processing, data
analysis, data reporting, data protection, as well as experimental studies and
lessons learned. In particular, ITADATA2024 focused on
  - Data spaces
  - Data processing life cycle
  - Machine learning and Large Language Models
  - Applications of big data and data science in healthcare, finance, industry
5.0, and beyond
  - Data science for social network analysis
","['Nicola Bena', 'Claudia Diamantini', 'Michela Natilli', 'Luigi Romano', 'Giovanni Stilo', 'Valentina Pansanella', 'Claudio A. Ardagna', 'Anna Monreale', 'Roberto Trasarti']"
http://arxiv.org/abs/1607.00858v1,Data science,2016-07-04T12:40:15Z,2016-07-04T12:40:15Z,Embracing Data Science,"  Statistics is running the risk of appearing irrelevant to today's
undergraduate students. Today's undergraduate students are familiar with data
science projects and they judge statistics against what they have seen.
Statistics, especially at the introductory level, should take inspiration from
data science so that the discipline is not seen as somehow lesser than data
science. This article provides a brief overview of data science, outlines ideas
for how introductory courses could take inspiration from data science, and
provides a reference to materials for developing stand-alone data science
courses.
",['Adam Loy']
http://arxiv.org/abs/2306.16177v3,Data science,2023-06-28T12:58:42Z,2023-07-24T12:32:58Z,Defining data science: a new field of inquiry,"  Data science is not a science. It is a research paradigm. Its power, scope,
and scale will surpass science, our most powerful research paradigm, to enable
knowledge discovery and change our world. We have yet to understand and define
it, vital to realizing its potential and managing its risks. Modern data
science is in its infancy. Emerging slowly since 1962 and rapidly since 2000,
it is a fundamentally new field of inquiry, one of the most active, powerful,
and rapidly evolving 21st century innovations. Due to its value, power, and
applicability, it is emerging in over 40 disciplines, hundreds of research
areas, and thousands of applications. Millions of data science publications
contain myriad definitions of data science and data science problem solving.
Due to its infancy, many definitions are independent, application specific,
mutually incomplete, redundant, or inconsistent, hence so is data science. This
research addresses this data science multiple definitions challenge by
proposing the development of coherent, unified definition based on a data
science reference framework using a data science journal for the data science
community to achieve such a definition. This paper provides candidate
definitions for essential data science artifacts that are required to discuss
such a definition. They are based on the classical research paradigm concept
consisting of a philosophy of data science, the data science problem solving
paradigm, and the six component data science reference framework (axiology,
ontology, epistemology, methodology, methods, technology) that is a frequently
called for unifying framework with which to define, unify, and evolve data
science. It presents challenges for defining data science, solution approaches,
i.e., means for defining data science, and their requirements and benefits as
the basis of a comprehensive solution.
",['Michael L Brodie']
http://arxiv.org/abs/2308.04896v1,Data science,2023-08-08T06:45:15Z,2023-08-08T06:45:15Z,Why Data Science Projects Fail,"  Data Science is a modern Data Intelligence practice, which is the core of
many businesses and helps businesses build smart strategies around to deal with
businesses challenges more efficiently. Data Science practice also helps in
automating business processes using the algorithm, and it has several other
benefits, which also deliver in a non-profitable framework. In regards to data
science, three key components primarily influence the effective outcome of a
data science project. Those are 1.Availability of Data 2.Algorithm 3.Processing
power or infrastructure
",['Balaram Panda']
http://arxiv.org/abs/2506.03165v1,Data science,2025-05-26T14:07:42Z,2025-05-26T14:07:42Z,"What Does Information Science Offer for Data Science Research?: A Review
  of Data and Information Ethics Literature","  This paper reviews literature pertaining to the development of data science
as a discipline, current issues with data bias and ethics, and the role that
the discipline of information science may play in addressing these concerns.
Information science research and researchers have much to offer for data
science, owing to their background as transdisciplinary scholars who apply
human-centered and social-behavioral perspectives to issues within natural
science disciplines. Information science researchers have already contributed
to a humanistic approach to data ethics within the literature and an emphasis
on data science within information schools all but ensures that this literature
will continue to grow in coming decades. This review article serves as a
reference for the history, current progress, and potential future directions of
data ethics research within the corpus of information science literature.
","['Brady D. Lund', 'Ting Wang']"
http://arxiv.org/abs/2307.06896v1,Data science,2023-07-13T16:48:53Z,2023-07-13T16:48:53Z,Citizen Science in the European Open Science Cloud,"  The European Open Science Cloud aims to make all data Findable, Accessible,
Interoperable and Reusable. By far the largest community of users of the
European Open Science Cloud is the science-inclined public. These users need a
more curated experience of open science than subject specialists, but
nevertheless make very substantial research contributions in open science,
especially in crowdsourced data mining, i.e. citizen science. This short,
non-technical invited review presents applications of citizen science in the
European Open Science Cloud, with a particular focus on astrophysics and
astroparticle physics.
",['Stephen Serjeant']
http://arxiv.org/abs/2007.08087v1,Data science,2020-07-16T03:15:56Z,2020-07-16T03:15:56Z,"Starting with data: advancing spatial data science by building and
  sharing high-quality datasets","  Spatial data science has emerged in recent years as an interdisciplinary
field. This position paper discusses the importance of building and sharing
high-quality datasets for spatial data science.
",['Yingjie Hu']
http://arxiv.org/abs/1805.05401v1,Data science,2018-05-04T12:28:03Z,2018-05-04T12:28:03Z,"Building Data Science Capabilities into University Data Warehouse to
  Predict Graduation","  The discipline of data science emerged to combine statistical methods with
computing. At Aalto University, Finland, we have taken first steps to bring
educational data science as a part of daily operations of Management
Information Services. This required changes in IT environment: we enhanced data
warehouse infrastructure with a data science lab, where we can read predictive
model training data from data warehouse database and use the created predictive
models in database queries. We then conducted a data science pilot with an
objective to predict students' graduation probability and time-to-degree with
student registry data. Further ethical and legal considerations are needed
before using predictions in daily operations of the university.
","['Joonas Pesonen', 'Anna Fomkin', 'Lauri Jokipii']"
http://arxiv.org/abs/2506.11010v1,Data science,2025-04-25T08:43:27Z,2025-04-25T08:43:27Z,Data Science: a Natural Ecosystem,"  This manuscript provides a holistic (data-centric) view of what we term
essential data science, as a natural ecosystem with challenges and missions
stemming from the data universe with its multiple combinations of the 5D
complexities (data structure, domain, cardinality, causality, and ethics) with
the phases of the data life cycle. Data agents perform tasks driven by specific
goals. The data scientist is an abstract entity that comes from the logical
organization of data agents with their actions. Data scientists face challenges
that are defined according to the missions. We define specific
discipline-induced data science, which in turn allows for the definition of
pan-data science, a natural ecosystem that integrates specific disciplines with
the essential data science. We semantically split the essential data science
into computational, and foundational. We claim that there is a serious threat
of divergence between computational and foundational data science. Especially,
if no approach is taken to rate whether a data universe discovery should be
useful or not. We suggest that rigorous approaches to measure the usefulness of
data universe discoveries might mitigate such a divergence.
","['Emilio Porcu', 'Roy El Moukari', 'Laurent Najman', 'Francisco Herrera', 'Horst Simon']"
http://arxiv.org/abs/1909.04486v1,Data science,2019-09-09T11:31:40Z,2019-09-09T11:31:40Z,Data Science in Biomedicine,"  We highlight the role of Data Science in Biomedicine. Our manuscript goes
from the general to the particular, presenting a global definition of Data
Science and showing the trend for this discipline together with the terms of
cloud computing and big data. In addition, since Data Science is mostly related
to areas like economy or business, we describe its importance in biomedicine.
Biomedical Data Science (BDS) presents the challenge of dealing with data
coming from a range of biological and medical research, focusing on
methodologies to advance the biomedical science discoveries, in an
interdisciplinary context.
","['Yovaninna Alarcón-Soto', 'Jenifer Espasandín-Domínguez', 'Ipek Guler', 'Mercedes Conde-Amboage', 'Francisco Gude-Sampedro', 'Klaus Langohr', 'Carmen Cadarso-Suárez', 'Guadalupe Gómez-Melis']"
http://arxiv.org/abs/1610.04276v1,Data science,2016-10-13T22:06:46Z,2016-10-13T22:06:46Z,Perspectives on Surgical Data Science,"  The availability of large amounts of data together with advances in
analytical techniques afford an opportunity to address difficult challenges in
ensuring that healthcare is safe, effective, efficient, patient-centered,
equitable, and timely. Surgical care and training stand to tremendously gain
through surgical data science. Herein, we discuss a few perspectives on the
scope and objectives for surgical data science.
","['S. Swaroop Vedula', 'Masaru Ishii', 'Gregory D. Hager']"
http://arxiv.org/abs/2006.16964v1,Data science,2020-06-28T02:06:54Z,2020-06-28T02:06:54Z,Data Science: Nature and Pitfalls,"  Data science is creating very exciting trends as well as significant
controversy. A critical matter for the healthy development of data science in
its early stages is to deeply understand the nature of data and data science,
and to discuss the various pitfalls. These important issues motivate the
discussions in this article.
",['Longbing Cao']
http://arxiv.org/abs/2501.02126v2,Data science,2025-01-03T22:36:20Z,2025-06-11T19:12:37Z,A Mathematical Lens for Teaching Data Science,"  Using the National Academies report, {\em Data Science for Undergraduates:
Opportunities and Options}, we connect data science curricula to the more
familiar pedagogy used by many mathematical scientists. We use their list of
``data acumen"" components to ground a discussion, which hopes to connect data
science curricula to the more familiar pedagogy used by many mathematical
scientists.
",['Johanna Hardin']
http://arxiv.org/abs/2007.13115v1,Gene therapy,2020-07-26T12:22:16Z,2020-07-26T12:22:16Z,"Challenges in constructing genetic instruments for pharmacologic
  therapies","  The genes that encode the targets of most therapies do not have rare variants
with large-effect or common variants with moderate effects on the biomarker
reflecting the pharmacologic action of the corresponding therapy. Therefore,
providing genetic target validation for most therapies is challenging. Novel
methods are being developed to combine multiple variants in the gene encoding
the target of a therapy that are weakly associated with the biomarker
reflecting the pharmacologic action of that therapy into a genetic score that
can be used as an adequate instrumental variable. We describe one approach to
solve this important problem.
","['B. A. Ference', 'G. Davey Smith', 'M. V. Holmes', 'A. L. Catapano', 'K. K. Ray', 'S. J. Nicholls']"
http://arxiv.org/abs/0810.0239v1,Gene therapy,2008-10-01T17:56:31Z,2008-10-01T17:56:31Z,"Stochastic models and numerical algorithms for a class of regulatory
  gene networks","  Regulatory gene networks contain generic modules like those involving
feedback loops, which are essential for the regulation of many biological
functions. We consider a class of self-regulated genes which are the building
blocks of many regulatory gene networks, and study the steady state
distributions of the associated Gillespie algorithm by providing efficient
numerical algorithms. We also study a regulatory gene network of interest in
synthetic biology and in gene therapy, using mean-field models with time
delays. Convergence of the related time-nonhomogeneous Markov chain is
established for a class of linear catalytic networks with feedback loops
","['Thomas Fournier', 'Jean-Pierre Gabriel', 'Christian Mazza', 'Jerome Pasquier', 'Jose Galbete', 'Nicolas Mermod']"
http://arxiv.org/abs/1902.00728v1,Gene therapy,2019-02-02T14:34:13Z,2019-02-02T14:34:13Z,"New combinational therapies for cancer using modern statistical
  mechanics","  We investigate a new dynamical system that describes tumor-host interaction.
The equation that describes the untreated tumor growth is based on
non-extensive statistical mechanics. Recently, this model has been shown to fit
successfully exponential, Gompertz, logistic, and power-law tumor growths. We
have been able to include as many hallmarks of cancer as possible. We study
also the dynamic response of cancer under therapy. Using our model, we can make
predictions about the different outcomes when we change the parameters, and/or
the initial conditions. We can determine the importance of different factors to
influence tumor growth. We discover synergistic therapeutic effects of
different treatments and drugs. Cancer is generally untreatable using
conventional monotherapy. We consider conventional therapies, oncogene-targeted
therapies, tumor-suppressors gene-targeted therapies, immunotherapies,
anti-angiogenesis therapies, virotherapy, among others. We need therapies with
the potential to target both tumor cells and the tumors' microenvironment.
Drugs that target oncogenes and tumor-suppressor genes can be effective in the
treatment of some cancers. However, most tumors do reoccur. We have found that
the success of the new therapeutic agents can be seen when used in combination
with other cancer-cell-killing therapies. Our results have allowed us to design
a combinational therapy that can lead to the complete eradication of cancer.
","['Jorge A. González', 'M. Acanda', 'Z. Akhtar', 'D. Andrews', 'J. I. Azqueta', 'E. Bass', 'A. Bellorín', 'J. Couso', 'Mónica A. García-Ñustes', 'Y. Infante', 'S. Jiménez', 'L. Lester', 'L. Maldonado', 'Juan F. Marín', 'L. Pineda', 'I. Rodríguez', 'C. C. Tamayo', 'D. Valdes', 'L. Vázquez']"
http://arxiv.org/abs/q-bio/0511020v1,Gene therapy,2005-11-15T07:47:51Z,2005-11-15T07:47:51Z,"Induction in myeloid leukemic cells of genes that are expressed in
  different normal tissues","  Using DNA microarray and cluster analysis of expressed genes in a cloned line
(M1-t-p53) of myeloid leukemic cells, we have analyzed the expression of genes
that are preferentially expressed in different normal tissues. Clustering of
547 highly expressed genes in these leukemic cells showed 38 genes
preferentially expressed in normal hematopoietic tissues and 122 other genes
preferentially expressed in different normal non-hematopoietic tissues
including neuronal tissues, muscle, liver and testis. We have also analyzed the
genes whose expression in the leukemic cells changed after activation of
wild-type p53 and treatment with the cytokine interleukin 6 (IL-6) or the
calcium mobilizer thapsigargin (TG). Out of 620 such genes in the leukemic
cells that were differentially expressed in normal tissues, clustering showed
80 genes that were preferentially expressed in hematopoietic tissues and 132
genes in different normal non-hematopietic tissues that also included neuronal
tissues, muscle, liver and testis. Activation of p53 and treatment with IL-6 or
TG induced different changes in the genes preferentially expressed in these
normal tissues. These myeloid leukemic cells thus express genes that are
expressed in normal non-hematopoietic tissues, and various treatments can
reprogram these cells to induce other such non-hematopoietic genes. The results
indicate that these leukemic cells share with normal hematopoietic stem cells
the plasticity of differentiation to different cell types. It is suggested that
this reprogramming to induce in malignant cells genes that are expressed in
different normal tissues may be of clinical value in therapy.
","['Joseph Lotem', 'Hila Benjamin', 'Dvir Netaneli', 'Eytan Domany', 'Leo Sachs']"
http://arxiv.org/abs/2403.01927v1,Gene therapy,2024-03-04T10:44:57Z,2024-03-04T10:44:57Z,"Advancing Gene Selection in Oncology: A Fusion of Deep Learning and
  Sparsity for Precision Gene Selection","  Gene selection plays a pivotal role in oncology research for improving
outcome prediction accuracy and facilitating cost-effective genomic profiling
for cancer patients. This paper introduces two gene selection strategies for
deep learning-based survival prediction models. The first strategy uses a
sparsity-inducing method while the second one uses importance based gene
selection for identifying relevant genes. Our overall approach leverages the
power of deep learning to model complex biological data structures, while
sparsity-inducing methods ensure the selection process focuses on the most
informative genes, minimizing noise and redundancy. Through comprehensive
experimentation on diverse genomic and survival datasets, we demonstrate that
our strategy not only identifies gene signatures with high predictive power for
survival outcomes but can also streamlines the process for low-cost genomic
profiling. The implications of this research are profound as it offers a
scalable and effective tool for advancing personalized medicine and targeted
cancer therapies. By pushing the boundaries of gene selection methodologies,
our work contributes significantly to the ongoing efforts in cancer genomics,
promising improved diagnostic and prognostic capabilities in clinical settings.
","['Akhila Krishna', 'Ravi Kant Gupta', 'Pranav Jeevan', 'Amit Sethi']"
http://arxiv.org/abs/2409.19115v1,Gene therapy,2024-09-27T19:44:20Z,2024-09-27T19:44:20Z,Identifying Key Genes in Cancer Networks Using Persistent Homology,"  Identifying driver genes is crucial for understanding oncogenesis and
developing targeted cancer therapies. Driver discovery methods using protein or
pathway networks rely on traditional network science measures, focusing on
nodes, edges, or community metrics. These methods can overlook the
high-dimensional interactions that cancer genes have within cancer networks.
This study presents a novel method using Persistent Homology to analyze the
role of driver genes in higher-order structures within Cancer Consensus
Networks derived from main cellular pathways. We integrate mutation data from
six cancer types and three biological functions: DNA Repair, Chromatin
Organization, and Programmed Cell Death. We systematically evaluated the impact
of gene removal on topological voids ($\beta_2$ structures) within the Cancer
Consensus Networks. Our results reveal that only known driver genes and
cancer-associated genes influence these structures, while passenger genes do
not. Although centrality measures alone proved insufficient to fully
characterize impact genes, combining higher-order topological analysis with
traditional network metrics can improve the precision of distinguishing between
drivers and passengers. This work shows that cancer genes play an important
role in higher-order structures, going beyond pairwise measures, and provides
an approach to distinguish drivers and cancer-associated genes from passenger
genes.
","['Rodrigo Henrique Ramos', 'Yago Augusto Bardelotte', 'Cynthia de Oliveira Lage Ferreira', 'Adenilso Simao']"
http://arxiv.org/abs/1612.09478v1,Gene therapy,2016-12-30T12:56:52Z,2016-12-30T12:56:52Z,Discovery of cancer common and specific driver gene sets,"  Cancer is known as a disease mainly caused by gene alterations. Discovery of
mutated driver pathways or gene sets is becoming an important step to
understand molecular mechanisms of carcinogenesis. However, systematically
investigating commonalities and specificities of driver gene sets among
multiple cancer types is still a great challenge, but this investigation will
undoubtedly benefit deciphering cancers and will be helpful for personalized
therapy and precision medicine in cancer treatment. In this study, we propose
two optimization models to \emph{de novo} discover common driver gene sets
among multiple cancer types (ComMDP) and specific driver gene sets of one
certain or multiple cancer types to other cancers (SpeMDP), respectively. We
first apply ComMDP and SpeMDP to simulated data to validate their efficiency.
Then, we further apply these methods to 12 cancer types from The Cancer Genome
Atlas (TCGA) and obtain several biologically meaningful driver pathways. As
examples, we construct a common cancer pathway model for BRCA and OV, infer a
complex driver pathway model for BRCA carcinogenesis based on common driver
gene sets of BRCA with eight cancer types, and investigate specific driver
pathways of the liquid cancer lymphoblastic acute myeloid leukemia (LAML)
versus other solid cancer types. In these processes more candidate cancer genes
are also found.
","['Junhua Zhang', 'Shihua Zhang']"
http://arxiv.org/abs/2311.06747v3,Gene therapy,2023-11-12T06:03:13Z,2024-11-25T22:37:38Z,Graph Frequency Features of Cancer Gene Co-Expression Networks,"  Complex gene interactions play a significant role in cancer progression,
driving cellular behaviors that contribute to tumor growth, invasion, and
metastasis. Gene co-expression networks model the functional connectivity
between genes under various biological conditions. Understanding the
system-level evolution of these networks in cancer is critical for elucidating
disease mechanisms and informing the development of targeted therapies. While
previous studies have primarily focused on structural differences between
cancer and normal cell co-expression networks, this study applies graph
frequency analysis to cancer transcriptomic signals defined on gene
co-expression networks, highlighting the graph spectral characteristics of
cancer systems. Using a range of graph frequency filters, we showed that cancer
cells display distinctive patterns in the graph frequency content of their gene
transcriptomic signals, effectively distinguishing between cancer types and
stages. The transformation of the original gene feature space into the graph
spectral space captured more intricate cancer properties, as validated by
significantly higher F-statistic scores for graph frequency-filtered gene
features compared to those in the original space.
","['Radwa Adel', 'Ercan Engin Kuruoglu']"
http://arxiv.org/abs/2411.12010v2,Gene therapy,2024-11-18T19:49:51Z,2024-12-11T11:52:24Z,"Active learning for efficient discovery of optimal gene combinations in
  the combinatorial perturbation space","  The advancement of novel combinatorial CRISPR screening technologies enables
the identification of synergistic gene combinations on a large scale. This is
crucial for developing novel and effective combination therapies, but the
combinatorial space makes exhaustive experimentation infeasible. We introduce
NAIAD, an active learning framework that efficiently discovers optimal gene
pairs capable of driving cells toward desired cellular phenotypes. NAIAD
leverages single-gene perturbation effects and adaptive gene embeddings that
scale with the training data size, mitigating overfitting in small-sample
learning while capturing complex gene interactions as more data is collected.
Evaluated on four CRISPR combinatorial perturbation datasets totaling over
350,000 genetic interactions, NAIAD, trained on small datasets, outperforms
existing models by up to 40\% relative to the second-best. NAIAD's
recommendation system prioritizes gene pairs with the maximum predicted
effects, resulting in the highest marginal gain in each AI-experiment round and
accelerating discovery with fewer CRISPR experimental iterations. Our NAIAD
framework (https://github.com/NeptuneBio/NAIAD) improves the identification of
novel, effective gene combinations, enabling more efficient CRISPR library
design and offering promising applications in genomics research and therapeutic
development.
","['Jason Qin', 'Hans-Hermann Wessels', 'Carlos Fernandez-Granda', 'Yuhan Hao']"
http://arxiv.org/abs/1111.1360v1,Gene therapy,2011-11-05T23:17:02Z,2011-11-05T23:17:02Z,"Magnetic Field-Assisted Gene Delivery: Achievements and Therapeutic
  Potential","  The discovery in the early 2000's that magnetic nanoparticles (MNPs)
complexed to nonviral or viral vectors can, in the presence of an external
magnetic field, greatly enhance gene transfer into cells has raised much
interest. This technique, called magnetofection, was initially developed mainly
to improve gene transfer in cell cultures, a simpler and more easily
controllable scenario than in vivo models. These studies provided evidence for
some unique capabilities of magnetofection. Progressively, the interest in
magnetofection expanded to its application in animal models and led to the
association of this technique with another technology, magnetic drug targeting
(MDT). This combination offers the possibility to develop more efficient and
less invasive gene therapy strategies for a number of major pathologies like
cancer, neurodegeneration and myocardial infarction. The goal of MDT is to
concentrate MNPs functionalized with therapeutic drugs, in target areas of the
body by means of properly focused external magnetic fields. The availability of
stable, nontoxic MNP-gene vector complexes now offers the opportunity to
develop magnetic gene targeting (MGT), a variant of MDT in which the gene
coding for a therapeutic molecule, rather than the molecule itself, is
delivered to a therapeutic target area in the body. This article will first
outline the principle of magnetofection, subsequently describing the properties
of the magnetic fields and MNPs used in this technique. Next, it will review
the results achieved by magnetofection in cell cultures. Last, the potential of
MGT for implementing minimally invasive gene therapy will be discussed.
","['José I. Schwerdt', 'Gerardo F. Goya', 'Pilar Calatayud', 'Claudia B. Hereñú', 'Paula C. Reggiani', 'Rodolfo G. Goya']"
http://arxiv.org/abs/2502.01689v1,Gene therapy,2025-02-02T15:43:20Z,2025-02-02T15:43:20Z,"scGSDR: Harnessing Gene Semantics for Single-Cell Pharmacological
  Profiling","  The rise of single-cell sequencing technologies has revolutionized the
exploration of drug resistance, revealing the crucial role of cellular
heterogeneity in advancing precision medicine. By building computational models
from existing single-cell drug response data, we can rapidly annotate cellular
responses to drugs in subsequent trials. To this end, we developed scGSDR, a
model that integrates two computational pipelines grounded in the knowledge of
cellular states and gene signaling pathways, both essential for understanding
biological gene semantics. scGSDR enhances predictive performance by
incorporating gene semantics and employs an interpretability module to identify
key pathways contributing to drug resistance phenotypes. Our extensive
validation, which included 16 experiments covering 11 drugs, demonstrates
scGSDR's superior predictive accuracy, when trained with either bulk-seq or
scRNA-seq data, achieving high AUROC, AUPR, and F1 Scores. The model's
application has extended from single-drug predictions to scenarios involving
drug combinations. Leveraging pathways of known drug target genes, we found
that scGSDR's cell-pathway attention scores are biologically interpretable,
which helped us identify other potential drug-related genes. Literature review
of top-ranking genes in our predictions such as BCL2, CCND1, the AKT family,
and PIK3CA for PLX4720; and ICAM1, VCAM1, NFKB1, NFKBIA, and RAC1 for
Paclitaxel confirmed their relevance. In conclusion, scGSDR, by incorporating
gene semantics, enhances predictive modeling of cellular responses to diverse
drugs, proving invaluable for scenarios involving both single drug and
combination therapies and effectively identifying key resistance-related
pathways, thus advancing precision medicine and targeted therapy development.
","['Yu-An Huang', 'Xiyue Cao', 'Zhu-Hong You', 'Yue-Chao Li', 'Xuequn Shang', 'Zhi-An Huang']"
http://arxiv.org/abs/1703.01900v1,Gene therapy,2017-03-01T02:09:50Z,2017-03-01T02:09:50Z,"Network-based Distance Metric with Application to Discover Disease
  Subtypes in Cancer","  While we once thought of cancer as single monolithic diseases affecting a
specific organ site, we now understand that there are many subtypes of cancer
defined by unique patterns of gene mutations. These gene mutational data, which
can be more reliably obtained than gene expression data, help to determine how
the subtypes develop, evolve, and respond to therapies. Different from dense
continuous-value gene expression data, which most existing cancer subtype
discovery algorithms use, somatic mutational data are extremely sparse and
heterogeneous, because there are less than 0.5\% mutated genes in discrete
value 1/0 out of 20,000 human protein-coding genes, and identical mutated genes
are rarely shared by cancer patients.
  Our focus is to search for cancer subtypes from extremely sparse and high
dimensional gene mutational data in discrete 1 and 0 values using unsupervised
learning. We propose a new network-based distance metric. We project cancer
patients' mutational profile into their gene network structure and measure the
distance between two patients using the similarity between genes and between
the gene vertexes of the patients in the network. Experimental results in
synthetic data and real-world data show that our approach outperforms the top
competitors in cancer subtype discovery. Furthermore, our approach can identify
cancer subtypes that cannot be detected by other clustering algorithms in real
cancer data.
","['Jipeng Qiang', 'Wei Ding', 'John Quackenbush', 'Ping Chen']"
http://arxiv.org/abs/1310.3528v1,Gene therapy,2013-10-13T23:30:57Z,2013-10-13T23:30:57Z,Evolution and Controllability of Cancer Networks: a Boolean Perspective,"  Cancer forms a robust system and progresses as stages over time typically
with increasing aggressiveness and worsening prognosis. Characterizing these
stages and identifying the genes driving transitions between them is critical
to understand cancer progression and to develop effective anti-cancer
therapies. Here, we propose a novel model of the 'cancer system' as a Boolean
state space in which a Boolean network, built from protein interaction and
gene-expression data from different stages of cancer, transits between Boolean
satisfiability states by ""editing"" interactions and ""flipping"" genes. The
application of our model (called BoolSpace) on three case studies - pancreatic
and breast tumours in human and post spinal-cord injury in rats - reveals
valuable insights into the phenomenon of cancer progression. In particular, we
notice that several of the genes flipped are serine/threonine kinases which act
as natural cellular switches and that different sets of genes are flipped
during the initial and final stages indicating a pattern to tumour progression.
We hypothesize that robustness of cancer partly stems from ""passing of the
baton"" between genes at different stages, and therefore an effective therapy
should target a ""cover set"" of these genes. A C/C++ implementation of BoolSpace
is freely available at: http://www.bioinformatics.org.au/tools-data
","['Sriganesh Srihari', 'Venkatesh Raman', 'Hon Wai Leong', 'Mark A. Ragan']"
http://arxiv.org/abs/2501.18794v1,Gene therapy,2025-01-30T23:03:03Z,2025-01-30T23:03:03Z,"Survey and Improvement Strategies for Gene Prioritization with Large
  Language Models","  Rare diseases are challenging to diagnose due to limited patient data and
genetic diversity. Despite advances in variant prioritization, many cases
remain undiagnosed. While large language models (LLMs) have performed well in
medical exams, their effectiveness in diagnosing rare genetic diseases has not
been assessed. To identify causal genes, we benchmarked various LLMs for gene
prioritization. Using multi-agent and Human Phenotype Ontology (HPO)
classification, we categorized patients based on phenotypes and solvability
levels. As gene set size increased, LLM performance deteriorated, so we used a
divide-and-conquer strategy to break the task into smaller subsets. At
baseline, GPT-4 outperformed other LLMs, achieving near 30% accuracy in ranking
causal genes correctly. The multi-agent and HPO approaches helped distinguish
confidently solved cases from challenging ones, highlighting the importance of
known gene-phenotype associations and phenotype specificity. We found that
cases with specific phenotypes or clear associations were more accurately
solved. However, we observed biases toward well-studied genes and input order
sensitivity, which hindered gene prioritization. Our divide-and-conquer
strategy improved accuracy by overcoming these biases. By utilizing HPO
classification, novel multi-agent techniques, and our LLM strategy, we improved
causal gene identification accuracy compared to our baseline evaluation. This
approach streamlines rare disease diagnosis, facilitates reanalysis of unsolved
cases, and accelerates gene discovery, supporting the development of targeted
diagnostics and therapies.
","['Matthew Neeley', 'Guantong Qi', 'Guanchu Wang', 'Ruixiang Tang', 'Dongxue Mao', 'Chaozhong Liu', 'Sasidhar Pasupuleti', 'Bo Yuan', 'Fan Xia', 'Pengfei Liu', 'Zhandong Liu', 'Xia Hu']"
http://arxiv.org/abs/1408.0083v1,Gene therapy,2014-08-01T05:36:59Z,2014-08-01T05:36:59Z,"Gene-level pharmacogenetic analysis on survival outcomes using
  gene-trait similarity regression","  Gene/pathway-based methods are drawing significant attention due to their
usefulness in detecting rare and common variants that affect disease
susceptibility. The biological mechanism of drug responses indicates that a
gene-based analysis has even greater potential in pharmacogenetics. Motivated
by a study from the Vitamin Intervention for Stroke Prevention (VISP) trial, we
develop a gene-trait similarity regression for survival analysis to assess the
effect of a gene or pathway on time-to-event outcomes. The similarity
regression has a general framework that covers a range of survival models, such
as the proportional hazards model and the proportional odds model. The
inference procedure developed under the proportional hazards model is robust
against model misspecification. We derive the equivalence between the
similarity survival regression and a random effects model, which further
unifies the current variance component-based methods. We demonstrate the
effectiveness of the proposed method through simulation studies. In addition,
we apply the method to the VISP trial data to identify the genes that exhibit
an association with the risk of a recurrent stroke. The TCN2 gene was found to
be associated with the recurrent stroke risk in the low-dose arm. This gene may
impact recurrent stroke risk in response to cofactor therapy.
","['Jung-Ying Tzeng', 'Wenbin Lu', 'Fang-Chi Hsu']"
http://arxiv.org/abs/1202.3015v2,Gene therapy,2012-02-14T12:24:09Z,2012-08-18T19:50:11Z,On dynamic network entropy in cancer,"  The cellular phenotype is described by a complex network of molecular
interactions. Elucidating network properties that distinguish disease from the
healthy cellular state is therefore of critical importance for gaining
systems-level insights into disease mechanisms and ultimately for developing
improved therapies. By integrating gene expression data with a protein
interaction network to induce a stochastic dynamics on the network, we here
demonstrate that cancer cells are characterised by an increase in the dynamic
network entropy, compared to cells of normal physiology. Using a fundamental
relation between the macroscopic resilience of a dynamical system and the
uncertainty (entropy) in the underlying microscopic processes, we argue that
cancer cells will be more robust to random gene perturbations. In addition, we
formally demonstrate that gene expression differences between normal and cancer
tissue are anticorrelated with local dynamic entropy changes, thus providing a
systemic link between gene expression changes at the nodes and their local
network dynamics. In particular, we also find that genes which drive
cell-proliferation in cancer cells and which often encode oncogenes are
associated with reductions in the dynamic network entropy. In summary, our
results support the view that the observed increased robustness of cancer cells
to perturbation and therapy may be due to an increase in the dynamic network
entropy that allows cells to adapt to the new cellular stresses. Conversely,
genes that exhibit local flux entropy decreases in cancer may render cancer
cells more susceptible to targeted intervention and may therefore represent
promising drug targets.
","['James West', 'Ginestra Bianconi', 'Simone Severini', 'Andrew Teschendorff']"
http://arxiv.org/abs/2007.03186v1,Gene therapy,2020-07-07T03:58:44Z,2020-07-07T03:58:44Z,"Advancing Drug Resistance Research Through Quantitative Modeling and
  Synthetic Biology","  Antimicrobial resistance is an emerging global health crisis that is
undermining advances in modern medicine and, if unmitigated, threatens to kill
10 million people per year worldwide by 2050. Research over the last decade has
demonstrated that the differences between genetically identical cells in the
same environment can lead to drug resistance. Fluctuations in gene expression,
modulated by gene regulatory networks, can lead to non-genetic heterogeneity
that results in the fractional killing of microbial populations causing drug
therapies to fail; this non-genetic drug resistance can enhance the probability
of acquiring genetic drug resistance mutations. Mathematical models of gene
networks can elucidate general principles underlying drug resistance, predict
the evolution of resistance, and guide drug resistance experiments in the
laboratory. Cells genetically engineered to carry synthetic gene networks
regulating drug resistance genes allow for controlled, quantitative experiments
on the role of non-genetic heterogeneity in the development of drug resistance.
In this perspective article, we emphasize the contributions that mathematical,
computational, and synthetic gene network models play in advancing our
understanding of antimicrobial resistance to discover effective therapies
against drug-resistant infections.
","['K. Farquhar', 'H. Flohr', 'D. A. Charlebois']"
http://arxiv.org/abs/1602.08111v1,Gene therapy,2015-12-15T05:15:51Z,2015-12-15T05:15:51Z,A Cancer Biotherapy Resource,"  Cancer Biotherapy (CB), as opposed to cancer chemotherapy, is the use of
macromolecular, biological agents instead of organic chemicals or drugs to
treat cancer. Biological agents usually have higher selectivity and have less
toxic side effects than chemical agents. The I.S.B.T.C., being the only major
information database for CB, seems lacking in some crucial information on
various cancer biotherapy regimens. It is thus necessary to have a
comprehensive curated CB database. The database accessible to cancer patients
and also should be a sounding board for scientific ideas by cancer researchers.
The database/web server has information about main families of cancer
biotherapy regimens to date, namely, Protein Kinase Inhibitors, Ras Pathway
Inhibitors, Cell-Cycle Active Agents, MAbs (monoclonal antibodies), ADEPT
(Antibody-Directed Enzyme Pro-Drug Therapy), Cytokines, Anti-Angiogenesis
Agents, Cancer Vaccines, Cell-based Immunotherapeutics, Gene Therapy,
Hematopoietic Growth Factors, Retinoids, and CAAT. For each biotherapy regimen,
we will extract the following attributes in populating the database: Cancer
type, Gene/s and gene product/s involved, Gene sequence, Organs affected,
Reference papers, Clinical phase/stage, Survival rate, Clinical test center
locations, Cost, Patient blogs, Researcher blogs, and Future work. The database
will be accessible to public through a website and had FAQs for making it
understandable to the laymen and discussion page for researchers to express
their views and ideas. In addition to information about the biotherapy
regimens, the website will link to other biologically significant databases
like structural proteomics, metabolomics, glycomics, and lipidomics databases,
as well as to news around the world regarding cancer therapy results. The
database attributes would be regularly updated for novel attributes as
discoveries are made.
","['Preety Priya', 'Vicente M. Reyes']"
http://arxiv.org/abs/1510.00815v1,Gene therapy,2015-10-03T13:09:36Z,2015-10-03T13:09:36Z,"Inferring synthetic lethal interactions from mutual exclusivity of
  genetic events in cancer","  Background: Synthetic lethality (SL) refers to the genetic interaction
between two or more genes where only their co-alteration (e.g. by mutations,
amplifications or deletions) results in cell death. In recent years, SL has
emerged as an attractive therapeutic strategy against cancer: by targeting the
SL partners of altered genes in cancer cells, these cells can be selectively
killed while sparing the normal cells. Consequently, a number of studies have
attempted prediction of SL interactions in human, a majority by extrapolating
SL interactions inferred through large-scale screens in model organisms.
However, these predicted SL interactions either do not hold in human cells or
do not include genes that are (frequently) altered in human cancers, and are
therefore not attractive in the context of cancer therapy.
  Results: Here, we develop a computational approach to infer SL interactions
directly from frequently altered genes in human cancers. It is based on the
observation that pairs of genes that are altered in a (significantly) mutually
exclusive manner in cancers are likely to constitute lethal combinations. Using
genomic copy-number and gene-expression data from four cancers, breast,
prostate, ovarian and uterine (total 3980 samples) from The Cancer Genome
Atlas, we identify 718 genes that are frequently amplified or upregulated, and
are likely to be synthetic lethal with six key DNA-damage response (DDR) genes
in these cancers. By comparing with published data on gene essentiality (~16000
genes) from ten DDR-deficient cancer cell lines, we show that our identified
genes are enriched among the top quartile of essential genes in these cell
lines, implying that our inferred genes are highly likely to be (synthetic)
lethal upon knockdown in these cell lines.
","['Sriganesh Srihari', 'Jitin Singla', 'Limsoon Wong', 'Mark A. Ragan']"
http://arxiv.org/abs/0803.0962v1,Gene therapy,2008-03-06T20:12:06Z,2008-03-06T20:12:06Z,Predicting synthetic rescues in metabolic networks,"  An important goal of medical research is to develop methods to recover the
loss of cellular function due to mutations and other defects. Many approaches
based on gene therapy aim to repair the defective gene or to insert genes with
compensatory function. Here, we propose an alternative, network-based strategy
that aims to restore biological function by forcing the cell to either bypass
the functions affected by the defective gene, or to compensate for the lost
function. Focusing on the metabolism of single-cell organisms, we
computationally study mutants that lack an essential enzyme, and thus are
unable to grow or have a significantly reduced growth rate. We show that
several of these mutants can be turned into viable organisms through additional
gene deletions that restore their growth rate. In a rather counterintuitive
fashion, this is achieved via additional damage to the metabolic network. Using
flux balance-based approaches, we identify a number of synthetically viable
gene pairs, in which the removal of one enzyme-encoding gene results in a
nonviable phenotype, while the deletion of a second enzyme-encoding gene
rescues the organism. The systematic network-based identification of
compensatory rescue effects may open new avenues for genetic interventions.
","['Adilson E. Motter', 'Natali Gulbahce', 'Eivind Almaas', 'Albert-Laszlo Barabasi']"
http://arxiv.org/abs/2006.16925v3,Neurotechnology,2020-06-23T07:46:22Z,2024-09-18T23:37:41Z,"Ethical Analysis on the Application of Neurotechnology for Human
  Augmentation in Physicians and Surgeons","  With the shortage of physicians and surgeons and increase in demand worldwide
due to situations such as the COVID-19 pandemic, there is a growing interest in
finding solutions to help address the problem. A solution to this problem would
be to use neurotechnology to provide them augmented cognition, senses and
action for optimal diagnosis and treatment. Consequently, doing so can
negatively impact them and others. We argue that applying neurotechnology for
human enhancement in physicians and surgeons can cause injustices, and harm to
them and patients. In this paper, we will first describe the augmentations and
neurotechnologies that can be used to achieve the relevant augmentations for
physicians and surgeons. We will then review selected ethical concerns
discussed within literature, discuss the neuroengineering behind using
neurotechnology for augmentation purposes, then conclude with an analysis on
outcomes and ethical issues of implementing human augmentation via
neurotechnology in medical and surgical practice.
","['Soaad Hossain', 'Syed Ishtiaque Ahmed']"
http://arxiv.org/abs/1607.05023v1,Neurotechnology,2016-07-18T11:28:11Z,2016-07-18T11:28:11Z,"Intelligent Biohybrid Neurotechnologies: Are They Really What They
  Claim?","  In the era of intelligent biohybrid neurotechnologies for brain repair, new
fanciful terms are appearing in the scientific dictionary to define what has so
far been unimaginable. As the emerging neurotechnologies are becoming
increasingly polyhedral and sophisticated, should we talk about evolution and
rank the intelligence of these devices?
","['Gabriella Panuccio', 'Marianna Semprini', 'Lorenzo Natale', 'Michela Chiappalone']"
http://arxiv.org/abs/2404.00047v2,Neurotechnology,2024-03-25T09:43:20Z,2024-09-11T17:02:08Z,"Foundational guidelines for enhancing neurotechnology research and
  development through end-user involvement","  Neurotechnologies are increasingly becoming integrated with our everyday
lives, our bodies and our mental states. As the popularity and impact of
neurotechnology grows, so does our responsibility to ensure we understand its
particular implications on its end users, as well as broader ethical and
societal implications. Enabling end-users and stakeholders to participate in
the development of neurotechnology, from its earliest stages of conception,
will help us better navigate our design around these considerations and deliver
more impactful technologies. There are many terms and frameworks to articulate
the concept of involving end users in the technology development lifecycle, for
example: 'Public and Patient Involvement and Engagement' (PPIE), 'lived
experience' and 'co-design'. Here we utilise the PPIE framework to develop
clear guidelines for implementing a robust involvement process of current and
future end-users in neurotechnology. We present best practice guidance for
researchers and engineers who are interested in developing and conducting a PPI
strategy for their neurotechnology. We provide advice from various online
sources to orient individual teams (and funders) to carve up their own approach
to meaningful involvement. After an introduction that coveys the tangible and
conceptual benefits of user involvement, we guide the reader to develop a
general strategy towards setting up their own process. We then help the reader
map out their relevant stakeholders and provide advice on how to consider user
diversity and representation. We also provide advice on how to quantify the
outcomes of the engagement, as well as a check-list to ensure transparency and
accountability at various stages. The aim is the establishment of gold-standard
methodologies for ensuring that patient and public insights are at the
forefront of our scientific inquiry and product development.
","['Amparo Güemes', 'Tiago da Silva Costa', 'Tamar Makin']"
http://arxiv.org/abs/1903.00981v1,Neurotechnology,2019-03-03T20:20:32Z,2019-03-03T20:20:32Z,"A Separation Principle for Discrete-Time Fractional-Order Dynamical
  Systems and its Implications to Closed-loop Neurotechnology","  Closed-loop neurotechnology requires the capability to predict the state
evolution and its regulation under (possibly) partial measurements. There is
evidence that neurophysiological dynamics can be modeled by fractional-order
dynamical systems. Therefore, we propose to establish a separation principle
for discrete-time fractional-order dynamical systems, which are inherently
nonlinear and are able to capture spatiotemporal relations that exhibit
non-Markovian properties. The separation principle states that the problems of
controller and state estimator design can be done independently of each other
while ensuring proper estimation and control in closed-loop setups. Lastly, we
illustrate, as proof-of-concept, the application of the separation principle
when designing controllers and estimators for these classes of systems in the
context of neurophysiological data. In particular, we rely on real data to
derive the models used to assess and regulate the evolution of closed-loop
neurotechnologies based on electroencephalographic data.
","['Sarthak Chatterjee', 'Orlando Romero', 'Sérgio Pequito']"
http://arxiv.org/abs/2110.11475v1,Neurotechnology,2021-10-21T20:54:24Z,2021-10-21T20:54:24Z,Future of Smart Classroom in the Era of Wearable Neurotechnology,"  Interdisciplinary research among engineering, computer science, and
neuroscience to understand and utilize the human brain signals resulted in
advances and widespread applicability of wearable neurotechnology in adaptive
human-in-the-loop smart systems. Considering these advances, we envision that
future education will exploit the advances in wearable neurotechnology and move
toward more personalized smart classrooms where instructions and interactions
are tailored towards. students' individual strengths and needs. In this paper,
we discuss the future of smart classrooms and how advances in neuroscience,
machine learning, and embedded systems as key enablers will provide the
infrastructure for envisioned smart classrooms and personalized education along
with open challenges that are required to be addressed.
","['Mojtaba Taherisadr', 'Berken Utku Demirel', 'Mohammad Abdullah Al Faruque', 'Salma Elmalaki']"
http://arxiv.org/abs/2403.07945v4,Neurotechnology,2024-03-11T03:44:18Z,2025-01-26T20:27:15Z,"A Mathematical Framework for the Problem of Security for Cognition in
  Neurotechnology","  The rapid advancement in neurotechnology in recent years has created an
emerging critical intersection between neurotechnology and security.
Implantable devices, non-invasive monitoring, and non-invasive therapies all
carry with them the prospect of violating the privacy and autonomy of
individuals' cognition. A growing number of scientists and physicians have made
calls to address this issue, but applied efforts have been relatively limited.
A major barrier hampering scientific and engineering efforts to address these
security issues is the lack of a clear means of describing and analyzing
relevant problems. In this paper we develop Cognitive Neurosecurity, a
mathematical framework which enables such description and analysis by drawing
on methods and results from multiple fields. We demonstrate certain statistical
properties which have significant implications for Cognitive Neurosecurity, and
then present descriptions of the algorithmic problems faced by attackers
attempting to violate privacy and autonomy, and defenders attempting to
obstruct such attempts.
","['Bryce Allen Bagley', 'Claudia K Petritsch']"
http://arxiv.org/abs/2207.13190v1,Neurotechnology,2022-07-26T21:38:01Z,2022-07-26T21:38:01Z,How does artificial intelligence contribute to iEEG research?,"  Artificial intelligence (AI) is a fast-growing field focused on modeling and
machine implementation of various cognitive functions with an increasing number
of applications in computer vision, text processing, robotics, neurotechnology,
bio-inspired computing and others. In this chapter, we describe how AI methods
can be applied in the context of intracranial electroencephalography (iEEG)
research. IEEG data is unique as it provides extremely high-quality signals
recorded directly from brain tissue. Applying advanced AI models to these data
carries the potential to further our understanding of many fundamental
questions in neuroscience. At the same time, as an invasive technique, iEEG
lends itself well to long-term, mobile brain-computer interface applications,
particularly for communication in severely paralyzed individuals. We provide a
detailed overview of these two research directions in the application of AI
techniques to iEEG. That is, (1) the development of computational models that
target fundamental questions about the neurobiological nature of cognition
(AI-iEEG for neuroscience) and (2) applied research on monitoring and
identification of event-driven brain states for the development of clinical
brain-computer interface systems (AI-iEEG for neurotechnology). We explain key
machine learning concepts, specifics of processing and modeling iEEG data and
details of state-of-the-art iEEG-based neurotechnology and brain-computer
interfaces.
","['Julia Berezutskaya', 'Anne-Lise Saive', 'Karim Jerbi', 'Marcel van Gerven']"
http://arxiv.org/abs/1703.02365v1,Neurotechnology,2017-03-07T13:12:31Z,2017-03-07T13:12:31Z,"Scientific Outreach with Teegi, a Tangible EEG Interface to Talk about
  Neurotechnologies","  Teegi is an anthropomorphic and tangible avatar exposing a users' brain
activity in real time. It is connected to a device sensing the brain by means
of electroencephalog-raphy (EEG). Teegi moves its hands and feet and closes its
eyes along with the person being monitored. It also displays on its scalp the
associated EEG signals, thanks to a semi-spherical display made of LEDs.
Attendees can interact directly with Teegi -- e.g. move its limbs -- to
discover by themselves the underlying brain processes. Teegi can be used for
scientific outreach to introduce neurotechnologies in general and
brain-computer interfaces (BCI) in particular.
","['Jérémy Frey', 'Renaud Gervais', 'Thibault Lainé', 'Maxime Duluc', 'Hugo Germain', 'Stéphanie Fleck', 'Fabien Lotte', 'Martin Hachet']"
http://arxiv.org/abs/2405.10780v2,Neurotechnology,2024-05-13T21:37:50Z,2024-05-31T15:00:36Z,"Intelligent and Miniaturized Neural Interfaces: An Emerging Era in
  Neurotechnology","  Integrating smart algorithms on neural devices presents significant
opportunities for various brain disorders. In this paper, we review the latest
advancements in the development of three categories of intelligent neural
prostheses featuring embedded signal processing on the implantable or wearable
device. These include: 1) Neural interfaces for closed-loop symptom tracking
and responsive stimulation; 2) Neural interfaces for emerging network-related
conditions, such as psychiatric disorders; and 3) Intelligent BMI SoCs for
movement recovery following paralysis.
","['Mahsa Shoaran', 'Uisub Shin', 'MohammadAli Shaeri']"
http://arxiv.org/abs/1804.10454v2,Neurotechnology,2018-04-27T11:56:04Z,2019-01-21T11:39:50Z,"Mining within-trial oscillatory brain dynamics to address the
  variability of optimized spatial filters","  Data-driven spatial filtering algorithms optimize scores such as the contrast
between two conditions to extract oscillatory brain signal components. Most
machine learning approaches for filter estimation, however, disregard
within-trial temporal dynamics and are extremely sensitive to changes in
training data and involved hyperparameters. This leads to highly variable
solutions and impedes the selection of a suitable candidate for,
e.g.,~neurotechnological applications. Fostering component introspection, we
propose to embrace this variability by condensing the functional signatures of
a large set of oscillatory components into homogeneous clusters, each
representing specific within-trial envelope dynamics.
  The proposed method is exemplified by and evaluated on a complex hand force
task with a rich within-trial structure. Based on electroencephalography data
of 18 healthy subjects, we found that the components' distinct temporal
envelope dynamics are highly subject-specific. On average, we obtained seven
clusters per subject, which were strictly confined regarding their underlying
frequency bands. As the analysis method is not limited to a specific spatial
filtering algorithm, it could be utilized for a wide range of
neurotechnological applications, e.g., to select and monitor functionally
relevant features for brain-computer interface protocols in stroke
rehabilitation.
","['Andreas Meinel', 'Henrich Kolkhorst', 'Michael Tangermann']"
http://arxiv.org/abs/1410.7550v1,Neurotechnology,2014-10-28T08:37:01Z,2014-10-28T08:37:01Z,Learning deep dynamical models from image pixels,"  Modeling dynamical systems is important in many disciplines, e.g., control,
robotics, or neurotechnology. Commonly the state of these systems is not
directly observed, but only available through noisy and potentially
high-dimensional observations. In these cases, system identification, i.e.,
finding the measurement mapping and the transition mapping (system dynamics) in
latent space can be challenging. For linear system dynamics and measurement
mappings efficient solutions for system identification are available. However,
in practical applications, the linearity assumptions does not hold, requiring
non-linear system identification techniques. If additionally the observations
are high-dimensional (e.g., images), non-linear system identification is
inherently hard. To address the problem of non-linear system identification
from high-dimensional observations, we combine recent advances in deep learning
and system identification. In particular, we jointly learn a low-dimensional
embedding of the observation by means of deep auto-encoders and a predictive
transition model in this low-dimensional space. We demonstrate that our model
enables learning good predictive models of dynamical systems from pixel
information only.
","['Niklas Wahlström', 'Thomas B. Schön', 'Marc Peter Deisenroth']"
http://arxiv.org/abs/1505.03964v1,Neurotechnology,2015-05-15T05:53:45Z,2015-05-15T05:53:45Z,"Algebraic identification of the effective connectivity of constrained
  geometric network models of neural signaling","  Cellular neural circuit and networks consisting of interconnected neurons and
glia are ulti- mately responsible for the information processing associated
with information processing in the brain. While there are major efforts aimed
at mapping the structural and (electro)physiological connectivity of brain
networks, such as the White House BRAIN Initiative aimed at the devel- opment
of neurotechnologies capable of high density neural recordings, theoretical and
compu- tational methods for analyzing and making sense of all this data seem to
be further behind. Here, we propose and provide a summary of an approach for
calculating effective connectivity from experimental observations of neuronal
network activity. The proposed method operates on network-level data, makes use
of all relevant prior knowledge, such as dynamical models of individual cells
in the network and the physical structural connectivity of the network, and is
broadly applicable to large classes of biological and non-biological networks.
","['Marius Buibas', 'Gabriel A. Silva']"
http://arxiv.org/abs/2007.11674v1,Neurotechnology,2020-07-18T18:05:14Z,2020-07-18T18:05:14Z,"Using EEG-based brain connectivity for the study of brain dynamics in
  brain-computer interfaces","  The analysis of brain connectivity aims to understand the emergence of
functional networks into the brain. This information can be used in the process
of electroencephalographic (EEG) signal analysis and classification for a
braincomputer interface (BCI). These systems provide an alternative channel of
communication and control to people with motor impairments. In this article,
four strategies for using the brain connectivity in a BCI environment as a tool
to obtain a deeper understanding of the cerebral mechanisms are proposed, with
the principal aim of developing a scheme oriented to neuro-rehabilitation of
gait in combination with different neurotechnologies and exoskeletons. This
scheme would allow improving current schemes and/or to design new control
strategies, as well as rehabilitation approaches.
",['J. A. Gaxiola-Tirado']
http://arxiv.org/abs/2101.05084v1,Neurotechnology,2020-12-10T15:32:17Z,2020-12-10T15:32:17Z,"This Face Does Not Exist ... But It Might Be Yours! Identity Leakage in
  Generative Models","  Generative adversarial networks (GANs) are able to generate high resolution
photo-realistic images of objects that ""do not exist."" These synthetic images
are rather difficult to detect as fake. However, the manner in which these
generative models are trained hints at a potential for information leakage from
the supplied training data, especially in the context of synthetic faces. This
paper presents experiments suggesting that identity information in face images
can flow from the training corpus into synthetic samples without any
adversarial actions when building or using the existing model. This raises
privacy-related questions, but also stimulates discussions of (a) the face
manifold's characteristics in the feature space and (b) how to create
generative models that do not inadvertently reveal identity information of real
subjects whose images were used for training. We used five different face
matchers (face_recognition, FaceNet, ArcFace, SphereFace and Neurotechnology
MegaMatcher) and the StyleGAN2 synthesis model, and show that this identity
leakage does exist for some, but not all methods. So, can we say that these
synthetically generated faces truly do not exist? Databases of real and
synthetically generated faces are made available with this paper to allow full
replicability of the results discussed in this work.
","['Patrick Tinsley', 'Adam Czajka', 'Patrick Flynn']"
http://arxiv.org/abs/2106.12295v1,Neurotechnology,2021-06-23T10:24:15Z,2021-06-23T10:24:15Z,Quantum Brain Networks: a Perspective,"  We propose Quantum Brain Networks (QBraiNs) as a new interdisciplinary field
integrating knowledge and methods from neurotechnology, artificial
intelligence, and quantum computing. The objective is to develop an enhanced
connectivity between the human brain and quantum computers for a variety of
disruptive applications. We foresee the emergence of hybrid classical-quantum
networks of wetware and hardware nodes, mediated by machine learning techniques
and brain-machine interfaces. QBraiNs will harness and transform in
unprecedented ways arts, science, technologies, and entrepreneurship, in
particular activities related to medicine, Internet of humans, intelligent
devices, sensorial experience, gaming, Internet of things, crypto trading, and
business.
","['E. R. Miranda', 'S. Venkatesh', 'C. Hernani-Morales', 'L. Lamata', 'J. D. Martín-Guerrero', 'E. Solano']"
http://arxiv.org/abs/2204.02362v2,Neurotechnology,2022-04-04T12:47:07Z,2022-04-13T12:02:18Z,"Challenges and Opportunities of Edge AI for Next-Generation Implantable
  BMIs","  Neuroscience and neurotechnology are currently being revolutionized by
artificial intelligence (AI) and machine learning. AI is widely used to study
and interpret neural signals (analytical applications), assist people with
disabilities (prosthetic applications), and treat underlying neurological
symptoms (therapeutic applications). In this brief, we will review the emerging
opportunities of on-chip AI for the next-generation implantable brain-machine
interfaces (BMIs), with a focus on state-of-the-art prosthetic BMIs. Major
technological challenges for the effectiveness of AI models will be discussed.
Finally, we will present algorithmic and IC design solutions to enable a new
generation of AI-enhanced and high-channel-count BMIs.
","['MohammadAli Shaeri', 'Arshia Afzal', 'Mahsa Shoaran']"
http://arxiv.org/abs/2302.03752v1,Neurotechnology,2023-02-07T20:57:15Z,2023-02-07T20:57:15Z,"Dynamic Visualization of Gyral and Sulcal Stereoelectroencephalographic
  contacts in Humans","  Stereoelectroencephalography (SEEG) is a neurosurgical method to survey
electrophysiological activity within the brain to treat disorders such as
Epilepsy. In this stereotactic approach, leads are implanted through straight
trajectories to survey both cortical and sub-cortical activity. Visualizing the
recorded locations covering sulcal and gyral activity while staying true to the
cortical architecture is challenging due to the folded, three-dimensional
nature of the human cortex. To overcome this challenge, we developed a novel
visualization concept, allowing investigators to dynamically morph between the
subjects' cortical reconstruction and an inflated cortex representation. This
inflated view, in which gyri and sulci are viewed on a smooth surface, allows
better visualization of electrodes buried within the sulcus while staying true
to the underlying cortical architecture.
","['Markus Adamek', 'Alexander P Rockhill', 'Peter Brunner', 'Dora Hermes']"
http://arxiv.org/abs/2409.11751v1,Neurotechnology,2024-09-18T07:09:59Z,2024-09-18T07:09:59Z,"Accelerated Algorithms for Source Orientation Detection (AORI) and
  Spatiotemporal LCMV (ALCMV) Beamforming in EEG Source Localization","  This paper illustrates the development of two efficient source localization
algorithms for electroencephalography (EEG) data, aimed at enhancing real-time
brain signal reconstruction while addressing the computational challenges of
traditional methods. Accurate EEG source localization is crucial for
applications in cognitive neuroscience, neurorehabilitation, and brain-computer
interfaces (BCIs). To make significant progress toward precise source
orientation detection and improved signal reconstruction, we introduce the
Accelerated Linear Constrained Minimum Variance (ALCMV) beamforming toolbox and
the Accelerated Brain Source Orientation Detection (AORI) toolbox. The ALCMV
algorithm speeds up EEG source reconstruction by utilizing recursive covariance
matrix calculations, while AORI simplifies source orientation detection from
three dimensions to one, reducing computational load by 66% compared to
conventional methods. Using both simulated and real EEG data, we demonstrate
that these algorithms maintain high accuracy, with orientation errors below
0.2% and signal reconstruction accuracy within 2%. These findings suggest that
the proposed toolboxes represent a substantial advancement in the efficiency
and speed of EEG source localization, making them well-suited for real-time
neurotechnological applications.
","['Ava Yektaeian Vaziri', 'Bahador Makkiabadi']"
http://arxiv.org/abs/2505.20509v1,Neurotechnology,2025-05-26T20:20:46Z,2025-05-26T20:20:46Z,"OpenNIRScap: An Open-Source, Low-Cost Wearable Near-Infrared
  Spectroscopy-based Brain Interfacing Cap","  Functional Near-Infrared Spectroscopy (fNIRS) is a non-invasive, real-time
method for monitoring brain activity by measuring hemodynamic responses in the
cerebral cortex. However, existing systems are expensive, bulky, and limited to
clinical or research environments. This paper introduces OpenNIRScap, an
open-source, low-cost, and wearable fNIRS system designed to make real-time
brain monitoring more accessible in everyday environments. The device features
24 custom-designed sensor boards with dual-wavelength light emitters and
photodiode detectors, a central electrical control unit (ECU) with analog
multiplexing, and a real-time data processing pipeline. Bench validation and
pilot tests on volunteers have confirmed the ability of the system to capture
cognitively evoked hemodynamic responses, supporting its potential as an
affordable tool for cognitive monitoring and portable neurotechnology
applications. The hardware, software, and graphical user interface have all
been open-sourced and made publicly available at the following link:
https://github.com/tonykim07/fNIRS.
","['Tony Kim', 'Haotian Liu', 'Chiung-Ting Huang', 'Ingrid Wu', 'Xilin Liu']"
http://arxiv.org/abs/2505.24790v1,Neurotechnology,2025-05-30T16:52:44Z,2025-05-30T16:52:44Z,"Towards model-based design of causal manipulations of brain circuits
  with high spatiotemporal precision","  Recent advancements in neurotechnology enable precise spatiotemporal patterns
of microstimulations with single-cell resolution. The choice of perturbation
sites must satisfy two key criteria: efficacy in evoking significant responses
and selectivity for the desired target effects. This choice is currently based
on laborious trial-and-error procedures, unfeasible for sequences of multi-site
stimulations. Efficient methods to design complex perturbation patterns are
urgently needed. Can we design a spatiotemporal pattern of stimulation to steer
neural activity and behavior towards a desired target? We outline a method for
achieving this goal in two steps. First, we identify the most effective
perturbation sites, or hubs, only based on short observations of spontaneous
neural activity. Second, we provide an efficient method to design multi-site
stimulation patterns by combining approaches from nonlinear dynamical systems,
control theory and data-driven methods. We demonstrate the feasibility of our
approach using multi-site stimulation patterns in recurrent network models.
","['Anandita De', 'Roozbeh Kiani', 'Luca Mazzucato']"
http://arxiv.org/abs/2504.15291v1,Reusable launch vehicle,2025-04-08T22:15:13Z,2025-04-08T22:15:13Z,"Greenhouse Gas (GHG) Emissions Poised to Rocket: Modeling the
  Environmental Impact of LEO Satellite Constellations","  The proliferation of satellite megaconstellations in low Earth orbit (LEO)
represents a significant advancement in global broadband connectivity. However,
we urgently need to understand the potential environmental impacts,
particularly greenhouse gas (GHG) emissions associated with these
constellations. This study addresses a critical gap in modeling current and
future GHG emissions by developing a comprehensive open-source life cycle
assessment (LCA) methodology, applied to 10 launch vehicles and 15
megaconstellations. Our analysis reveals that the production of launch vehicles
and propellant combustion during launch events contribute most significantly to
overall GHG emissions, accounting for 72.6% of life cycle emissions. Among the
rockets analyzed, reusable vehicles like Falcon-9 and Starship demonstrate
95.4% lower production emissions compared to non-reusable alternatives,
highlighting the environmental benefits of reusability in space technology. The
findings underscore the importance of launch vehicle and satellite design
choices to minimize potential environmental impacts. The Open-source Rocket and
Constellation Lifecycle Emissions (ORACLE) repository is freely available and
aims to facilitate further research in this field. This study provides a
critical baseline for policymakers and industry stakeholders to develop
strategies for reducing the carbon footprint of the space industry, especially
satellite megaconstellations.
","['Rushil Kukreja', 'Edward J. Oughton', 'Richard Linares']"
http://arxiv.org/abs/2107.13513v2,Reusable launch vehicle,2021-04-19T00:15:27Z,2021-12-21T07:53:19Z,Feasibility Study For Multiply Reusable Space Launch System,"  A novel concept of orbital launch system in which all stages are reusable is
presented. The first two stages called Midpoint Delivery System (MPDS) deliver
the next stages to a midpoint. A midpoint is defined by an altitude of 100 $km$
to 120 $km$ and horizontal velocity of 2.8 $km/s$ to 3.2 $km/s$. MPDS stages
decelerate in the atmosphere and perform vertical landing on barges. These
stages can be reused daily for many years. The payload is delivered from the
midpoint to a 400 $km$ Low Earth Orbit by one or two stage rocket called
Midpoint to Orbit Delivery System (MPTO). All of MPTO engines are delivered to
LEO. These engines do not return to Earth themselves. They are returned to
Earth in packs of 50 to 100 by a Reentry Vehicle. Overall, the fully and
multiply reusable launch system should deliver payload to LEO for \$300 to
\$400 per $kg$
",['Mikhail Shubov']
http://arxiv.org/abs/2009.01664v1,Reusable launch vehicle,2020-09-03T13:48:54Z,2020-09-03T13:48:54Z,"Multidisciplinary Design Optimization of Reusable Launch Vehicles for
  Different Propellants and Objectives","  Identifying the optimal design of a new launch vehicle is most important
since design decisions made in the early development phase limit the vehicles'
later performance and determines the associated costs. Reusing the first stage
via retro-propulsive landing increases the complexity even more. Therefore, we
develop an optimization framework for partially reusable launch vehicles, which
enables multidisciplinary design studies. The framework contains suitable mass
estimates of all essential subsystems and a routine to calculate the needed
propellant for the ascent and landing maneuvers. For design optimization, the
framework can be coupled with a genetic algorithm. The overall goal is to
reveal the implications of different propellant combinations and objective
functions on the launcher's optimal design for various mission scenarios. The
results show that the optimization objective influences the most suitable
propellant choice and the overall launcher design, concerning staging, weight,
size, and rocket engine parameters. In terms of gross lift-off weight, liquid
hydrogen seems to be favorable. When optimizing for a minimum structural mass
or an expandable structural mass, hydrocarbon-based solutions show better
results. Finally, launch vehicles using a hydrocarbon fuel in the first stage
and liquid hydrogen in the upper stage are an appealing alternative, combining
both fuels' benefits.
","['Kai Dresia', 'Simon Jentzsch', 'Günther Waxenegger-Wilfing', 'Robson Hahn', 'Jan Deeken', 'Michael Oschwald', 'Fabio Mota']"
http://arxiv.org/abs/2405.01264v1,Reusable launch vehicle,2024-05-02T13:13:35Z,2024-05-02T13:13:35Z,"Model Predictive Guidance for Fuel-Optimal Landing of Reusable Launch
  Vehicles","  This paper introduces a landing guidance strategy for reusable launch
vehicles (RLVs) using a model predictive approach based on sequential convex
programming (SCP). The proposed approach devises two distinct optimal control
problems (OCPs): planning a fuel-optimal landing trajectory that accommodates
practical path constraints specific to RLVs, and determining real-time optimal
tracking commands. This dual optimization strategy allows for reduced
computational load through adjustable prediction horizon lengths in the
tracking task, achieving near closed-loop performance. Enhancements in model
fidelity for the tracking task are achieved through an alternative rotational
dynamics representation, enabling a more stable numerical solution of the OCP
and accounting for vehicle transient dynamics. Furthermore, modifications of
aerodynamic force in both planning and tracking phases are proposed, tailored
for thrust-vector-controlled RLVs, to reduce the fidelity gap without adding
computational complexity. Extensive 6-DOF simulation experiments validate the
effectiveness and improved guidance performance of the proposed algorithm.
","['Ki-Wook Jung', 'Sang-Don Lee', 'Cheol-Goo Jung', 'Chang-Hun Lee']"
http://arxiv.org/abs/2406.04185v1,Reusable launch vehicle,2024-06-06T15:41:12Z,2024-06-06T15:41:12Z,Numerical Optimization Study of a Constrained Hypersonic Reentry Vehicle,"  The trajectory optimization of the atmospheric entry of a reusable launch
vehicle is studied. The objective is to maximize the crossrange of the vehicle
subject to two control-inequality path constraints, two state-inequality path
constraints, and one mixed state-and-control inequality path constraint. In
order to determine the complex switching structure in the activity of the path
constraints, a recently developed method for solving state-path constrained
optimal control problems is used. This recently developed method is designed to
algorithmically locate the points of activation and deactivation in the path
constraints and partition the domain of the independent variable into
subdomains based on these activation and deactivation points. Additionally, in
a domain where a state-inequality path constraint is found to be active, the
method algorithmically determines and enforces the additional necessary
conditions that apply on the constrained arc. A multiple-domain formulation of
Legendre-Gauss-Radau direct collocation is then employed to transcribe the
optimal control problem into a large sparse nonlinear programming problem. Two
studies are performed which analyze a variety of problem formulations of the
hypersonic reusable launch vehicle. Key features of the constrained
trajectories are presented, and the method used is shown to obtain highly
accurate solutions with minimal user intervention.
","['Cale A. Byczkowski', 'Anil V. Rao']"
http://arxiv.org/abs/2503.11862v1,Reusable launch vehicle,2025-03-14T20:43:58Z,2025-03-14T20:43:58Z,"Ignition Point Reachability for Aerodynamically-Controlled Reusable
  Launch Vehicles","  We describe a successive convex programming (Sequential Convex Programming
(SCP)) based approach for estimate the set of points where a 5-degree of
freedom (5-DoF) reusable launch vehicle (RLV) returning to a landing site can
transition from aerodynamic to propulsive descent. Determining the set of
feasible ignition points that a RLV can use and then safely land is important
for mission planning and range safety. However, past trajectory optimization
approaches for RLVs consider substantially simplified versions of the vehicle
dynamics. Furthermore, prior reachability analysis methods either do not extend
to the full constraint set needed for an RLV or are too beset by the curse of
dimensionality to handle the full 5-DoF dynamics. To solve this problem, we
describe an algorithm that approximates the projection of a high dimensional
reachable set onto a low dimensional space. Instead of computing all parts of
the reachable space, we only calculate reachability in the projected space of
interest by using repeated trajectory optimization to sample the reachable
polytope in the reduced space. The optimization can take into account initial
and terminal constraints as well as state and control constraints. We show that
our algorithm is able to compute the projection of a reachable set into a low
dimensional space by calculating the feasible ignition points for a two-phase
aerodynamic/propulsive RLV landing trajectory, while also demonstrating the
aerodynamic divert enabled by our body and fin actuator model.
","['Benjamin Chung', 'Kazuya Echigo', 'Behçet Açıkmeşe']"
http://arxiv.org/abs/1409.1036v2,Reusable launch vehicle,2014-09-03T11:14:38Z,2015-02-20T08:26:39Z,EMMI - Electric Solar Wind Sail Facilitated Manned Mars Initiative,"  The novel propellantless electric solar wind sail concept promises efficient
low thrust transportation in the Solar System outside Earth's magnetosphere.
Combined with asteroid mining to provide water and synthetic cryogenic rocket
fuel in orbits of Earth and Mars, possibilities for affordable continuous
manned presence on Mars open up. Orbital fuel and water enable reusable
bidirectional Earth-Mars vehicles for continuous manned presence on Mars and
allow smaller fuel fraction of spacecraft than what is achievable by
traditional means. Water can also be used as radiation shielding of the manned
compartment, thus reducing the launch mass further. In addition, the presence
of fuel in the orbit of Mars provides the option for an all-propulsive landing,
thus potentially eliminating issues of heavy heat shields and augmenting the
capability of pinpoint landing. With this E-sail enabled scheme, the recurrent
cost of continuous bidirectional traffic between Earth and Mars might
ultimately approach the recurrent cost of running the International Space
Station, ISS.
","['Pekka Janhunen', 'Sini Merikallio', 'Mark Paton']"
http://arxiv.org/abs/1606.02387v1,Reusable launch vehicle,2016-06-08T03:42:41Z,2016-06-08T03:42:41Z,"Angle-of-Attack Modulation in Trajectory Tracking for a Reusable Launch
  Vehicle","  This paper deals with the problem of angle-of-attack modulation with the aim
of enhancing transient performance of entry guidance during bank reversals,
while compensating adverse effects of fast time-varying transient disturbances.
An extended single-input/single-output system is developed in the velocity
domain by means of a dynamic extension technique, and explicitly captures the
trajectory dynamics of angle-of-attack modulation. A normal form for this
extended system is derived for the sake of employing a feedback linearization
controller. Further, the control characteristics of angle-of-attack modulation
is found to be a non-minimum phase behavior under two common conditions in a
near- equilibrium glide flight. Therefore, the issue of angle-of-attack
modulation is formulated as robust output stabilization of the non-minimum
phase system. A disturbance observer-based feedback linearization technique is
used to design a robustly dynamical output-feedback controller for
angle-of-attack modulation, and an internal-state feedback controller for
bank-angle modulation is used to stabilize the unstable internal dynamics.
Numerical simulations are conducted to demonstrate that the performance of the
proposed method of angle-of-attack modulation is enhanced compared to the
existing shuttle method.
","['Ran Zhang', 'Huifeng Li', 'Rui Zhang']"
http://arxiv.org/abs/2310.05994v1,Reusable launch vehicle,2023-10-09T00:41:01Z,2023-10-09T00:41:01Z,Launch Vehicle High-Energy Performance Dataset,"  The choice of the launch vehicle is an important consideration during the
preliminary planning of interplanetary missions. The launch vehicle must be
highly reliable, capable of imparting sufficient energy to the spacecraft to
inject it on to an Earth-escape trajectory, and must fit within the cost
constraints of the mission. Over the recent past, the most commonly used
launchers for interplanetary missions include the Atlas V401, Atlas V551, Delta
IVH, and Falcon Heavy expendable version. The NASA Launch Vehicle Performance
website maintains a tool to help mission planners evaluate various launch
vehicles during mission studies. However, there is no comprehensive dataset
which can be used to quickly compare the launch performance and launch cost of
various options. The present study compiles a dataset of the high energy
performance of existing and planned launchers from open-source data and
performs a quantitative comparison of the launch performance and the launch
cost per kg. The Falcon Heavy expendable offers the lowest cost-per-kg for
high-energy launches, with only $0.075M per kg. The Vulcan Centaur offers
comparable performance to the Falcon Heavy. The results indicate Falcon Heavy
Expendable and the Vulcan Centaur will be the likely choice for several future
missions.
",['Athul Pradeepkumar Girija']
http://arxiv.org/abs/2310.06541v1,Reusable launch vehicle,2023-10-10T11:40:20Z,2023-10-10T11:40:20Z,"Realizing Stabilized Landing for Computation-Limited Reusable Rockets: A
  Quantum Reinforcement Learning Approach","  The advent of reusable rockets has heralded a new era in space exploration,
reducing the costs of launching satellites by a significant factor. Traditional
rockets were disposable, but the design of reusable rockets for repeated use
has revolutionized the financial dynamics of space missions. The most critical
phase of reusable rockets is the landing stage, which involves managing the
tremendous speed and attitude for safe recovery. The complexity of this task
presents new challenges for control systems, specifically in terms of precision
and adaptability. Classical control systems like the
proportional-integral-derivative (PID) controller lack the flexibility to adapt
to dynamic system changes, making them costly and time-consuming to redesign of
controller. This paper explores the integration of quantum reinforcement
learning into the control systems of reusable rockets as a promising
alternative. Unlike classical reinforcement learning, quantum reinforcement
learning uses quantum bits that can exist in superposition, allowing for more
efficient information encoding and reducing the number of parameters required.
This leads to increased computational efficiency, reduced memory requirements,
and more stable and predictable performance. Due to the nature of reusable
rockets, which must be light, heavy computers cannot fit into them. In the
reusable rocket scenario, quantum reinforcement learning, which has reduced
memory requirements due to fewer parameters, is a good solution.
","['Gyu Seon Kim', 'JaeHyun Chung', 'Soohyun Park']"
http://arxiv.org/abs/2411.04073v1,Reusable launch vehicle,2024-11-06T17:50:32Z,2024-11-06T17:50:32Z,"Rescheduling after vehicle failures in the multi-depot rural postman
  problem with rechargeable and reusable vehicles","  We present a centralized auction algorithm to solve the Multi-Depot Rural
Postman Problem with Rechargeable and Reusable Vehicles (MD-RPP-RRV), focusing
on rescheduling arc routing after vehicle failures. The problem involves
finding heuristically obtained best feasible routes for multiple rechargeable
and reusable vehicles with capacity constraints capable of performing multiple
trips from multiple depots, with the possibility of vehicle failures. Our
algorithm auctions the failed trips to active (non-failed) vehicles through
local auctioning, modifying initial routes to handle dynamic vehicle failures
efficiently. When a failure occurs, the algorithm searches for the best active
vehicle to perform the failed trip and inserts the trip into that vehicle's
route, which avoids a complete rescheduling and reduces the computational
effort. We compare the algorithm's solutions against offline optimal solutions
obtained from solving a Mixed Integer Linear Programming (MILP) formulation
using the Gurobi solver; this formulation assumes that perfect information
about the vehicle failures and failure times is given. The results demonstrate
that the centralized auction algorithm produces solutions that are, in some
cases, near optimal; moreover, the execution time for the proposed approach is
much more consistent and is, for some instances, orders of magnitude less than
the execution time of the Gurobi solver. The theoretical analysis provides an
upper bound for the competitive ratio and computational complexity of our
algorithm, offering a formal performance guarantee in dynamic failure
scenarios.
","['Eashwar Sathyamurthy', 'Jeffrey W. Herrmann', 'Shapour Azarm']"
http://arxiv.org/abs/2009.06495v1,Reusable launch vehicle,2020-09-14T14:58:12Z,2020-09-14T14:58:12Z,"Assembled Kinetic Impactor for Deflecting Asteroids via Combining the
  Spacecraft with the Launch Vehicle Final Stage","  Asteroid Impacts pose a major threat to all life on the Earth. Deflecting the
asteroid from the impact trajectory is an important way to mitigate the threat.
A kinetic impactor remains to be the most feasible method to deflect the
asteroid. However, due to the constraint of the launch capability, an impactor
with the limited mass can only produce a very limited amount of velocity
increment for the asteroid. In order to improve the deflection efficiency of
the kinetic impactor strategy, this paper proposed a new concept called the
Assembled Kinetic Impactor (AKI), which is combining the spacecraft with the
launch vehicle final stage. By making full use of the mass of the launch
vehicle final stage, the mass of the impactor will be increased, which will
cause the improvement of the deflection efficiency. According to the technical
data of Long March 5 (CZ-5) launch vehicle, the missions of deflecting Bennu
are designed to demonstrate the power of the AKI concept. Simulation results
show that, compared with the Classic Kinetic Impactor (CKI, performs
spacecraft-rocket separation), the addition of the mass of the launch vehicle
final stage can increase the deflection distance to more than 3 times, and
reduce the launch lead-time by at least 15 years. With the requirement of the
same deflection distance, the addition of the mass of the launch vehicle final
stage can reduce the number of launches to 1/3 of that of the number of CKI
launches. The AKI concept makes it possible to defend Bennu-like large
asteroids by a no-nuclear technique within 10-year launch lead-time. At the
same time, for a single CZ-5, the deflection distance of a 140 m diameter
asteroid within 10-year launch lead-time, can be increased from less than 1
Earth radii to more than 1 Earth radii.
","['Yirui Wang', 'Mingtao Li', 'Zizheng Gong', 'Jianming Wang', 'Chuankui Wang', 'Binghong Zhou']"
http://arxiv.org/abs/2303.17869v1,Reusable launch vehicle,2023-03-31T08:06:20Z,2023-03-31T08:06:20Z,"Numerical Modelling and GNSS Observations of Ionospheric Depletions due
  to a Small-Lift Launch Vehicle","  Space launches produce ionospheric disturbances which can be observed through
measurements such as Global Navigation Satellite System signal delays. Here we
report observations and numerical simulations of the ionospheric depletion due
to a Small-Lift Launch Vehicle. The case examined was the launch of a Rocket
Lab Electron at 22:30 UTC on March 22, 2021. Despite the very small launch
vehicle, ground stations in the Chatham Islands measured decreases in
line-of-sight total electron content for navigation satellite signals following
the launch. General Circulation Model results indicated ionospheric depletions
which were comparable with these measurements. Line-of-sight measurements
showed a maximum decrease of $2.7$~TECU in vertical total electron content,
compared with a simulated decrease of $2.6$~TECU. Advection of the exhaust
plume due to its initial velocity and subsequent effects of neutral winds are
identified as some remaining challenges for this form of modelling.
","['G. W. Bowden', 'M. Brown']"
http://arxiv.org/abs/2205.05205v1,Reusable launch vehicle,2022-05-10T22:56:49Z,2022-05-10T22:56:49Z,An integrated debris environment assessment model,"  Launch behaviors are a key determinant of the orbital environment. Physical
and economic forces such as fragmentations and changing launch costs, or
policies like post-mission disposal (PMD) compliance requirements, will alter
the relative attractiveness of different orbits and lead operators to adjust
their launch behaviors. However, integrating models of adaptive launch behavior
with models of the debris environment remains an open challenge. We present a
statistical framework for integrating theoretically-grounded models of launch
behavior with evolutionary models of the low-Earth orbit (LEO) environment. We
implement this framework using data on satellite launches, the orbital
environment, launch vehicle prices, sectoral revenues, and government budgets
over 2007-2020. The data are combined with a multi-shell and multi-species
Particle-in-a-Box (PIB) model of the debris environment and a two-stage
budgeting model of commercial, civil government, and defense decisions to
allocate new launches across orbital shells. We demonstrate the framework's
capabilities in three counterfactual scenarios: unexpected fragmentation events
in highly-used regions, a sharp decrease in the cost of accessing lower parts
of LEO, and increasing compliance with 25-year PMD guidelines. Substitution
across orbits based on their evolving characteristics and the behavior of other
operators induces notable changes in the debris environment relative to models
without behavioral channels.
","['Akhil Rao', 'Francesca Letizia']"
http://arxiv.org/abs/2307.12642v1,Reusable launch vehicle,2023-07-24T09:32:54Z,2023-07-24T09:32:54Z,"Simultaneous Optimization of Launch Vehicle Stage and Trajectory
  Considering Operational Safety Constraints","  A conceptual design of a launch vehicle involves the optimization of
trajectory and stages considering its launch operations. This process
encompasses various disciplines, such as structural design, aerodynamics,
propulsion systems, flight control, and stage sizing. Traditional approaches
used for the conceptual design of a launch vehicle conduct the stage and
trajectory designs sequentially, often leading to high computational complexity
and suboptimal results. This paper presents an optimization framework that
addresses both trajectory optimization and staging in an integrated way. The
proposed framework aims to maximize the payload-to-liftoff mass ratio while
satisfying the constraints required for safe launch operations (e.g., the
impact points of burnt stages and fairing). A case study demonstrates the
advantage of the proposed framework compared to the traditional sequential
optimization approach.
","['Jaeyoul Ko', 'Jaewoo Kim', 'Jimin Choi', 'Jaemyung Ahn']"
http://arxiv.org/abs/2008.13239v1,Reusable launch vehicle,2020-08-30T18:44:18Z,2020-08-30T18:44:18Z,"Convex Optimization of Launch Vehicle Ascent Trajectory with Heat-Flux
  and Splash-Down Constraints","  This paper presents a convex programming approach to the optimization of a
multistage launch vehicle ascent trajectory, from the liftoff to the payload
injection into the target orbit, taking into account multiple nonconvex
constraints, such as the maximum heat flux after fairing jettisoning and the
splash-down of the burned-out stages. Lossless and successive convexification
are employed to convert the problem into a sequence of convex subproblems.
Virtual controls and buffer zones are included to ensure the recursive
feasibility of the process and a state-of-the-art method for updating the
reference solution is implemented to filter out undesired phenomena that may
hinder convergence. A hp pseudospectral discretization scheme is used to
accurately capture the complex ascent and return dynamics with a limited
computational effort. The convergence properties, computational efficiency, and
robustness of the algorithm are discussed on the basis of numerical results.
The ascent of the VEGA launch vehicle toward a polar orbit is used as case
study to discuss the interaction between the heat flux and splash-down
constraints. Finally, a sensitivity analysis of the launch vehicle carrying
capacity to different splash-down locations is presented.
","['Boris Benedikter', 'Alessandro Zavoli', 'Guido Colasurdo', 'Simone Pizzurro', 'Enrico Cavallini']"
http://arxiv.org/abs/1611.06925v1,Reusable launch vehicle,2016-11-21T18:13:27Z,2016-11-21T18:13:27Z,"Robust Design of H-infinity Controller for a Launch Vehicle Autopilot
  against Disturbances","  Atmospheric flight phase of a launch vehicle is utilized to evaluate the
performance of an H-infinity controller in the presence of disturbances.
Dynamics of the vehicle is linearly modeled using time-varying parameters. An
operating point was found to design a robust command tracker using H-infinity
control theory that guarantees a stable maneuver. At the end, the controller
was employed on the launch vehicle to assess the capability of control design
on the linearized aerospace vehicle. Experimental results illustrate the
excellent performance of the H-infinity controller and accurate tracking
implemented by the autopilot. Also the robustness of the entire system against
disturbances is demonstrated to be acceptable.
","['Antonio Graells', 'Francisco Carrabina']"
http://arxiv.org/abs/1611.05512v1,Reusable launch vehicle,2016-11-17T00:13:45Z,2016-11-17T00:13:45Z,"Unmatched Perturbation Accommodation for an Aerospace Launch Vehicle
  Autopilot Using Dynamic Sliding Manifolds","  Sliding mode control of a launch vehicle during its atmospheric flight phase
is studied in the presence of unmatched disturbances. Linear time-varying
dynamics of the aerospace vehicle is converted into a systematic formula and
then dynamic sliding manifold as an advanced method is used in order to
overcome the limited capability of conventional sliding manifolds in minimizing
the undesired effects of unmatched perturbations on the control system. At the
end, simulation results are evaluated and the performance of two approaches are
compared in terms of stability and robustness of the autopilot.
",['Mohammad Reza Saniee']
http://arxiv.org/abs/2307.16788v1,Reusable launch vehicle,2023-07-31T15:55:50Z,2023-07-31T15:55:50Z,Congestion Analysis for the DARPA OFFSET CCAST Swarm,"  The Defense Advanced Research Projects Agency (DARPA) OFFensive Swarm-Enabled
Tactics program's goal of launching 250 unmanned aerial and ground vehicles
from a limited sized launch zone was a daunting challenge. The swarm's aerial
vehicles were primarily multirotor platforms, which can efficiently be launched
en masse. Each field exercise expected the deployment of an even larger swarm.
While the launch zone's spatial area increased with each field exercise, the
relative space for each vehicle was not necessarily increased, considering the
increasing size of the swarm and the vehicles' associated GPS error; however,
safe mission deployment and execution were expected. At the same time,
achieving the mission goals required maximizing efficiency of the swarm's
performance by reducing congestion that blocked vehicles from completing tactic
assignments. Congestion analysis conducted before the final field exercise
focused on adjusting various constraints to optimize the swarm's deployment
without reducing safety. During the field exercise, data was collected that
permitted analyzing the number and durations of individual vehicle blockages'
impact on the resulting congestion. After the field exercise, additional
analyses used the mission plan to validate the use of simulation for analyzing
congestion.
","['Robert Brown', 'Julie A. Adams']"
http://arxiv.org/abs/1911.05639v1,Reusable launch vehicle,2019-11-13T17:16:51Z,2019-11-13T17:16:51Z,Design of a Ballistically-Launched Foldable Multirotor,"  The operation of multirotors in crowded environments requires a highly
reliable takeoff method, as failures during takeoff can damage more valuable
assets nearby. The addition of a ballistic launch system imposes a
deterministic path for the multirotor to prevent collisions with its
environment, as well as increases the multirotor's range of operation and
allows deployment from an unsteady platform. In addition, outfitting planetary
rovers or entry vehicles with such deployable multirotors has the potential to
greatly extend the data collection capabilities of a mission. A
proof-of-concept multirotor aircraft has been developed, capable of
transitioning from a ballistic launch configuration to a fully controllable
flight configuration in midair after launch. The transition is accomplished via
passive unfolding of the multirotor arms, triggered by a nichrome burn wire
release mechanism. The design is 3D printable, launches from a three-inch
diameter barrel, and has sufficient thrust to carry a significant payload. The
system has been fabricated and field tested from a moving vehicle up to 50mph
to successfully demonstrate the feasibility of the concept and experimentally
validate the design's aerodynamic stability and deployment reliability.
","['Daniel Pastor', 'Jacob Izraelevitz', 'Paul Nadan', 'Amanda Bouman', 'Joel Burdick', 'Brett Kennedy']"
http://arxiv.org/abs/1907.13114v1,Robotics,2019-07-30T17:56:17Z,2019-07-30T17:56:17Z,The Use of Agricultural Robots in Orchard Management,"  Book chapter that summarizes recent research on agricultural robotics in
orchard management, including Robotic pruning, Robotic thinning, Robotic
spraying, Robotic harvesting, Robotic fruit transportation, and future trends.
","['Qin Zhang', 'Manoj Karkee', 'Amy Tabb']"
http://arxiv.org/abs/2208.05095v1,Robotics,2022-08-10T01:02:57Z,2022-08-10T01:02:57Z,Robotics in Snow and Ice,"  Definition: The terms ""robotics in snow and ice"" refers to robotic systems
being studied, developed, and used in areas where water can be found in its
solid state. This specialized branch of field robotics investigates the impact
of extreme conditions related to cold environments on autonomous vehicles.
",['François Pomerleau']
http://arxiv.org/abs/2005.07474v1,Robotics,2020-05-15T11:31:54Z,2020-05-15T11:31:54Z,Robot Accident Investigation: a case study in Responsible Robotics,"  Robot accidents are inevitable. Although rare, they have been happening since
assembly-line robots were first introduced in the 1960s. But a new generation
of social robots are now becoming commonplace. Often with sophisticated
embedded artificial intelligence (AI) social robots might be deployed as care
robots to assist elderly or disabled people to live independently. Smart robot
toys offer a compelling interactive play experience for children and
increasingly capable autonomous vehicles (AVs) the promise of hands-free
personal transport and fully autonomous taxis. Unlike industrial robots which
are deployed in safety cages, social robots are designed to operate in human
environments and interact closely with humans; the likelihood of robot
accidents is therefore much greater for social robots than industrial robots.
This paper sets out a draft framework for social robot accident investigation;
a framework which proposes both the technology and processes that would allow
social robot accidents to be investigated with no less rigour than we expect of
air or rail accident investigations. The paper also places accident
investigation within the practice of responsible robotics, and makes the case
that social robotics without accident investigation would be no less
irresponsible than aviation without air accident investigation.
","['Alan F. T. Winfield', 'Katie Winkle', 'Helena Webb', 'Ulrik Lyngs', 'Marina Jirotka', 'Carl Macrae']"
http://arxiv.org/abs/1403.2625v1,Robotics,2014-03-11T16:12:58Z,2014-03-11T16:12:58Z,Pattern Formation for Asynchronous Robots without Agreement in Chirality,"  This paper presents a deterministic algorithm for forming a given asymmetric
pattern in finite time by a set of autonomous, homogeneous, oblivious mobile
robots under the CORDA model. The robots are represented as points on the 2D
plane. There is no explicit communication between the robots. The robots
coordinate among themselves by observing the positions of the other robots on
the plane. Initially all the robots are assumed to be stationary. The robots
have local coordinate systems defined by Sense of Direction (SoD), orientation
or chirality and scale. Initially the robots are in asymmetric configuration.
We show that these robots can form any given asymmetric pattern in finite time.
","['Sruti Gan Chaudhuri', 'Swapnil Ghike', 'Shrainik Jain', 'Krishnendu Mukhopadhyaya']"
http://arxiv.org/abs/1408.2072v1,Robotics,2014-08-09T07:43:54Z,2014-08-09T07:43:54Z,Formation of General Position by Asynchronous Mobile Robots,"  The traditional distributed model of autonomous, homogeneous, mobile point
robots usually assumes that the robots do not create any visual obstruction for
the other robots, i.e., the robots are see through. In this paper, we consider
a slightly more realistic model, by incorporating the notion of obstructed
visibility (i.e., robots are not see through) for other robots. Under the new
model of visibility, a robot may not have the full view of its surroundings.
Many of the existing algorithms demand that each robot should have the complete
knowledge of the positions of other robots. Since, vision is the only mean of
their communication, it is required that the robots are in general position
(i.e., no three robots are collinear). We consider asynchronous robots. They
also do not have common chirality (or any agreement on a global coordinate
system). In this paper, we present a distributed algorithm for obtaining a
general position for the robots in finite time from any arbitrary
configuration. The algorithm also assures collision free motion for each robot.
This algorithm may also be used as a preprocessing module for many other
subsequent tasks performed by the robots.
","['S. Bhagat', 'S. Gan Chaudhuri', 'K. Mukhopadhyaya']"
http://arxiv.org/abs/2210.05204v1,Robotics,2022-10-11T07:19:04Z,2022-10-11T07:19:04Z,A review of cuspidal serial and parallel manipulators,"  Cuspidal robots can move from one inverse or direct kinematic solution to
another without ever passing through a singularity. These robots have remained
unknown because almost all industrial robots do not have this feature. However,
in fact, industrial robots are the exceptions. Some robots appeared recently in
the industrial market can be shown to be cuspidal but, surprisingly, almost
nobody knows it and robot users meet difficulties in planning trajectories with
these robots. This paper proposes a review on the fundamental and application
aspects of cuspidal robots. It addresses the important issues raised by these
robots for the design and planning of trajectories. The identification of all
cuspidal robots is still an open issue. This paper recalls in details the case
of serial robots with three joints but it also addresses robots with more
complex architectures such as 6-revolute-jointed robot and parallel robots. We
hope that this paper will help disseminate more widely knowledge on cuspidal
robots.
","['Philippe Wenger', 'Damien Chablat']"
http://arxiv.org/abs/2408.05491v1,Robotics,2024-08-10T08:43:07Z,2024-08-10T08:43:07Z,Optimal Dispersion of Silent Robots in a Ring,"  Given a set of co-located mobile robots in an unknown anonymous graph, the
robots must relocate themselves in distinct graph nodes to solve the dispersion
problem. In this paper, we consider the dispersion problem for silent robots
\cite{gorain2024collaborative}, i.e., no direct, explicit communication between
any two robots placed in the nodes of an oriented $n$ node ring network. The
robots operate in synchronous rounds. The dispersion problem for silent mobile
robots has been studied in arbitrary graphs where the robots start from a
single source. In this paper, we focus on the dispersion problem for silent
mobile robots where robots can start from multiple sources. The robots have
unique labels from a range $[0,\;L]$ for some positive integer $L$. Any two
co-located robots do not have the information about the label of the other
robot. The robots have weak multiplicity detection capability, which means they
can determine if it is alone on a node. The robots are assumed to be able to
identify an increase or decrease in the number of robots present on a node in a
particular round. However, the robots can not get the exact number of increase
or decrease in the number of robots. We have proposed a deterministic
distributed algorithm that solves the dispersion of $k$ robots in an oriented
ring in $O(\log L+k)$ synchronous rounds with $O(\log L)$ bits of memory for
each robot. A lower bound $\Omega(\log L+k)$ on time for the dispersion of $k$
robots on a ring network is presented to establish the optimality of the
proposed algorithm.
","['Bibhuti Das', 'Barun Gorain', 'Kaushik Mondal', 'Krishnendu Mukhopadhyaya', 'Supantha Pandit']"
http://arxiv.org/abs/cs/0411018v1,Robotics,2004-11-08T20:41:44Z,2004-11-08T20:41:44Z,"Artificial Intelligence and Systems Theory: Applied to Cooperative
  Robots","  This paper describes an approach to the design of a population of cooperative
robots based on concepts borrowed from Systems Theory and Artificial
Intelligence. The research has been developed under the SocRob project, carried
out by the Intelligent Systems Laboratory at the Institute for Systems and
Robotics - Instituto Superior Tecnico (ISR/IST) in Lisbon. The acronym of the
project stands both for ""Society of Robots"" and ""Soccer Robots"", the case study
where we are testing our population of robots. Designing soccer robots is a
very challenging problem, where the robots must act not only to shoot a ball
towards the goal, but also to detect and avoid static (walls, stopped robots)
and dynamic (moving robots) obstacles. Furthermore, they must cooperate to
defeat an opposing team. Our past and current research in soccer robotics
includes cooperative sensor fusion for world modeling, object recognition and
tracking, robot navigation, multi-robot distributed task planning and
coordination, including cooperative reinforcement learning in cooperative and
adversarial environments, and behavior-based architectures for real time task
execution of cooperating robot teams.
","['Pedro U. Lima', 'Luis M. M. Custodio']"
http://arxiv.org/abs/0808.1661v1,Robotics,2008-08-12T13:21:52Z,2008-08-12T13:21:52Z,"Medical robotics: where we come from, where we are and where we could go","  This short note presents a viewpoint about medical robotics.
",['Jocelyne Troccaz']
http://arxiv.org/abs/1701.07790v2,Robotics,2017-01-26T17:45:47Z,2017-04-06T02:26:42Z,Game-Theoretic Modeling of Human Adaptation in Human-Robot Collaboration,"  In human-robot teams, humans often start with an inaccurate model of the
robot capabilities. As they interact with the robot, they infer the robot's
capabilities and partially adapt to the robot, i.e., they might change their
actions based on the observed outcomes and the robot's actions, without
replicating the robot's policy. We present a game-theoretic model of human
partial adaptation to the robot, where the human responds to the robot's
actions by maximizing a reward function that changes stochastically over time,
capturing the evolution of their expectations of the robot's capabilities. The
robot can then use this model to decide optimally between taking actions that
reveal its capabilities to the human and taking the best action given the
information that the human currently has. We prove that under certain
observability assumptions, the optimal policy can be computed efficiently. We
demonstrate through a human subject experiment that the proposed model
significantly improves human-robot team performance, compared to policies that
assume complete adaptation of the human to the robot.
","['Stefanos Nikolaidis', 'Swaprava Nath', 'Ariel D. Procaccia', 'Siddhartha Srinivasa']"
http://arxiv.org/abs/1812.06784v4,Robotics,2018-12-17T14:21:37Z,2019-04-24T08:44:46Z,"Animation Techniques in Human-Robot Interaction User Studies: a
  Systematic Literature Review","  There are many different ways a robot can move in Human-Robot Interaction.
One way is to use techniques from film animation to instruct the robot to move.
This article is a systematic literature review of human-robot trials, pilots,
and evaluations that have applied techniques from animation to move a robot.
Through 27 articles, we find that animation techniques improves individual's
interaction with robots, improving individual's perception of qualities of a
robot, understanding what a robot intends to do, and showing the robot's state,
or possible emotion. Animation techniques also help people relate to robots
that do not resemble a human or robot. The studies in the articles show further
areas for research, such as applying animation principles in other types of
robots and situations, combining animation techniques with other modalities,
and testing robots moving with animation techniques over the long term.
","['Trenton Schulz', 'Jim Torresen', 'Jo Herstad']"
http://arxiv.org/abs/1904.03049v2,Robotics,2019-04-05T13:17:27Z,2019-09-08T09:23:21Z,Loosely Coupled Payload Transport System with Robot Replacement,"  In this work, we present an algorithm for robot replacement to increase the
operational time of a multi-robot payload transport system. Our system
comprises a group of nonholonomic wheeled mobile robots traversing on a known
trajectory. We design a multi-robot system with loosely coupled robots that
ensures the system lasts much longer than the battery life of an individual
robot. A system level optimization is presented, to decide on the operational
state (charging or discharging) of each robot in the system. The charging state
implies that the robot is not in a formation and is kept on charge whereas the
discharging state implies that the robot is a part of the formation. Robot
battery recharge hubs are present along the trajectory. Robots in the formation
can be replaced at these hub locations with charged robots using a replacement
mechanism. We showcase the efficacy of the proposed scheduling framework
through simulations and experiments with real robots.
","['Pulkit Verma', 'Rahul Tallamraju', 'Abhay Rawat', 'Subhasis Chand', 'Kamalakar Karlapalem']"
http://arxiv.org/abs/1909.05777v1,Robotics,2019-09-12T16:16:21Z,2019-09-12T16:16:21Z,Robots that Take Advantage of Human Trust,"  Humans often assume that robots are rational. We believe robots take optimal
actions given their objective; hence, when we are uncertain about what the
robot's objective is, we interpret the robot's actions as optimal with respect
to our estimate of its objective. This approach makes sense when robots
straightforwardly optimize their objective, and enables humans to learn what
the robot is trying to achieve. However, our insight is that---when robots are
aware that humans learn by trusting that the robot actions are
rational---intelligent robots do not act as the human expects; instead, they
take advantage of the human's trust, and exploit this trust to more efficiently
optimize their own objective. In this paper, we formally model instances of
human-robot interaction (HRI) where the human does not know the robot's
objective using a two-player game. We formulate different ways in which the
robot can model the uncertain human, and compare solutions of this game when
the robot has conservative, optimistic, rational, and trusting human models. In
an offline linear-quadratic case study and a real-time user study, we show that
trusting human models can naturally lead to communicative robot behavior, which
influences end-users and increases their involvement.
","['Dylan P. Losey', 'Dorsa Sadigh']"
http://arxiv.org/abs/2207.01684v1,Robotics,2022-07-04T19:26:13Z,2022-07-04T19:26:13Z,"Robot Vitals and Robot Health: Towards Systematically Quantifying
  Runtime Performance Degradation in Robots Under Adverse Conditions","  This paper addresses the problem of automatically detecting and quantifying
performance degradation in remote mobile robots during task execution. A robot
may encounter a variety of uncertainties and adversities during task execution,
which can impair its ability to carry out tasks effectively and cause its
performance to degrade. Such situations can be mitigated or averted by timely
detection and intervention (e.g., by a remote human supervisor taking over
control in teleoperation mode). Inspired by patient triaging systems in
hospitals, we introduce the framework of ""robot vitals"" for estimating overall
""robot health"". A robot's vitals are a set of indicators that estimate the
extent of performance degradation faced by a robot at a given point in time.
Robot health is a metric that combines robot vitals into a single scalar value
estimate of performance degradation. Experiments, both in simulation and on a
real mobile robot, demonstrate that the proposed robot vitals and robot health
can be used effectively to estimate robot performance degradation during
runtime.
","['Aniketh Ramesh', 'Rustam Stolkin', 'Manolis Chiou']"
http://arxiv.org/abs/2309.02979v1,Robotics,2023-09-06T13:24:45Z,2023-09-06T13:24:45Z,"Come Closer: The Effects of Robot Personality on Human Proxemics
  Behaviours","  Social Robots in human environments need to be able to reason about their
physical surroundings while interacting with people. Furthermore, human
proxemics behaviours around robots can indicate how people perceive the robots
and can inform robot personality and interaction design. Here, we introduce
Charlie, a situated robot receptionist that can interact with people using
verbal and non-verbal communication in a dynamic environment, where users might
enter or leave the scene at any time. The robot receptionist is stationary and
cannot navigate. Therefore, people have full control over their personal space
as they are the ones approaching the robot. We investigated the influence of
different apparent robot personalities on the proxemics behaviours of the
humans. The results indicate that different types of robot personalities,
specifically introversion and extroversion, can influence human proxemics
behaviours. Participants maintained shorter distances with the introvert robot
receptionist, compared to the extrovert robot. Interestingly, we observed that
human-robot proxemics were not the same as typical human-human interpersonal
distances, as defined in the literature. We therefore propose new proxemics
zones for human-robot interaction.
","['Meriam Moujahid', 'David A. Robb', 'Christian Dondrup', 'Helen Hastie']"
http://arxiv.org/abs/2502.01256v1,Robotics,2025-02-03T11:26:32Z,2025-02-03T11:26:32Z,Soft is Safe: Human-Robot Interaction for Soft Robots,"  With the presence of robots increasing in the society, the need for
interacting with robots is becoming necessary. The field of Human-Robot
Interaction (HRI) has emerged important since more repetitive and tiresome jobs
are being done by robots. In the recent times, the field of soft robotics has
seen a boom in the field of research and commercialization. The Industry 5.0
focuses on human robot collaboration which also spurs the field of soft
robotics. However the HRI for soft robotics is still in the nascent stage. In
this work we review and then discuss how HRI is done for soft robots. We first
discuss the control, design, materials and manufacturing of soft robots. This
will provide an understanding of what is being interacted with. Then we discuss
about the various input and output modalities that are used in HRI. The
applications where the HRI for soft robots are found in the literature are
discussed in detail. Then the limitations of HRI for soft robots and various
research opportunities that exist in this field are discussed in detail. It is
concluded that there is a huge scope for development for HRI for soft robots.
","['Rajashekhar V S', 'Gowdham Prabhakar']"
http://arxiv.org/abs/2211.05572v1,Robotics,2022-10-24T13:26:18Z,2022-10-24T13:26:18Z,Modular Robots: extending the capabilities of one robot,"  For a robot to be perfect and enter the everyday life of humans,like
computers did, it needs to move from special-purpose robots to general-purpose.
So, the idea of modularity is considered in this project.Thus, any type of task
that falls in the 4 D's of Robotization: Dull, Dirty, Dangerous and Dear can be
achieved by adding a module to the robot.
","['Aymen Rachdi', 'Fedi Zrelli', 'Amine Kammmoun']"
http://arxiv.org/abs/1610.04080v2,Robotics,2016-10-13T13:58:59Z,2016-12-08T13:26:59Z,Cuspidal Robots,"  This chapter is dedicated to the so-called cuspidal robots, i.e. those robots
that can move from one inverse geometric solution to another without meeting a
singular confuguration. This feature was discovered quite recently and has then
been fascinating a lot of researchers. After a brief history of cuspidal
robots, the chapter provides the main features of cuspidal robots: explanation
of the non-singular change of posture, uniqueness domains, regions of feasible
paths, identification and classification of cuspidal robots. The chapter
focuses on 3-R orthogonal serial robots. The case of 6-dof robots and parallel
robots is discussed in the end of this chapter.
",['Philippe Wenger']
http://arxiv.org/abs/1804.06383v1,Robotics,2018-04-17T17:26:30Z,2018-04-17T17:26:30Z,Effects of Interruptibility-Aware Robot Behavior,"  As robots become increasingly prevalent in human environments, there will
inevitably be times when a robot needs to interrupt a human to initiate an
interaction. Our work introduces the first interruptibility-aware mobile robot
system, and evaluates the effects of interruptibility-awareness on human task
performance, robot task performance, and on human interpretation of the robot's
social aptitude. Our results show that our robot is effective at predicting
interruptibility at high accuracy, allowing it to interrupt at more appropriate
times. Results of a large-scale user study show that while participants are
able to maintain task performance even in the presence of interruptions,
interruptibility-awareness improves the robot's task performance and improves
participant social perception of the robot.
","['Siddhartha Banerjee', 'Andrew Silva', 'Karen Feigh', 'Sonia Chernova']"
http://arxiv.org/abs/1805.03737v2,Robotics,2018-05-09T21:24:50Z,2019-01-27T13:42:51Z,Graph Neural Networks for Learning Robot Team Coordination,"  This paper shows how Graph Neural Networks can be used for learning
distributed coordination mechanisms in connected teams of robots. We capture
the relational aspect of robot coordination by modeling the robot team as a
graph, where each robot is a node, and edges represent communication links.
During training, robots learn how to pass messages and update internal states,
so that a target behavior is reached. As a proxy for more complex problems,
this short paper considers the problem where each robot must locally estimate
the algebraic connectivity of the team's network topology.
",['Amanda Prorok']
http://arxiv.org/abs/2007.13115v1,Stem-cell therapy,2020-07-26T12:22:16Z,2020-07-26T12:22:16Z,"Challenges in constructing genetic instruments for pharmacologic
  therapies","  The genes that encode the targets of most therapies do not have rare variants
with large-effect or common variants with moderate effects on the biomarker
reflecting the pharmacologic action of the corresponding therapy. Therefore,
providing genetic target validation for most therapies is challenging. Novel
methods are being developed to combine multiple variants in the gene encoding
the target of a therapy that are weakly associated with the biomarker
reflecting the pharmacologic action of that therapy into a genetic score that
can be used as an adequate instrumental variable. We describe one approach to
solve this important problem.
","['B. A. Ference', 'G. Davey Smith', 'M. V. Holmes', 'A. L. Catapano', 'K. K. Ray', 'S. J. Nicholls']"
http://arxiv.org/abs/1811.06262v3,Stem-cell therapy,2018-11-15T10:00:11Z,2019-10-09T11:47:59Z,"In Silico Implementation of Evolutionary Paradigm in Therapy Design:
  Towards Anti-Cancer Therapy as Darwinian Process","  In here presented in silico study we suggest a way how to implement the
evolutionary principles into anti-cancer therapy design. We hypothesize that
instead of its ongoing supervised adaptation, the therapy may be constructed as
a self-sustaining evolutionary process in a dynamic fitness landscape
established implicitly by evolving cancer cells, microenvironment and the
therapy itself. For these purposes, we replace a unified therapy with the
`therapy species', which is a population of heterogeneous elementary therapies,
and propose a way how to turn the toxicity of the elementary therapy into its
fitness in a way conforming to evolutionary causation. As a result, not only
the therapies govern the evolution of different cell phenotypes, but the cells'
resistances govern the evolution of the therapies as well. We illustrate the
approach by the minimalistic ad hoc evolutionary model. Its results indicate
that the resistant cells could bias the evolution towards more toxic elementary
therapies by inhibiting the less toxic ones. As the evolutionary causation of
cancer drug resistance has been intensively studied for a few decades, we refer
to cancer as a special case to illustrate purely theoretical analysis.
","['Branislav Brutovsky', 'Denis Horvath']"
http://arxiv.org/abs/2411.16362v2,Stem-cell therapy,2024-11-25T13:15:31Z,2024-12-04T16:30:46Z,"Optimal switching strategies in multi-drug therapies for chronic
  diseases","  Antimicrobial resistance is a threat to public health with millions of deaths
linked to drug resistant infections every year. To mitigate resistance, common
strategies that are used are combination therapies and therapy switching.
However, the stochastic nature of pathogenic mutation makes the optimization of
these strategies challenging. Here, we propose a two-scale stochastic model
that considers the effective evolution of therapies in a multidimensional
efficacy space, where each dimension represents the efficacy of a specific drug
in the therapy. The diffusion of therapies within this space is subject to
stochastic resets, representing therapy switches. The boundaries of the space,
inferred from coarser pathogen-host dynamics, can be either reflecting or
absorbing. Reflecting boundaries impede full recovery of the host, while
absorbing boundaries represent the development of antimicrobial resistance,
leading to therapy failure. We derive analytical expressions for the average
absorption times, accounting for both continuous and discrete genomic changes
using the frameworks of Langevin and Master equations, respectively. These
expressions allow us to evaluate the relevance of times between drug-switches
and the number of simultaneous drugs in relation to typical timescales for drug
resistance development. We also explore realistic scenarios where therapy
constraints are imposed to the number of administered therapies and/or their
costs, finding non-trivial optimal drug-switching protocols that maximize the
time before antimicrobial resistance develops while reducing therapy costs.
","['Juan Magalang', 'Javier Aguilar', 'Jose Perico Esguerra', 'Édgar Roldán', 'Daniel Sanchez-Taltavull']"
http://arxiv.org/abs/2102.03061v1,Stem-cell therapy,2021-02-05T08:54:38Z,2021-02-05T08:54:38Z,Applications of Artificial Intelligence in Particle Radiotherapy,"  Radiotherapy, due to its technology-intensive nature and reliance on digital
data and human-machine interactions, is particularly suited to benefit from
artificial intelligence (AI) to improve the accuracy and efficiency of its
clinical workflow. Recently, various artificial intelligence (AI) methods have
been successfully developed to exploit the benefit of the inherent physical
properties of particle therapy. Many reviews about AI applications in
radiotherapy have already been published, but none were specifically dedicated
to particle therapy. In this article, we present a comprehensive review of the
recent published works on AI applications in particle therapy, which can be
classified into particle therapy treatment planning, adaptive particle therapy,
range and dose verification and other applications in particle therapy.
Although promising results reported in these works demonstrate how AI-based
methods can help exploit the intrinsic physic advantages of particle therapy,
challenges remained to be address before AI applications in particle therapy
enjoy widespread implementation in clinical practice.
","['Chao Wu', 'Dan Nguyen', 'Jan Schuemann', 'Andrea Mairani', 'Yuehu Pu', 'Steve Jiang']"
http://arxiv.org/abs/2204.05877v1,Stem-cell therapy,2022-04-12T15:14:12Z,2022-04-12T15:14:12Z,Computational model for tumor response to adoptive cell transfer therapy,"  One of the barriers to the development of effective adoptive cell transfer
therapies (ACT), specifically for genetically engineered T-cell receptors
(TCRs), and chimeric antigen receptor (CAR) T-cells, is target antigen
heterogeneity. It is thought that intratumor heterogeneity is one of the
leading determinants of therapeutic resistance and treatment failure. While
understanding antigen heterogeneity is important for effective therapeutics, a
good therapy strategy could enhance the therapy efficiency. In this work we
introduce an agent-based model to rationalize the outcomes of two types of ACT
therapies over heterogeneous tumors: antigen specific ACT therapy and
multi-antigen recognition ACT therapy. We found that one dose of antigen
specific ACT therapy should be expected to reduce the tumor size as well as its
growth rate, however it may not be enough to completely eliminate it. A second
dose also reduced the tumor size as well as the tumor growth rate, but, due to
the intratumor heterogeneity, it turned out to be less effective than the
previous dose. Moreover, an interesting emergent phenomenon results from the
simulations, namely the formation of a shield-like structure of cells with low
oncoprotein expression. This shield turns out to protect cells with high
oncoprotein expression. On the other hand, our studies suggest that the earlier
the multi-antigen recognition ACT therapy is applied, the more efficient it
turns. In fact, it could completely eliminate the tumor. Based on our results,
it is clear that a proper therapeutic strategy could enhance the therapies
outcomes. In that direction, our computational approach provides a framework to
model treatment combinations in different scenarios and explore the
characteristics of successful and unsuccessful treatments.
","['Luciana Melina Luque', 'Carlos Manuel Carlevaro', 'Enrique Rodríguez-Lomba', 'Enrique Lomba']"
http://arxiv.org/abs/2412.06600v2,Stem-cell therapy,2024-12-09T15:49:18Z,2024-12-12T05:15:09Z,"Advancing Music Therapy: Integrating Eastern Five-Element Music Theory
  and Western Techniques with AI in the Novel Five-Element Harmony System","  In traditional medical practices, music therapy has proven effective in
treating various psychological and physiological ailments. Particularly in
Eastern traditions, the Five Elements Music Therapy (FEMT), rooted in
traditional Chinese medicine, possesses profound cultural significance and
unique therapeutic philosophies. With the rapid advancement of Information
Technology and Artificial Intelligence, applying these modern technologies to
FEMT could enhance the personalization and cultural relevance of the therapy
and potentially improve therapeutic outcomes. In this article, we developed a
music therapy system for the first time by applying the theory of the five
elements in music therapy to practice. This innovative approach integrates
advanced Information Technology and Artificial Intelligence with Five-Element
Music Therapy (FEMT) to enhance personalized music therapy practices. As
traditional music therapy predominantly follows Western methodologies, the
unique aspects of Eastern practices, specifically the Five-Element theory from
traditional Chinese medicine, should be considered. This system aims to bridge
this gap by utilizing computational technologies to provide a more
personalized, culturally relevant, and therapeutically effective music therapy
experience.
","['Yubo Zhou', 'Weizhen Bian', 'Kaitai Zhang', 'Xiaohan Gu']"
http://arxiv.org/abs/q-bio/0608028v3,Stem-cell therapy,2006-08-15T14:04:22Z,2013-05-02T22:25:31Z,"Incubation periods under various anti-retroviral therapies in
  homogeneous mixing and age-structured dynamical models: A theoretical
  approach","  With the launch of second line anti-retroviral therapy for HIV infected
individuals, there has been an increased expectation on surviving period of
people with HIV. We consider previously well-known models in HIV epidemiology
where the parameter for incubation period is used as one of the important
components to explain the dynamics of the variables. Such models are extended
here to explain the dynamics with respect to a given therapy that prolongs life
of an HIV infected individual. A deconvolution method is demonstrated for
estimation of parameters in the situations when no-therapy and multiple
therapies are given to the infected population. The models and deconvolution
method are extended in order to study the impact of therapy in age-structured
populations. A generalization for a situation when n-types of therapies are
available is given. Models are demonstrated using hypothetical data and
sensitivity of the parameters are also computed.
",['Arni S. R. Srinivasa Rao']
http://arxiv.org/abs/1504.07642v1,Stem-cell therapy,2015-04-28T20:05:31Z,2015-04-28T20:05:31Z,"Infinitesimal Perturbation Analysis for Personalized Cancer Therapy
  Design","  We use a Stochastic Hybrid Automaton (SHA) model of prostate cancer evolution
under intermittent androgen suppression (IAS) to study a threshold-based policy
for therapy design. IAS is currently one of the most widely used treatments for
advanced prostate cancer. Patients undergoing IAS are submitted to cycles of
treatment (in the form of androgen deprivation) and off-treatment periods in an
alternating manner. One of the main challenges in IAS is to optimally design a
therapy scheme, i.e., to determine when to discontinue and recommence androgen
suppression. The level of prostate specific antigen (PSA) in a patient's serum
is frequently monitored to determine when the patient will be taken off therapy
and when therapy will resume. The threshold-based policy we propose is
parameterized by lower and upper PSA threshold values and is associated with a
cost metric that combines clinically relevant measures of therapy success.
Using Infinitesimal Perturbation Analysis (IPA), we derive unbiased gradient
estimators of this cost metric with respect to the controllable PSA threshold
values based on actual data and show how these estimators can be used to
adaptively adjust controllable parameters so as to improve therapy outcomes
based on the cost metric defined.
","['Julia L. Fleck', 'Christos G. Cassandras']"
http://arxiv.org/abs/1409.1928v1,Stem-cell therapy,2014-09-05T20:00:17Z,2014-09-05T20:00:17Z,Neutron Therapy in the 21st Century,"  The question of whether or not neutron therapy works has been answered. It is
a qualified yes, as is the case with all of radiation therapy. But, neutron
therapy has not kept pace with the rest of radiation therapy in terms of beam
delivery techniques. Modern photon and proton based external beam radiotherapy
routinely implements image-guidance, beam intensity-modulation and
3-dimensional treatment planning. The current iteration of fast neutron
radiotherapy does not. Addressing these deficiencies, however, is not a matter
of technology or understanding, but resources. The future of neutron therapy
lies in better understanding the interaction processes of radiation with living
tissue. A combination of radiobiology and computer simulations is required in
order to optimize the use of neutron therapy. The questions that need to be
answered are: Can we connect the macroscopic with the microscopic? What is the
optimum energy? What is the optimum energy spectrum? Can we map the sensitivity
of the various tissues of the human body and use that knowledge to our
advantage? And once we gain a better understanding of the above radiobiological
issues will we be able to capitalize on this understanding by precisely and
accurately delivering fast neutrons in a manner comparable to what is now
possible with photons and protons? This presentation will review the
accomplishments to date. It will then lay out the questions that need to be
answered for neutron therapy to truly be a 21st Century therapy.
","['Thomas K. Kroc', 'James S. Welsh']"
http://arxiv.org/abs/1602.02077v1,Stem-cell therapy,2016-02-05T16:03:43Z,2016-02-05T16:03:43Z,Cancer and electromagnetic radiation therapy: Quo Vadis?,"  In oncology, treating cancer with a beam of photons is a well established
therapeutic technique, developed over 100 years, and today over 50% of cancer
patients will undergo traditional X-ray radiotherapy. However, ionizing
radiation therapy is not the only option, as the high-energy photons delivering
their cell-killing radiation energy into cancerous tumor can lead to
significant damage to healthy tissues surrounding the tumor, located throughout
the beam's path. Therefore, in nowadays, advances in ionizing radiation therapy
are competitive to non-ionizing ones, as for example the laser light based
therapy, resulting in a synergism that has revolutionized medicine. The use of
non-invasive or minimally invasive (e.g. through flexible endoscopes)
therapeutic procedures in the management of patients represents a very
interesting treatment option. Moreover, as the major breakthrough in cancer
management is the individualized patient treatment, new biophotonic techniques,
e.g. photo-activated drug carriers, help the improvement of treatment efficacy
and/or normal tissue toxicity. Additionally, recent studies support that laser
technology progresses could revolutionize cancer proton therapy, by reducing
the cost of the needed installations. The aim of this review is to present some
laser-based future objectives for cancer radiation therapy, aiming to address
the relevant advances in the ionizing and non-ionizing radiation therapy, i.e.
protons and heavy ions therapy, as well as photodynamic targeted and molecular
therapies.
",['Mersini Makropoulou']
http://arxiv.org/abs/1603.00895v1,Stem-cell therapy,2016-03-02T21:24:40Z,2016-03-02T21:24:40Z,Personalized Cancer Therapy Design: Robustness vs. Optimality,"  Intermittent Androgen Suppression (IAS) is a treatment strategy for delaying
or even preventing time to relapse of advanced prostate cancer. IAS consists of
alternating cycles of therapy (in the form of androgen suppression) and
off-treatment periods. The level of prostate specific antigen (PSA) in a
patient's serum is frequently monitored to determine when the patient will be
taken off therapy and when therapy will resume. In spite of extensive recent
clinical experience with IAS, the design of an ideal protocol for any given
patient remains one of the main challenges associated with effectively
implementing this therapy. We use a threshold-based policy for optimal IAS
therapy design that is parameterized by lower and upper PSA threshold values
and is associated with a cost metric that combines clinically relevant measures
of therapy success. We apply Infinitesimal Perturbation Analysis (IPA) to a
Stochastic Hybrid Automaton (SHA) model of prostate cancer evolution under IAS
and derive unbiased estimators of the cost metric gradient with respect to
various model and therapy parameters. These estimators are subsequently used
for system analysis. By evaluating sensitivity estimates with respect to
several model parameters, we identify critical parameters and demonstrate that
relaxing the optimality condition in favor of increased robustness to modeling
errors provides an alternative objective to therapy design for at least some
patients.
","['Julia L. Fleck', 'Christos G. Cassandras']"
http://arxiv.org/abs/1902.00728v1,Stem-cell therapy,2019-02-02T14:34:13Z,2019-02-02T14:34:13Z,"New combinational therapies for cancer using modern statistical
  mechanics","  We investigate a new dynamical system that describes tumor-host interaction.
The equation that describes the untreated tumor growth is based on
non-extensive statistical mechanics. Recently, this model has been shown to fit
successfully exponential, Gompertz, logistic, and power-law tumor growths. We
have been able to include as many hallmarks of cancer as possible. We study
also the dynamic response of cancer under therapy. Using our model, we can make
predictions about the different outcomes when we change the parameters, and/or
the initial conditions. We can determine the importance of different factors to
influence tumor growth. We discover synergistic therapeutic effects of
different treatments and drugs. Cancer is generally untreatable using
conventional monotherapy. We consider conventional therapies, oncogene-targeted
therapies, tumor-suppressors gene-targeted therapies, immunotherapies,
anti-angiogenesis therapies, virotherapy, among others. We need therapies with
the potential to target both tumor cells and the tumors' microenvironment.
Drugs that target oncogenes and tumor-suppressor genes can be effective in the
treatment of some cancers. However, most tumors do reoccur. We have found that
the success of the new therapeutic agents can be seen when used in combination
with other cancer-cell-killing therapies. Our results have allowed us to design
a combinational therapy that can lead to the complete eradication of cancer.
","['Jorge A. González', 'M. Acanda', 'Z. Akhtar', 'D. Andrews', 'J. I. Azqueta', 'E. Bass', 'A. Bellorín', 'J. Couso', 'Mónica A. García-Ñustes', 'Y. Infante', 'S. Jiménez', 'L. Lester', 'L. Maldonado', 'Juan F. Marín', 'L. Pineda', 'I. Rodríguez', 'C. C. Tamayo', 'D. Valdes', 'L. Vázquez']"
http://arxiv.org/abs/2112.07717v1,Stem-cell therapy,2021-12-14T19:37:20Z,2021-12-14T19:37:20Z,"Deterministic and Stochastic in-host Tuberculosis Models for
  Bacterium-directed and Host-directed Therapy Combination","  Mycobacterium tuberculosis infection can involve all immune system components
and can result in different disease outcomes. The antibiotic TB drugs require
strict adherence to prevent both disease relapse and mutation of drug- and
multidrug-resistant strains. To overcome the constraints of pathogen-directed
therapy, host-directed therapy has attracted more attention in recent years as
an adjunct therapy to enhance host immunity to fight against this intractable
pathogen. The goal of this paper is to investigate in-host tuberculosis models
to provide insights into therapy development. Focusing on therapy-targeting
parameters, the parameter regions for different disease outcomes are identified
from an established ODE model. Interestingly, the ODE model also demonstrates
that the immune responses can both benefit and impede disease progression,
depending on the number of bacteria engulfed and released by macrophages. We
then develop two It\^{o} SDE models, which consider the impact of demographic
variations at the cellular level and environmental variations during therapies
along with demographic variations. The SDE model with demographic variation
suggests that stochastic fluctuations at the cellular level have significant
influences on (1) the T-cell population in all parameter regions, (2) the
bacterial population when parameters located in the region with multiple
disease outcomes, and (3) the uninfected macrophage population in the parameter
region representing active disease. Further, considering environmental
variations from therapies, the second SDE model suggests that disease
progression can slow down if therapies (1) can have fast return rates and (2)
can bring parameter values into the disease clearance regions.
",['Wenjing Zhang']
http://arxiv.org/abs/2203.05383v2,Stem-cell therapy,2022-03-10T14:17:07Z,2022-06-16T11:29:06Z,"KSoF: The Kassel State of Fluency Dataset -- A Therapy Centered Dataset
  of Stuttering","  Stuttering is a complex speech disorder that negatively affects an
individual's ability to communicate effectively. Persons who stutter (PWS)
often suffer considerably under the condition and seek help through therapy.
Fluency shaping is a therapy approach where PWSs learn to modify their speech
to help them to overcome their stutter. Mastering such speech techniques takes
time and practice, even after therapy. Shortly after therapy, success is
evaluated highly, but relapse rates are high. To be able to monitor speech
behavior over a long time, the ability to detect stuttering events and
modifications in speech could help PWSs and speech pathologists to track the
level of fluency. Monitoring could create the ability to intervene early by
detecting lapses in fluency. To the best of our knowledge, no public dataset is
available that contains speech from people who underwent stuttering therapy
that changed the style of speaking. This work introduces the Kassel State of
Fluency (KSoF), a therapy-based dataset containing over 5500 clips of PWSs. The
clips were labeled with six stuttering-related event types: blocks,
prolongations, sound repetitions, word repetitions, interjections, and -
specific to therapy - speech modifications. The audio was recorded during
therapy sessions at the Institut der Kasseler Stottertherapie. The data will be
made available for research purposes upon request.
","['Sebastian P. Bayerl', 'Alexander Wolff von Gudenberg', 'Florian Hönig', 'Elmar Nöth', 'Korbinian Riedhammer']"
http://arxiv.org/abs/2404.10310v1,Stem-cell therapy,2024-04-16T06:37:19Z,2024-04-16T06:37:19Z,"Wireless Earphone-based Real-Time Monitoring of Breathing Exercises: A
  Deep Learning Approach","  Several therapy routines require deep breathing exercises as a key component
and patients undergoing such therapies must perform these exercises regularly.
Assessing the outcome of a therapy and tailoring its course necessitates
monitoring a patient's compliance with the therapy. While therapy compliance
monitoring is routine in a clinical environment, it is challenging to do in an
at-home setting. This is so because a home setting lacks access to specialized
equipment and skilled professionals needed to effectively monitor the
performance of a therapy routine by a patient. For some types of therapies,
these challenges can be addressed with the use of consumer-grade hardware, such
as earphones and smartphones, as practical solutions. To accurately monitor
breathing exercises using wireless earphones, this paper proposes a framework
that has the potential for assessing a patient's compliance with an at-home
therapy. The proposed system performs real-time detection of breathing phases
and channels with high accuracy by processing a $\mathbf{500}$ ms audio signal
through two convolutional neural networks. The first network, called a channel
classifier, distinguishes between nasal and oral breathing, and a pause. The
second network, called a phase classifier, determines whether the audio segment
is from inhalation or exhalation. According to $k$-fold cross-validation, the
channel and phase classifiers achieved a maximum F1 score of $\mathbf{97.99\%}$
and $\mathbf{89.46\%}$, respectively. The results demonstrate the potential of
using commodity earphones for real-time breathing channel and phase detection
for breathing therapy compliance monitoring.
","['Hassam Khan Wazir', 'Zaid Waghoo', 'Vikram Kapila']"
http://arxiv.org/abs/2410.18329v1,Stem-cell therapy,2024-10-23T23:51:53Z,2024-10-23T23:51:53Z,"When Group Spirit Meets Personal Journeys: Exploring Motivational
  Dynamics and Design Opportunities in Group Therapy","  Psychotherapy, such as cognitive-behavioral therapy (CBT), is effective in
treating various mental disorders. Technology-facilitated mental health therapy
improves client engagement through methods like digitization or gamification.
However, these innovations largely cater to individual therapy, ignoring the
potential of group therapy-a treatment for multiple clients concurrently, which
enables individual clients to receive various perspectives in the treatment
process and also addresses the scarcity of healthcare practitioners to reduce
costs. Notwithstanding its cost-effectiveness and unique social dynamics that
foster peer learning and community support, group therapy, such as group CBT,
faces the issue of attrition. While existing medical work has developed
guidelines for therapists, such as establishing leadership and empathy to
facilitate group therapy, understanding about the interactions between each
stakeholder is still missing. To bridge this gap, this study examined a group
CBT program called the Serigaya Methamphetamine Relapse Prevention Program
(SMARPP) as a case study to understand stakeholder coordination and
communication, along with factors promoting and hindering continuous engagement
in group therapy. In-depth interviews with eight facilitators and six former
clients from SMARPP revealed the motivators and demotivators for
facilitator-facilitator, client-client, and facilitator-client communications.
Our investigation uncovers the presence of discernible conflicts between
clients' intrapersonal motivation as well as interpersonal motivation in the
context of group therapy through the lens of self-determination theory. We
discuss insights and research opportunities for the HCI community to mediate
such tension and enhance stakeholder communication in future
technology-assisted group therapy settings.
","['Shixian Geng', 'Ginshi Shimojima', 'Chi-Lan Yang', 'Zefan Sramek', 'Shunpei Norihama', 'Ayumi Takano', 'Simo Hosio', 'Koji Yatani']"
http://arxiv.org/abs/1804.08990v1,Stem-cell therapy,2018-04-24T12:36:09Z,2018-04-24T12:36:09Z,Therapy Control and Patient Safety for Proton Therapy,"  This contribution describes general concepts for control and safety systems
in proton therapy. These concepts are illustrated by concrete examples
implemented in the Proscan facility at PSI.
",['Martin Grossmann']
http://arxiv.org/abs/1812.04900v1,Stem-cell therapy,2018-12-12T11:18:19Z,2018-12-12T11:18:19Z,"Model of a Data Mining System for Personalized Therapy of Speech
  Disorders","  Lately, the children with speech disorder have more and more become object of
specialists attention and investment in speech disorder therapy are increasing
The development and use of information technology in order to assist and follow
speech disorder therapy allowed researchers to collect a considerable volume of
data. The aim of this paper is to present a data mining system designed to be
associated with TERAPERS system in order to provide information based on which
one could improve the process of personalized therapy of speech disorders.
","['Mirela Danubianu', 'Stefan Gheorghe Pentiuc', 'Iolanda Tobolcea', 'Tiberiu Socaciu']"
http://arxiv.org/abs/2011.00285v1,Stem-cell therapy,2020-10-31T14:33:16Z,2020-10-31T14:33:16Z,"On The Relationship Between The Energy, Energy Spread And Distal Slope
  for Proton Therapy Observed in GEANT4","  In proton therapy both the energy, which determines the range, and the distal
slope, which reflects the rate at which the protons decelerate, are of import
if we are to ensure accurate dose deposition and maximum tissue sparing. This
publication describes a Geant4 model and presents a two-dimensional polynomial
relationship between energy, the energy spread and the distal slope for beams
with Gaussian energy spectra for proton therapy. This simple polynomial
relationship will be useful for non-invasive or minimally invasive near
real-time monitoring of the energy and energy spread of a proton therapy beam.
","['Tim Fulcher', 'Richard A Amos', 'Hywel Owen', 'Rob Edgecock']"
http://arxiv.org/abs/2209.03812v1,Stem-cell therapy,2022-09-08T13:32:30Z,2022-09-08T13:32:30Z,"Optimal personalized therapies in colon-cancer induced immune response
  using a Fokker-Planck framework","  In this paper, a new stochastic framework to determine optimal combination
therapies in colon cancer-induced immune response is presented. The dynamics of
colon cancer is described through an It\""o stochastic process, whose
probability density function evolution is governed by the Fokker-Planck
equation. An open-loop control optimization problem is proposed to determine
the optimal combination therapies. Numerical results with combination therapies
comprising of the chemotherapy drug \ind{Doxorubicin} and immunotherapy drug
IL-2 validate the proposed framework.
","['Souvik Roy', 'Suvra Pal']"
http://arxiv.org/abs/2005.04867v1,Cloud computing,2020-05-11T05:31:15Z,2020-05-11T05:31:15Z,Security of Cloud FPGAs: A Survey,"  Integrating Field Programmable Gate Arrays (FPGAs) with cloud computing
instances is a rapidly emerging trend on commercial cloud computing platforms
such as Amazon Web Services (AWS), Huawei cloud, and Alibaba cloud. Cloud FPGAs
allow cloud users to build hardware accelerators to speed up the computation in
the cloud. However, since the cloud FPGA technology is still in its infancy,
the security implications of this integration of FPGAs in the cloud are not
clear. In this paper, we survey the emerging field of cloud FPGA security,
providing a comprehensive overview of the security issues related to cloud
FPGAs, and highlighting future challenges in this research area.
","['Chenglu Jin', 'Vasudev Gohil', 'Ramesh Karri', 'Jeyavijayan Rajendran']"
http://arxiv.org/abs/1212.5956v1,Cloud computing,2012-12-24T19:24:35Z,2012-12-24T19:24:35Z,Interoperability and Standardization of Intercloud Cloud Computing,"  Cloud computing is getting mature, and the interoperability and
standardization of the clouds is still waiting to be solved. This paper
discussed the interoperability among clouds about message transmission, data
transmission and virtual machine transfer. Starting from IEEE Pioneering Cloud
Computing Initiative, this paper discussed about standardization of the cloud
computing, especially intercloud cloud computing. This paper also discussed the
standardization from the market-oriented view.
","['Jingxin K. Wang', 'Jianrui Ding', 'Tian Niu']"
http://arxiv.org/abs/2402.17216v1,Cloud computing,2024-02-27T05:14:27Z,2024-02-27T05:14:27Z,"Application of Machine Learning Optimization in Cloud Computing Resource
  Scheduling and Management","  In recent years, cloud computing has been widely used. Cloud computing refers
to the centralized computing resources, users through the access to the
centralized resources to complete the calculation, the cloud computing center
will return the results of the program processing to the user. Cloud computing
is not only for individual users, but also for enterprise users. By purchasing
a cloud server, users do not have to buy a large number of computers, saving
computing costs. According to a report by China Economic News Network, the
scale of cloud computing in China has reached 209.1 billion yuan. At present,
the more mature cloud service providers in China are Ali Cloud, Baidu Cloud,
Huawei Cloud and so on. Therefore, this paper proposes an innovative approach
to solve complex problems in cloud computing resource scheduling and management
using machine learning optimization techniques. Through in-depth study of
challenges such as low resource utilization and unbalanced load in the cloud
environment, this study proposes a comprehensive solution, including
optimization methods such as deep learning and genetic algorithm, to improve
system performance and efficiency, and thus bring new breakthroughs and
progress in the field of cloud computing resource management.Rational
allocation of resources plays a crucial role in cloud computing. In the
resource allocation of cloud computing, the cloud computing center has limited
cloud resources, and users arrive in sequence. Each user requests the cloud
computing center to use a certain number of cloud resources at a specific time.
","['Yifan Zhang', 'Bo Liu', 'Yulu Gong', 'Jiaxin Huang', 'Jingyu Xu', 'Weixiang Wan']"
http://arxiv.org/abs/1308.1303v1,Cloud computing,2013-08-05T06:11:12Z,2013-08-05T06:11:12Z,Evolution of Cloud Storage as Cloud Computing Infrastructure Service,"  Enterprises are driving towards less cost, more availability, agility,
managed risk - all of which is accelerated towards Cloud Computing. Cloud is
not a particular product, but a way of delivering IT services that are
consumable on demand, elastic to scale up and down as needed, and follow a
pay-for-usage model. Out of the three common types of cloud computing service
models, Infrastructure as a Service (IaaS) is a service model that provides
servers, computing power, network bandwidth and Storage capacity, as a service
to their subscribers. Cloud can relate to many things but without the
fundamental storage pieces, which is provided as a service namely Cloud
Storage, none of the other applications is possible. This paper introduces
Cloud Storage, which covers the key technologies in cloud computing and Cloud
Storage, management insights about cloud computing, different types of cloud
services, driving forces of cloud computing and cloud storage, advantages and
challenges of cloud storage and concludes by pinpointing few challenges to be
addressed by the cloud storage providers.
","['Arokia Paul Rajan', ' Shanmugapriyaa']"
http://arxiv.org/abs/1403.5627v1,Cloud computing,2014-03-22T08:49:30Z,2014-03-22T08:49:30Z,A Survey on Cloud Security Issues and Techniques,"  Today, cloud computing is an emerging way of computing in computer science.
Cloud computing is a set of resources and services that are offered by the
network or internet. Cloud computing extends various computing techniques like
grid computing, distributed computing. Today cloud computing is used in both
industrial field and academic field. Cloud facilitates its users by providing
virtual resources via internet. As the field of cloud computing is spreading
the new techniques are developing. This increase in cloud computing environment
also increases security challenges for cloud developers. Users of cloud save
their data in the cloud hence the lack of security in cloud can lose the users
trust. In this paper we will discuss some of the cloud security issues in
various aspects like multi-tenancy, elasticity, availability etc. The paper
also discuss existing security techniques and approaches for a secure cloud.
This paper will enable researchers and professionals to know about different
security threats and models and tools proposed.
","['Shubhanjali Sharma', 'Garima Gupta', 'P. R. Laxmi']"
http://arxiv.org/abs/1601.06289v2,Cloud computing,2016-01-23T17:08:22Z,2025-06-09T08:11:34Z,Considerations for Cloud Security Operations,"  Information Security in Cloud Computing environments is explored. Cloud
Computing is presented, security needs are discussed, and mitigation approaches
are listed. Topics covered include Information Security, Cloud Computing,
Private Cloud, Public Cloud, SaaS, PaaS, IaaS, ISO 27001, OWASP, Secure SDLC.
",['James Cusick']
http://arxiv.org/abs/1505.00236v1,Cloud computing,2015-05-01T18:10:51Z,2015-05-01T18:10:51Z,Discussion of various models related to cloud performance,"  This paper discusses the various models related to cloud computing. Knowing
the metrics related to infrastructure is very critical to enhance the
performance of cloud services. Various metrics related to clouds such as
pageview response time, admission control and enforcing elasticity to cloud
infrastructure are very crucial in analyzing the characteristics of the cloud
to enhance the cloud performance.
",['Chaitanya Krishna Kande']
http://arxiv.org/abs/1403.6918v1,Cloud computing,2014-03-27T05:07:28Z,2014-03-27T05:07:28Z,"A Comparative Study of Load Balancing Algorithms in Cloud Computing
  Environment","  Cloud Computing is a new trend emerging in IT environment with huge
requirements of infrastructure and resources. Load Balancing is an important
aspect of cloud computing environment. Efficient load balancing scheme ensures
efficient resource utilization by provisioning of resources to cloud users on
demand basis in pay as you say manner. Load Balancing may even support
prioritizing users by applying appropriate scheduling criteria. This paper
presents various load balancing schemes in different cloud environment based on
requirements specified in Service Level Agreement (SLA).
","['Mayanka Katyal', 'Atul Mishra']"
http://arxiv.org/abs/1703.00374v1,Cloud computing,2017-02-24T11:39:59Z,2017-02-24T11:39:59Z,Resource Management in Cloud Computing: Classification and Taxonomy,"  Cloud Computing is a new era of remote computing / Internet based computing
where one can access their personal resources easily from any computer through
Internet. Cloud delivers computing as a utility as it is available to the cloud
consumers on demand. It is a simple pay-per-use consumer-provider service
model. It contains large number of shared resources. So Resource Management is
always a major issue in cloud computing like any other computing paradigm. Due
to the availability of finite resources it is very challenging for cloud
providers to provide all the requested resources. From the cloud providers
perspective cloud resources must be allocated in a fair and efficient manner.
Research Survey is not available from the perspective of resource management as
a process in cloud computing. So this research paper provides a detailed
sequential view / steps on resource management in cloud computing. Firstly this
research paper classifies various resources in cloud computing. It also gives
taxonomy on resource management in cloud computing through which one can do
further research. Lastly comparisons on various resource management algorithms
has been presented.
","['Swapnil M Parikh', 'Narendra M Patel', 'Harshadkumar B Prajapati']"
http://arxiv.org/abs/1411.6771v1,Cloud computing,2014-11-25T08:56:01Z,2014-11-25T08:56:01Z,Securing the Data in Clouds with Hyperelliptic Curve Cryptography,"  In todays world, Cloud computing has attracted research communities as it
provides services in reduced cost due to virtualizing all the necessary
resources. Even modern business architecture depends upon Cloud computing .As
it is a internet based utility, which provides various services over a network,
it is prone to network based attacks. Hence security in clouds is the most
important in case of cloud computing. Cloud Security concerns the customer to
fully rely on storing data on clouds. That is why Cloud security has attracted
attention of the research community. This paper will discuss securing the data
in clouds by implementing key agreement, encryption and signature
verification/generation with hyperelliptic curve cryptography.
","['Debajyoti Mukhopadhyay', 'Ashay Shirwadkar', 'Pratik Gaikar', 'Tanmay Agrawal']"
http://arxiv.org/abs/1206.5468v1,Cloud computing,2012-06-24T07:20:46Z,2012-06-24T07:20:46Z,A Survey on Cloud Computing Security,"  Computation encounter the new approach of cloud computing which maybe keeps
the world and possibly can prepare all the human's necessities. In other words,
cloud computing is the subsequent regular step in the evolution of on-demand
information technology services and products. The Cloud is a metaphor for the
Internet and is a concept for the covered complicated infrastructure; it also
depends on sketching in computer network diagrams. In this paper we will focus
on concept of cloud computing, cloud deployment models, cloud security
challenges encryption and data protection, privacy and security and data
management and movement from grid to cloud.
","['Hero Modares', 'Rosli Salleh', 'Amirhosein Moravejosharieh', 'Hassan Keshavarz', 'Majid Talebi Shahgoli']"
http://arxiv.org/abs/1808.04143v1,Cloud computing,2018-08-13T10:45:38Z,2018-08-13T10:45:38Z,A Preliminary Study On Emerging Cloud Computing Security Challenges,"  Cloud computing is the internet based provisioning of the computing
resources, software, and information on demand. Cloud Computing is referred to
as one of most recent emerging paradigms of computing utilities. Since Cloud
computing is the dominant infrastructure of the shared services over the
internet, it is important to be aware of the security risk and the challenges
associated with this emerging computing paradigm. This survey provides a brief
introduction to the cloud computing, its major characteristics, and service
models. It also explores cloud security threats, lists a few security solutions
, and proposes a promsing research direction to deal with the evolving security
challenges in Cloud computing.
","['Babin Bhandari', 'James Zheng']"
http://arxiv.org/abs/1601.01608v1,Cloud computing,2016-01-07T17:21:41Z,2016-01-07T17:21:41Z,"Framework for cloud computing adoption: A road map for Smes to cloud
  migration","  Small and Medium size Enterprises (SME) are considered as a backbone of many
developing and developed economies of the world; they are the driving force to
any major economy across the globe. Through Cloud Computing firms outsource
their entire information technology (IT) process while concentrating more on
their core business. It allows businesses to cut down heavy cost incurred over
IT infrastructure without losing focus on customer needs. However, Cloud
industry to an extent has struggled to grow among SMEs due to the reluctance
and concerns expressed by them. Throughout the course of this study several
interviews were conducted and the literature was reviewed to understand how
cloud providers offer services and what challenges SMEs are facing. The study
identified issues like cloud knowledge, interoperability, security and
contractual concerns to be hindering SMEs adoption of cloud services. From the
interviews common practices followed by cloud vendors and what concerns SMEs
have were identified as a basis for a cloud framework which will bridge gaps
between cloud vendors and SMEs. A stepwise framework for cloud adoption is
formulated which identifies and provides recommendation to four most
predominant challenges which are hurting cloud industry and taking SMEs away
from cloud computing, as well as guide SMEs aiding in successful cloud
adoption. Moreover, this framework streamlines the cloud adoption process for
SMEs by removing ambiguity in regards to fundamentals associated with their
organisation and cloud adoption process.
","['Nabeel Khan', 'Adil Al-Yasiri']"
http://arxiv.org/abs/1605.00085v1,Cloud computing,2016-04-30T09:30:14Z,2016-04-30T09:30:14Z,"Usage of Cloud Computing Simulators and Future Systems For Computational
  Research","  Cloud Computing is an Internet based computing, whereby shared resources,
software and information, are provided to computers and devices on demand, like
the electricity grid. Currently, IaaS (Infrastructure as a Service), PaaS
(Platform as a Service) and SaaS (Software as a Service) are used as a business
model for Cloud Computing. Nowadays, the adoption and deployment of Cloud
Computing is increasing in various domains, forcing researchers to conduct
research in the area of Cloud Computing globally. Setting up the research
environment is critical for the researchers in the developing countries to
evaluate the research outputs. Currently, modeling, simulation technology and
access of resources from various university data centers has become a useful
and powerful tool in cloud computing research. Several cloud simulators have
been specifically developed by various universities to carry out Cloud
Computing research, including CloudSim, SPECI, Green Cloud and Future Systems
(the Indiana University machines India, Bravo, Delta, Echo and Foxtrot)
supports leading edge data science research and a broad range of
computing-enabled education as well as integration of ideas from cloud and HPC
systems. In this paper, the features, suitability, adaptability and the
learning curve of the existing Cloud Computing simulators and Future Systems
are reviewed and analyzed.
","['Ramkumar Lakshminarayanan', 'Rajasekar Ramalingam']"
http://arxiv.org/abs/1107.4077v1,Cloud computing,2011-07-20T19:18:36Z,2011-07-20T19:18:36Z,Is Cloud Computing Steganography-proof?,"  The paper focuses on characterisation of information hiding possibilities in
Cloud Computing. After general introduction to cloud computing and its security
we move to brief description of steganography. In particular we introduce
classification of steganographic communication scenarios in cloud computing
which is based on location of the steganograms receiver. These scenarios as
well as the threats that steganographic methods can cause must be taken into
account when designing secure cloud computing services.
","['Wojciech Mazurczyk', 'Krzysztof Szczypiorski']"
http://arxiv.org/abs/physics/0306067v1,Cloud computing,2003-06-09T11:59:36Z,2003-06-09T11:59:36Z,Surrogate cloud fields with measured cloud properties,"  This paper describes two new methods to generate 2D and 3D cloud fields based
on 1D and 2D ground based profiler meas-urements. These cloud fields share
desired statistical properties with real cloud fields. As they, however, are
similar but not the same as real clouds, we call them surrogate clouds. One
important advantage of the new methods is that the amplitude distribution of
cloud liquid water is also exactly determined by the measurement: The surrogate
clouds made with the classi-cal methods such as the Fourier method and the
Bounded Cascade method are Gaussian and 'log-normal-like', respectively. Our
first new method iteratively creates a time series with a measured amplitude
distribution and power spectrum. Our sec-ond method uses an evolutionary search
algorithm to generate cloud fields with practically arbitrary constraints.
These clouds will be used to study the relation between radiation and cloud
structure.
","['Victor Venema', 'Susanne Crewell', 'Clemens Simmer']"
http://arxiv.org/abs/1302.6267v1,Cloud computing,2013-02-25T22:36:06Z,2013-02-25T22:36:06Z,SecLaaS: Secure Logging-as-a-Service for Cloud Forensics,"  Cloud computing has emerged as a popular computing paradigm in recent years.
However, today's cloud computing architectures often lack support for computer
forensic investigations. Analyzing various logs (e.g., process logs, network
logs) plays a vital role in computer forensics. Unfortunately, collecting logs
from a cloud is very hard given the black-box nature of clouds and the
multi-tenant cloud models, where many users share the same processing and
network resources. Researchers have proposed using log API or cloud management
console to mitigate the challenges of collecting logs from cloud
infrastructure. However, there has been no concrete work, which shows how to
provide cloud logs to investigator while preserving users' privacy and
integrity of the logs. In this paper, we introduce Secure-Logging-as-a-Service
(SecLaaS), which stores virtual machines' logs and provides access to forensic
investigators ensuring the confidentiality of the cloud users. Additionally,
SeclaaS preserves proofs of past log and thus protects the integrity of the
logs from dishonest investigators or cloud providers. Finally, we evaluate the
feasibility of the scheme by implementing SecLaaS for network access logs in
OpenStack - a popular open source cloud platform.
","['Shams Zawoad', 'Amit Kumar Dutta', 'Ragib Hasan']"
http://arxiv.org/abs/1407.1963v1,Cloud computing,2014-07-08T06:20:48Z,2014-07-08T06:20:48Z,"soCloud: A service-oriented component-based PaaS for managing
  portability, provisioning, elasticity, and high availability across multiple
  clouds","  Multi-cloud computing is a promising paradigm to support very large scale
world wide distributed applications. Multi-cloud computing is the usage of
multiple, independent cloud environments, which assumed no priori agreement
between cloud providers or third party. However, multi-cloud computing has to
face several key challenges such as portability, provisioning, elasticity, and
high availability. Developers will not only have to deploy applications to a
specific cloud, but will also have to consider application portability from one
cloud to another, and to deploy distributed applications spanning multiple
clouds. This article presents soCloud a service-oriented component-based
Platform as a Service (PaaS) for managing portability, elasticity,
provisioning, and high availability across multiple clouds. soCloud is based on
the OASIS Service Component Architecture (SCA) standard in order to address
portability. soCloud provides services for managing provisioning, elasticity,
and high availability across multiple clouds. soCloud has been deployed and
evaluated on top of ten existing cloud providers: Windows Azure, DELL KACE,
Amazon EC2, CloudBees, OpenShift, dotCloud, Jelastic, Heroku, Appfog, and an
Eucalyptus private cloud.
","['Fawaz Paraiso', 'Philippe Merle', 'Lionel Seinturier']"
http://arxiv.org/abs/0901.0131v1,Cloud computing,2008-12-31T19:13:05Z,2008-12-31T19:13:05Z,Cloud Computing and Grid Computing 360-Degree Compared,"  Cloud Computing has become another buzzword after Web 2.0. However, there are
dozens of different definitions for Cloud Computing and there seems to be no
consensus on what a Cloud is. On the other hand, Cloud Computing is not a
completely new concept; it has intricate connection to the relatively new but
thirteen-year established Grid Computing paradigm, and other relevant
technologies such as utility computing, cluster computing, and distributed
systems in general. This paper strives to compare and contrast Cloud Computing
with Grid Computing from various angles and give insights into the essential
characteristics of both.
","['Ian Foster', 'Yong Zhao', 'Ioan Raicu', 'Shiyong Lu']"
http://arxiv.org/abs/2305.18308v1,Cloud computing,2023-05-16T20:26:22Z,2023-05-16T20:26:22Z,Cloud Adoption A Modern Approach,"  Todays Information Technology world is cloud-centric. Companies are intrigued
to migrate their workload private cloud from on-premise Datacenter to Public
cloud to take advantage of the latest innovations. It drives the business
growth and competitiveness of the organization. At the same time, it is
important for Enterprise Architects to understand the drawbacks and challenges
to migrate the workload to Cloud. This paper aims to identify the key factors
to migrate the workload to the cloud. It also helps an organization to identify
the candidate for cloud migration. An impulsive decision to move to the Cloud
may be detrimental to an organization. Also, I will discuss one case study to
see the benefits and disadvantages of cloud migration. This will help the
organization to maximize its ROI.
",['Subhadip Kumar']
http://arxiv.org/abs/2208.00733v1,Quantum computing,2022-08-01T10:36:13Z,2022-08-01T10:36:13Z,The Rise of Quantum Internet Computing,"  This article highlights quantum Internet computing as referring to
distributed quantum computing over the quantum Internet, analogous to
(classical) Internet computing involving (classical) distributed computing over
the (classical) Internet. Relevant to quantum Internet computing would be areas
of study such as quantum protocols for distributed nodes using quantum
information for computations, quantum cloud computing, delegated verifiable
blind or private computing, non-local gates, and distributed quantum
applications, over Internet-scale distances.
",['Seng W. Loke']
http://arxiv.org/abs/quant-ph/0003151v1,Quantum computing,2000-03-31T22:07:23Z,2000-03-31T22:07:23Z,Unconventional Quantum Computing Devices,"  This paper investigates a variety of unconventional quantum computation
devices, including fermionic quantum computers and computers that exploit
nonlinear quantum mechanics. It is shown that unconventional quantum computing
devices can in principle compute some quantities more rapidly than
`conventional' quantum computers.
",['Seth Lloyd']
http://arxiv.org/abs/1311.4939v1,Quantum computing,2013-11-20T02:23:12Z,2013-11-20T02:23:12Z,Geometrical perspective on quantum states and quantum computation,"  We interpret quantum computing as a geometric evolution process by
reformulating finite quantum systems via Connes' noncommutative geometry. In
this formulation, quantum states are represented as noncommutative connections,
while gauge transformations on the connections play a role of unitary quantum
operations. Thereby, a geometrical model for quantum computation is presented,
which is equivalent to the quantum circuit model. This result shows a geometric
way of realizing quantum computing and as such, provides an alternative
proposal of building a quantum computer.
",['Zeqian Chen']
http://arxiv.org/abs/1210.0736v1,Quantum computing,2012-10-02T11:47:37Z,2012-10-02T11:47:37Z,Quantum Computation and Quantum Information,"  Quantum computation and quantum information are of great current interest in
computer science, mathematics, physical sciences and engineering. They will
likely lead to a new wave of technological innovations in communication,
computation and cryptography. As the theory of quantum physics is fundamentally
stochastic, randomness and uncertainty are deeply rooted in quantum
computation, quantum simulation and quantum information. Consequently quantum
algorithms are random in nature, and quantum simulation utilizes Monte Carlo
techniques extensively. Thus statistics can play an important role in quantum
computation and quantum simulation, which in turn offer great potential to
revolutionize computational statistics. While only pseudo-random numbers can be
generated by classical computers, quantum computers are able to produce genuine
random numbers; quantum computers can exponentially or quadratically speed up
median evaluation, Monte Carlo integration and Markov chain simulation. This
paper gives a brief review on quantum computation, quantum simulation and
quantum information. We introduce the basic concepts of quantum computation and
quantum simulation and present quantum algorithms that are known to be much
faster than the available classic algorithms. We provide a statistical
framework for the analysis of quantum algorithms and quantum simulation.
",['Yazhen Wang']
http://arxiv.org/abs/1610.02500v1,Quantum computing,2016-10-08T08:48:09Z,2016-10-08T08:48:09Z,"Probabilistic Process Algebra to Unifying Quantum and Classical
  Computing in Closed Systems","  We have unified quantum and classical computing in open quantum systems
called qACP which is a quantum generalization of process algebra ACP. But, an
axiomatization for quantum and classical processes with an assumption of closed
quantum systems is still missing. For closed quantum systems, unitary operator,
quantum measurement and quantum entanglement are three basic components for
quantum computing. This leads to probability unavoidable. Along the solution of
qACP to unify quantum and classical computing in open quantum systems, we unify
quantum and classical computing with an assumption of closed systems under the
framework of ACP-like probabilistic process algebra. This unification make it
can be used widely in verification for quantum and classical computing mixed
systems, such as most quantum communication protocols.
",['Yong Wang']
http://arxiv.org/abs/2410.00917v1,Quantum computing,2024-09-23T15:56:14Z,2024-09-23T15:56:14Z,Google Quantum AI's Quest for Error-Corrected Quantum Computers,"  Quantum computers stand at the forefront of technological innovation,
offering exponential computational speed-ups that challenge classical computing
capabilities. At the cutting edge of this transformation is Google Quantum AI,
a leader in driving forward the development of practical quantum computers.
This article provides a comprehensive review of Google Quantum AI's pivotal
role in the quantum computing landscape over the past decade, emphasizing their
significant strides towards achieving quantum computational supremacy. By
exploring their advancements and contributions in quantum hardware, quantum
software, error correction, and quantum algorithms, this study highlights the
transformative impact of Google Quantum AI's initiatives in shaping the future
of quantum computing technology.
",['M. AbuGhanem']
http://arxiv.org/abs/2210.02886v1,Quantum computing,2022-09-16T02:37:32Z,2022-09-16T02:37:32Z,Optimal Stochastic Resource Allocation for Distributed Quantum Computing,"  With the advent of interconnected quantum computers, i.e., distributed
quantum computing (DQC), multiple quantum computers can now collaborate via
quantum networks to perform massively complex computational tasks. However, DQC
faces problems sharing quantum information because it cannot be cloned or
duplicated between quantum computers. Thanks to advanced quantum mechanics,
quantum computers can teleport quantum information across quantum networks.
However, challenges to utilizing efficiently quantum resources, e.g., quantum
computers and quantum channels, arise in DQC due to their capabilities and
properties, such as uncertain qubit fidelity and quantum channel noise. In this
paper, we propose a resource allocation scheme for DQC based on stochastic
programming to minimize the total deployment cost for quantum resources.
Essentially, the two-stage stochastic programming model is formulated to handle
the uncertainty of quantum computing demands, computing power, and fidelity in
quantum networks. The performance evaluation demonstrates the effectiveness and
ability of the proposed scheme to balance the utilization of quantum computers
and on-demand quantum computers while minimizing the overall cost of
provisioning under uncertainty.
","['Napat Ngoenriang', 'Minrui Xu', 'Sucha Supittayapornpong', 'Dusit Niyato', 'Han Yu', ' Xuemin', ' Shen']"
http://arxiv.org/abs/0804.3401v1,Quantum computing,2008-04-21T20:07:38Z,2008-04-21T20:07:38Z,Quantum Computational Complexity,"  This article surveys quantum computational complexity, with a focus on three
fundamental notions: polynomial-time quantum computations, the efficient
verification of quantum proofs, and quantum interactive proof systems.
Properties of quantum complexity classes based on these notions, such as BQP,
QMA, and QIP, are presented. Other topics in quantum complexity, including
quantum advice, space-bounded quantum computation, and bounded-depth quantum
circuits, are also discussed.
",['John Watrous']
http://arxiv.org/abs/quant-ph/0201082v1,Quantum computing,2002-01-18T15:08:05Z,2002-01-18T15:08:05Z,"Quantum Computers and Quantum Computer Languages: Quantum Assembly
  Language and Quantum C Language","  We show a representation of Quantum Computers defines Quantum Turing Machines
with associated Quantum Grammars. We then create examples of Quantum Grammars.
Lastly we develop an algebraic approach to high level Quantum Languages using
Quantum Assembly language and Quantum C language as examples.
",['Stephen Blaha']
http://arxiv.org/abs/2410.00916v1,Quantum computing,2024-09-17T07:50:50Z,2024-09-17T07:50:50Z,"IBM Quantum Computers: Evolution, Performance, and Future Directions","  Quantum computers represent a transformative frontier in computational
technology, promising exponential speedups beyond classical computing limits.
IBM Quantum has led significant advancements in both hardware and software,
providing access to quantum hardware via IBM Cloud since 2016, achieving a
milestone with the world's first accessible quantum computer. This article
explores IBM's quantum computing journey, focusing on the development of
practical quantum computers. We summarize the evolution and advancements of IBM
Quantum's processors across generations, including their recent breakthrough
surpassing the 1,000-qubit barrier. The paper reviews detailed performance
metrics across various hardware, tracing their evolution over time and
highlighting IBM Quantum's transition from the noisy intermediate-scale quantum
(NISQ) computing era towards fault-tolerant quantum computing capabilities.
",['M. AbuGhanem']
http://arxiv.org/abs/1507.03200v1,Quantum computing,2015-07-12T07:50:13Z,2015-07-12T07:50:13Z,Duality quantum computer and the efficient quantum simulations,"  In this paper, we firstly briefly review the duality quantum computer.
Distinctly, the generalized quantum gates, the basic evolution operators in a
duality quantum computer are no longer unitary, and they can be expressed in
terms of linear combinations of unitary operators. All linear bounded operators
can be realized in a duality quantum computer, and unitary operators are just
the extreme points of the set of generalized quantum gates. A d-slits duality
quantum computer can be realized in an ordinary quantum computer with an
additional qudit using the duality quantum computing mode. Duality quantum
computer provides flexibility and clear physical picture in designing quantum
algorithms, serving as a useful bridge between quantum and classical
algorithms. In this review, we will show that duality quantum computer can
simulate quantum systems more efficiently than ordinary quantum computers by
providing descriptions of the recent efficient quantum simulation algorithms of
Childs et al [Quantum Information & Computation, 12(11-12): 901-924 (2012)] for
the fast simulation of quantum systems with a sparse Hamiltonian, and the
quantum simulation algorithm by Berry et al [Phys. Rev. Lett. 114, 090502
(2015)], which provides exponential improvement in precision for simulating
systems with a sparse Hamiltonian.
","['Shi-Jie Wei', 'Gui-Lu Long']"
http://arxiv.org/abs/quant-ph/9603028v1,Quantum computing,1996-03-26T14:44:18Z,1996-03-26T14:44:18Z,Simulations of Many-Body Quantum Systems by a Quantum Computer,"  We suggest that quantum computers can solve quantum many-body problems that
are impracticable to solve on a classical computer.
",['Stephen Wiesner']
http://arxiv.org/abs/quant-ph/0703105v1,Quantum computing,2007-03-13T15:47:07Z,2007-03-13T15:47:07Z,A bird's eye view of quantum computers,"  Quantum computers are discussed in the general framework of computation, the
laws of physics and the foundations of quantum mechanics.
","['Giuliano Benenti', 'Giuliano Strini']"
http://arxiv.org/abs/cs/0411037v2,Quantum computing,2004-11-12T18:56:15Z,2004-11-13T01:01:34Z,A Note on Bulk Quantum Turing Machine,"  Recently, among experiments for realization of quantum computers, NMR quantum
computers have achieved the most impressive succession. There is a model of the
NMR quantum computation,namely Atsumi and Nishino's bulk quantum Turing
Machine. It assumes, however, an unnatural assumption with quantum mechanics.
We, then, define a more natural and quantum mechanically realizable modified
bulk quantum Turing Machine, and show its computational ability by comparing
complexity classes with quantum Turing Machine's counter part.
",['Tetsushi Matsui']
http://arxiv.org/abs/quant-ph/9807072v1,Quantum computing,1998-07-26T10:23:48Z,1998-07-26T10:23:48Z,Pulse controlled noise suppressed quantum computation,"  To make arbitrarily accurate quantum computation possible, practical
realization of quantum computers will require suppressing noise in quantum
memory and gate operations to make it below a threshold value. A scheme based
on realistic quantum computer models is described for suppressing noise in
quantum computation without the cost of stringent quantum computing resources.
","['Lu-Ming Duan', 'Guang-Can Guo']"
http://arxiv.org/abs/1402.1141v1,Quantum computing,2014-02-05T19:48:24Z,2014-02-05T19:48:24Z,"Quantum Cybernetics and Complex Quantum Systems Science - A Quantum
  Connectionist Exploration","  Quantum cybernetics and its connections to complex quantum systems science is
addressed from the perspective of complex quantum computing systems. In this
way, the notion of an autonomous quantum computing system is introduced in
regards to quantum artificial intelligence, and applied to quantum artificial
neural networks, considered as autonomous quantum computing systems, which
leads to a quantum connectionist framework within quantum cybernetics for
complex quantum computing systems. Several examples of quantum feedforward
neural networks are addressed in regards to Boolean functions' computation,
multilayer quantum computation dynamics, entanglement and quantum
complementarity. The examples provide a framework for a reflection on the role
of quantum artificial neural networks as a general framework for addressing
complex quantum systems that perform network-based quantum computation,
possible consequences are drawn regarding quantum technologies, as well as
fundamental research in complex quantum systems science and quantum biology.
",['Carlos Pedro Gonçalves']
http://arxiv.org/abs/2208.10127v2,Quantum computing,2022-08-22T07:58:59Z,2022-08-24T11:29:19Z,"From Distributed Quantum Computing to Quantum Internet Computing: an
  Overview","  The possibility of quantum computing has been proposed decades ago, at least
as far back as the 1980s, and distributed quantum computing has been studied
around two decades ago. Recent times have seen experimental successes and
advances in quantum computer hardware and in quantum networking, leading
towards the quantum Internet. We provide in this paper an overview of concepts
and ideas in distributed quantum computing since over two decades ago as well
as look at recent efforts in the area, and consider how, with the development
of the quantum Internet, distributed quantum computing is evolving into quantum
Internet computing.
",['Seng W. Loke']
http://arxiv.org/abs/2410.11997v1,Quantum computing,2024-10-15T19:04:29Z,2024-10-15T19:04:29Z,Quantum Computing for Multi Period Asset Allocation,"  Portfolio construction has been a long-standing topic of research in finance.
The computational complexity and the time taken both increase rapidly with the
number of investments in the portfolio. It becomes difficult, even impossible
for classic computers to solve. Quantum computing is a new way of computing
which takes advantage of quantum superposition and entanglement. It changes how
such problems are approached and is not constrained by some of the classic
computational complexity. Studies have shown that quantum computing can offer
significant advantages over classical computing in many fields. The application
of quantum computing has been constrained by the unavailability of actual
quantum computers. In the past decade, there has been the rapid development of
the large-scale quantum computer. However, software development for quantum
computing is slow in many fields. In our study, we apply quantum computing to a
multi-asset portfolio simulation. The simulation is based on historic data,
covariance, and expected returns, all calculated using quantum computing.
Although technically a solvable problem for classical computing, we believe the
software development is important to the future application of quantum
computing in finance. We conducted this study through simulation of a quantum
computer and the use of Rensselaer Polytechnic Institute's IBM quantum
computer.
","['Queenie Sun', 'Nicholas Grablevsky', 'Huaizhang Deng', 'Pooya Azadi']"
http://arxiv.org/abs/0708.0261v1,Quantum computing,2007-08-02T02:50:42Z,2007-08-02T02:50:42Z,An Introduction to Quantum Computing,"  Quantum Computing is a new and exciting field at the intersection of
mathematics, computer science and physics. It concerns a utilization of quantum
mechanics to improve the efficiency of computation. Here we present a gentle
introduction to some of the ideas in quantum computing. The paper begins by
motivating the central ideas of quantum mechanics and quantum computation with
simple toy models. From there we move on to a formal presentation of the small
fraction of (finite dimensional) quantum mechanics that we will need for basic
quantum computation. Central notions of quantum architecture (qubits and
quantum gates) are described. The paper ends with a presentation of one of the
simplest quantum algorithms: Deutsch's algorithm. Our presentation demands
neither advanced mathematics nor advanced physics.
",['Noson S. Yanofsky']
http://arxiv.org/abs/1106.3982v1,Quantum computing,2011-06-20T18:24:51Z,2011-06-20T18:24:51Z,Quantum Computing via The Bethe Ansatz,"  We recognize quantum circuit model of computation as factorisable scattering
model and propose that a quantum computer is associated with a quantum
many-body system solved by the Bethe ansatz. As an typical example to support
our perspectives on quantum computation, we study quantum computing in
one-dimensional nonrelativistic system with delta-function interaction, where
the two-body scattering matrix satisfies the factorisation equation (the
quantum Yang--Baxter equation) and acts as a parametric two-body quantum gate.
We conclude by comparing quantum computing via the factorisable scattering with
topological quantum computing.
",['Yong Zhang']
http://arxiv.org/abs/1903.02723v1,Virtual reality,2019-03-07T04:29:50Z,2019-03-07T04:29:50Z,"Symmetrical Reality: Toward a Unified Framework for Physical and Virtual
  Reality","  In this paper, we review the background of physical reality, virtual reality,
and some traditional mixed forms of them. Based on the current knowledge, we
propose a new unified concept called symmetrical reality to describe the
physical and virtual world in a unified perspective. Under the framework of
symmetrical reality, the traditional virtual reality, augmented reality,
inverse virtual reality, and inverse augmented reality can be interpreted using
a unified presentation. We analyze the characteristics of symmetrical reality
from two different observation locations (i.e., from the physical world and
from the virtual world), where all other forms of physical and virtual reality
can be treated as special cases of symmetrical reality.
","['Zhenliang Zhang', 'Cong Wang', 'Dongdong Weng', 'Yue Liu', 'Yongtian Wang']"
http://arxiv.org/abs/1808.03413v1,Virtual reality,2018-08-10T05:23:37Z,2018-08-10T05:23:37Z,Inverse Augmented Reality: A Virtual Agent's Perspective,"  We propose a framework called inverse augmented reality (IAR) which describes
the scenario that a virtual agent living in the virtual world can observe both
virtual objects and real objects. This is different from the traditional
augmented reality. The traditional virtual reality, mixed reality and augmented
reality are all generated for humans, i.e., they are human-centered frameworks.
On the contrary, the proposed inverse augmented reality is a virtual
agent-centered framework, which represents and analyzes the reality from a
virtual agent's perspective. In this paper, we elaborate the framework of
inverse augmented reality to argue the equivalence of the virtual world and the
physical world regarding the whole physical structure.
","['Zhenliang Zhang', 'Dongdong Weng', 'Haiyan Jiang', 'Yue Liu', 'Yongtian Wang']"
http://arxiv.org/abs/2104.08579v2,Virtual reality,2021-04-17T15:47:48Z,2021-05-04T17:29:28Z,"SelectVisAR: Selective Visualisation of Virtual Environments in
  Augmented Reality","  When establishing a visual connection between a virtual reality user and an
augmented reality user, it is important to consider whether the augmented
reality user faces a surplus of information. Augmented reality, compared to
virtual reality, involves two, not one, planes of information: the physical and
the virtual. We propose SelectVisAR, a selective visualisation system of
virtual environments in augmented reality. Our system enables an augmented
reality spectator to perceive a co-located virtual reality user in the context
of four distinct visualisation conditions: Interactive, Proximity, Everything,
and Dollhouse. We explore an additional two conditions, Context and Spotlight,
in a follow-up study. Our design uses a human-centric approach to information
filtering, selectively visualising only parts of the virtual environment
related to the interactive possibilities of a virtual reality user. The
research investigates how selective visualisations can be helpful or trivial
for the augmented reality user when observing a virtual reality user.
","['Robbe Cools', 'Jihae Han', 'Adalberto L. Simeone']"
http://arxiv.org/abs/1805.09454v4,Virtual reality,2018-05-23T23:41:42Z,2018-09-20T19:33:14Z,Navigating a maze differently - a user study,"  Navigating spaces is an embodied experience. Examples can vary from rescue
workers trying to save people from natural disasters; a tourist finding their
way to the nearest coffee shop, or a gamer solving a maze. Virtual reality
allows these experiences to be simulated in a controlled virtual environment.
However, virtual reality users remain anchored in the real world and the
conventions by which the virtual environment is deployed influence user
performance. There is currently a need to evaluate the degree of influence
imposed by extrinsic factors and virtual reality hardware on its users.
Traditionally, virtual reality experiences have been deployed using
Head-Mounted Displays with powerful computers rendering the graphical content
of the virtual environment; however, user input has been facilitated using an
array of human interface devices including Keyboards, Mice, Trackballs,
Touchscreens, Joysticks, Gamepads, Motion detecting cameras and Webcams. Some
of these HIDs have also been introduced for non-immersive video games and
general computing. Due to this fact, a subset of virtual reality users has
greater familiarity than others in using these HIDs. Virtual reality
experiences that utilize gamepads (controllers) to navigate virtual
environments may introduce a bias towards usability among virtual reality users
previously exposed to video-gaming.
  This article presents an evaluative user study conducted using our ubiquitous
virtual reality framework with general audiences. Among our findings, we reveal
a usability bias among virtual reality users who are predominantly video
gamers. Beyond this, we found a statistical difference in user behavior between
untethered immersive virtual reality experiences compared to untethered
non-immersive virtual reality experiences.
","['Aryabrata Basu', 'Kyle Johnsen']"
http://arxiv.org/abs/2306.07955v1,Virtual reality,2023-06-12T08:36:13Z,2023-06-12T08:36:13Z,"Virtualization of Classical Reality: Limits and Possibilities in
  Physical Simulation","  This study explores the virtualization of classical reality and aims to
establish a clear framework to determine the limits and possibilities of
virtual reality. It addresses two primary questions: whether an observer's
senses can perceive a different reality through appropriate equipment, and
whether it is possible to simulate a reality without the laws of physics. As
virtual and augmented reality are increasingly used in various fields, it is
crucial to provide well-founded responses to these inquiries. Understanding the
limitations and achievability of virtual reality is essential for creating
realistic environments in education, entertainment, and other domains.
Additionally, considering the role of physics and scientific rigor in virtual
contexts is important. The study presents a theoretical framework divided into
three sections: Methods, Results, and Discussion. The Methods section explains
the nature of computers and their ability to create perceived virtual reality.
The Results section introduces the theoretical framework, emphasizing
observable simulation and interactive simulation and highlighting their
distinctions. Finally, the Discussion section builds upon the theoretical
foundation to provide comprehensive insights and answers to the research
questions. This study enhances our understanding of the boundaries and
possibilities of virtual reality, offering concrete answers and valuable
knowledge for the development and application of virtual reality in various
domains.
",['Francesco Sisini']
http://arxiv.org/abs/1312.4322v1,Virtual reality,2013-12-16T11:33:06Z,2013-12-16T11:33:06Z,Virtual Reality: A Definition History - A Personal Essay,"  This essay, written in 1998 by an active participant in both virtual reality
development and the virtual reality definition debate, discusses the definition
of the phrase ""Virtual Reality"" (VR). I start with history from a personal
perspective, concentrating on the debate between the ""Virtual Reality"" and
""Virtual Environment"" labels in the late 1980's and early 1990's. Definitions
of VR based on specific technologies are shown to be unsatisfactory. I propose
the following definition of VR, based on the striking effects of a good VR
system: ""Virtual Reality is the use of computer technology to create the effect
of an interactive three-dimensional world in which the objects have a sense of
spatial presence."" The justification for this definition is discussed in
detail, and is favorably compared with the dictionary definitions of ""virtual""
and ""reality"". The implications of this definition for virtual reality
technology are briefly examined.
",['Steve Bryson']
http://arxiv.org/abs/2206.07748v1,Virtual reality,2022-06-15T18:21:28Z,2022-06-15T18:21:28Z,Immersion Metrics for Virtual Reality,"  Technological advances in recent years have promoted the development of
virtual reality systems that have a wide variety of hardware and software
characteristics, providing varying degrees of immersion. Immersion is an
objective property of the virtual reality system that depends on both its
hardware and software characteristics. Virtual reality systems are currently
attempting to improve immersion as much as possible. However, there is no
metric to measure the level of immersion of a virtual reality system based on
its characteristics. To date, the influence of these hardware and software
variables on immersion has only been considered individually or in small
groups. The way these system variables simultaneously affect immersion has not
been analyzed either. In this paper, we propose immersion metrics for virtual
reality systems based on their hardware and software variables, as well as the
development process that led to their formulation. From the conducted
experiment and the obtained data, we followed a methodology to find immersion
models based on the variables of the system. The immersion metrics presented in
this work offer a useful tool in the area of virtual reality and immersive
technologies, not only to measure the immersion of any virtual reality system
but also to analyze the relationship and importance of the variables of these
systems.
","['Matias N. Selzer', 'Silvia M. Castro']"
http://arxiv.org/abs/cs/0312001v3,Virtual reality,2003-11-29T14:08:56Z,2006-03-30T22:38:13Z,The concept of strong and weak virtual reality,"  We approach the virtual reality phenomenon by studying its relationship to
set theory, and we investigate the case where this is done using the
wellfoundedness property of sets. Our hypothesis is that non-wellfounded sets
(hypersets) give rise to a different quality of virtual reality than do
familiar wellfounded sets. We initially provide an alternative approach to
virtual reality based on Sommerhoff's idea of first and second order
self-awareness; both categories of self-awareness are considered as necessary
conditions for consciousness in terms of higher cognitive functions. We then
introduce a representation of first and second order self-awareness through
sets, and assume that these sets, which we call events, originally form a
collection of wellfounded sets. Strong virtual reality characterizes virtual
reality environments which have the limited capacity to create only events
associated with wellfounded sets. In contrast, the more general concept of weak
virtual reality characterizes collections of virtual reality mediated events
altogether forming an entirety larger than any collection of wellfounded sets.
By giving reference to Aczel's hyperset theory we indicate that this definition
is not empty, because hypersets encompass wellfounded sets already. Moreover,
we argue that weak virtual reality could be realized in human history through
continued progress in computer technology. Finally, we reformulate our
characterization into a more general framework, and use Baltag's Structural
Theory of Sets (STS) to show that within this general hyperset theory
Sommerhoff's first and second order self-awareness as well as both concepts of
virtual reality admit a consistent mathematical representation.
",['A. M. Lisewski']
http://arxiv.org/abs/1804.08386v1,Virtual reality,2018-04-20T15:40:39Z,2018-04-20T15:40:39Z,"All Reality: Virtual, Augmented, Mixed (X), Mediated (X,Y), and
  Multimediated Reality","  The contributions of this paper are: (1) a taxonomy of the ""Realities""
(Virtual, Augmented, Mixed, Mediated, etc.), and (2) some new kinds of
""reality"" that come from nature itself, i.e. that expand our notion beyond
synthetic realities to include also phenomenological realities.
  VR (Virtual Reality) replaces the real world with a simulated experience
(virtual world). AR (Augmented Reality) allows a virtual world to be
experienced while also experiencing the real world at the same time. Mixed
Reality provides blends that interpolate between real and virtual worlds in
various proportions, along a ""Virtuality"" axis, and extrapolate to an ""X-axis"".
Mediated Reality goes a step further by mixing/blending and also modifying
reality. This modifying of reality introduces a second axis. Mediated Reality
is useful as a seeing aid (e.g. modifying reality to make it easier to
understand), and for psychology experiments like Stratton's 1896 upside-down
eyeglasses experiment.
  We propose Multimediated Reality as a multidimensional multisensory mediated
reality that includes not just interactive multimedia-based reality for our
five senses, but also includes additional senses (like sensory sonar, sensory
radar, etc.), as well as our human actions/actuators. These extra senses are
mapped to our human senses using synthetic synesthesia. This allows us to
directly experience real (but otherwise invisible) phenomena, such as wave
propagation and wave interference patterns, so that we can see radio waves and
sound waves and how they interact with objects and each other. Multimediated
reality is multidimensional, multimodal, multisensory, and multiscale. It is
also multidisciplinary, in that we must consider not just the user, but also
how the technology affects others, e.g. how its physical appearance affects
social situations.
","['Steve Mann', 'Tom Furness', 'Yu Yuan', 'Jay Iorio', 'Zixin Wang']"
http://arxiv.org/abs/1502.04744v1,Virtual reality,2015-02-16T22:50:03Z,2015-02-16T22:50:03Z,"Where's My Drink? Enabling Peripheral Real World Interactions While
  Using HMDs","  Head Mounted Displays (HMDs) allow users to experience virtual reality with a
great level of immersion. However, even simple physical tasks like drinking a
beverage can be difficult and awkward while in a virtual reality experience. We
explore mixed reality renderings that selectively incorporate the physical
world into the virtual world for interactions with physical objects. We
conducted a user study comparing four rendering techniques that balances
immersion in a virtual world with ease of interaction with the physical world.
Finally, we discuss the pros and cons of each approach, suggesting guidelines
for future rendering techniques that bring physical objects into virtual
reality.
","['Pulkit Budhiraja', 'Rajinder Sodhi', 'Brett Jones', 'Kevin Karsch', 'Brian Bailey', 'David Forsyth']"
http://arxiv.org/abs/cs/0612126v1,Virtual reality,2006-12-22T19:19:41Z,2006-12-22T19:19:41Z,The virtual reality framework for engineering objects,"  A framework for virtual reality of engineering objects has been developed.
This framework may simulate different equipment related to virtual reality.
Framework supports 6D dynamics, ordinary differential equations, finite
formulas, vector and matrix operations. The framework also supports embedding
of external software.
","['Petr R. Ivankov', 'Nikolay P. Ivankov']"
http://arxiv.org/abs/2404.16839v1,Virtual reality,2024-01-30T21:24:52Z,2024-01-30T21:24:52Z,"Immersed in Reality Secured by Design -- A Comprehensive Analysis of
  Security Measures in AR/VR Environments","  Virtual reality and related technologies such as mixed and augmented reality
have received extensive coverage in both mainstream and fringe media outlets.
When the subject goes to a new AR headset, another AR device, or AR glasses,
the talk swiftly shifts to the technical and design details. Unfortunately, no
one seemed to care about security. Data theft and other forms of cyberattack
pose serious threats to virtual reality systems. Virtual reality goggles are
just specialist versions of computers or Internet of Things devices, whereas
virtual reality experiences are software packages. As a result, AR systems are
just as vulnerable as any other Internet of Things (IoT) device we use on a
daily basis, such as computers, tablets, and phones. Preventing and responding
to common cybersecurity threats and assaults is crucial. Cybercriminals can
exploit virtual reality headsets just like any other computer system. This
paper analysis the data breach induced by these assaults could result in a
variety of concerns, including but not limited to identity theft, the
unauthorized acquisition of personal information or network credentials, damage
to hardware and software, and so on. Augmented reality (AR) allows for
real-time monitoring and visualization of network activity, system logs, and
security alerts. This allows security professionals to immediately identify
threats, monitor suspicious activities, and fix any issues that develop. This
data can be displayed in an aesthetically pleasing and intuitively structured
format using augmented reality interfaces, enabling for faster analysis and
decision-making.
","['Sameer Chauhan', 'Luv Sachdeva']"
http://arxiv.org/abs/2101.02565v1,Virtual reality,2021-01-07T14:43:51Z,2021-01-07T14:43:51Z,Augmentix -- An Augmented Reality System for asymmetric Teleteaching,"  Using augmented reality in education is already a common concept, as it has
the potential to turn learning into a motivational learning experience.
However, current research only covers the students site of learning. Almost no
research focuses on the teachers' site and whether augmented reality could
potentially improve his/her workflow of teaching the students or not. Many
researchers do not differentiate between multiple user roles, like a student
and a teacher. To allow investigation into these lacks of research, a teaching
system ""Augmentix"" is presented, which includes a differentiation between the
two user roles ""teacher"" and ""student"" to potentially enhances the teachers
workflow by using augmented reality. In this system's setting the student can
explore a virtual city in virtual reality and the teacher can guide him with
augmented reality.
",['Nico Feld']
http://arxiv.org/abs/2201.07003v1,Virtual reality,2022-01-13T16:54:36Z,2022-01-13T16:54:36Z,"Use of augmented and virtual reality tools in a general secondary
  education institution in the context of blended learning","  The study examines the problem of using augmented and virtual reality in the
process of blended learning in general secondary education. The study analyzes
the meaning of the concept of ""blended learning"". The conceptual principles of
blended learning are considered. The definition of augmented and virtual
reality is given. The mixed reality is considered as a separate kind of notion.
Separate applications of virtual and augmented reality that can be used in the
process of blended learning are considered. As a result of the study, the
authors propose possible ways to use augmented reality in the educational
process. The model of using augmented and virtual reality in blended learning
in general secondary education institutions was designed. It consists of the
following blocks: goal; teacher's activity; forms of education; teaching
methods; teaching aids; organizational forms of education; pupil activity and
results. Based on the model, the methodology of using augmented and virtual
reality in blended learning in general secondary education was developed. The
methodology contains the following components: target component, content
component, technological component and resultant component. The methodology is
quite universal and can be used for any subject in general secondary education.
The types of lessons in which it is expedient to use augmented (AR) and virtual
reality(VR) are determined. Recommendations are given at which stage of the
lesson it is better to use AR and VR tools (depending on the type of lesson).
","['Valentyna Kovalenko', 'Maiia Marienko', 'Alisa Sukhikh']"
http://arxiv.org/abs/0707.3563v1,Virtual reality,2007-07-24T14:28:01Z,2007-07-24T14:28:01Z,Virtual reality: A human centered tool for improving Manufacturing,"  Manufacturing is using Virtual Reality tools to enhance the product life
cycle. Their definitions are still in flux and it is necessary to define their
connections. Thus, firstly, we will introduce more closely some definitions
where we will find that, if the Virtual manufacturing concepts originate from
machining operations and evolve in this manufacturing area, there exist a lot
of applications in different fields such as casting, forging, sheet
metalworking and robotics (mechanisms). From the recent projects in Europe or
in USA, we notice that the human perception or the simulation of mannequin is
more and more needed in both fields. In this context, we have isolated some
applications as ergonomic studies, assembly and maintenance simulation, design
or training where the virtual reality tools can be applied. Thus, we find out a
family of applications where the virtual reality tools give the engineers the
main role in the optimization process. We will illustrate our paper by several
examples where virtual reality interfaces are used and combined with
optimization tools as multi-agent systems.
","['Fouad Bennis', 'Damien Chablat', 'Philippe Dépincé']"
http://arxiv.org/abs/0801.0337v2,Virtual reality,2008-01-02T05:04:27Z,2008-01-05T08:00:28Z,The Physical World as a Virtual Reality,"  This paper explores the idea that the universe is a virtual reality created
by information processing, and relates this strange idea to the findings of
modern physics about the physical world. The virtual reality concept is
familiar to us from online worlds, but our world as a virtual reality is
usually a subject for science fiction rather than science. Yet logically the
world could be an information simulation running on a multi-dimensional
space-time screen. Indeed, if the essence of the universe is information,
matter, charge, energy and movement could be aspects of information, and the
many conservation laws could be a single law of information conservation. If
the universe were a virtual reality, its creation at the big bang would no
longer be paradoxical, as every virtual system must be booted up. It is
suggested that whether the world is an objective reality or a virtual reality
is a matter for science to resolve. Modern information science can suggest how
core physical properties like space, time, light, matter and movement could
derive from information processing. Such an approach could reconcile relativity
and quantum theories, with the former being how information processing creates
space-time, and the latter how it creates energy and matter.
",['Brian Whitworth']
http://arxiv.org/abs/1810.10206v1,Virtual reality,2018-10-24T06:23:46Z,2018-10-24T06:23:46Z,"Immercity: a curation content application in Virtual and Augmented
  reality","  When working with emergent and appealing technologies as Virtual Reality,
Mixed Reality and Augmented Reality, the issue of definitions appear very
often. Indeed, our experience with various publics allows us to notice that
technology definitions pose ambiguity and representation problems for informed
as well as novice users. In this paper we present Immercity, a content curation
system designed in the context of a collaboration between the University of
Montpellier and CapGemi-ni, to deliver a technology watch. It is also used as a
testbed for our experiences with Virtual, Mixed and Augmented reality to
explore new interaction techniques and devices, artificial intelligence
integration, visual affordances, performance , etc. But another, very
interesting goal appeared: use Immercity to communicate about Virtual, Mixed
and Augmented Reality by using them as a support.
","['Jean-Daniel Taupiac', 'Nancy Rodriguez', 'Olivier Strauss']"
http://arxiv.org/abs/1609.03695v2,Virtual reality,2016-09-13T06:29:47Z,2016-09-15T15:13:20Z,"Blending Entropy: A Term for Addressing Information Density in Mediated
  Reality","  The virtuality continuum describes the degrees of positive virtuality under
the umbrella term mixed reality. Besides adding virtual information within a
mixed environment, diminished reality aims at reducing real world information.
Mann defined the term mediated reality (MR), which also considered diminished
reality, but without the possibility to describe different degrees of fusion
between a mixed and a diminished reality. That is why this work defines the new
term blending entropy that captures the relations between a mixed and a
diminished reality. The blending entropy is based on the information density of
the mediated reality and the actual area the user has to comprehend, which is
named perceptual frustum. We describe the blending entropy's twodimensional
dependencies and detail important points in the blending entropy's space.
","['Philipp Tiefenbacher', 'Gerhard Rigoll']"
http://arxiv.org/abs/2110.00497v1,Virtual reality,2021-10-01T15:51:59Z,2021-10-01T15:51:59Z,DiVRsify: Break the Cycle and Develop VR for Everyone,"  Virtual reality technology is biased. It excludes approximately 95% the
world's population by being primarily designed for male, western, educated,
industrial, rich, and democratic populations. This bias may be due to the lack
of diversity in virtual reality researchers, research participants, developers,
and end users, fueling a noninclusive research, development, and usability
cycle. The objective of this paper is to highlight the minimal virtual reality
research involving understudied populations with respect to dimensions of
diversity, such as gender, race, culture, ethnicity, age, disability, and
neurodivergence. Specifically, we highlight numerous differences in virtual
reality usability between underrepresented groups compared to commonly studied
populations. These differences illustrate the lack of generalizability of prior
virtual reality research. Lastly, we present a call to action with the aim
that, over time, will break the cycle and enable virtual reality for everyone.
","['Tabitha C. Peck', 'Kyla McMullen', 'John Quarles']"
http://arxiv.org/abs/2405.06872v1,Virtual reality,2024-05-11T02:07:33Z,2024-05-11T02:07:33Z,eCAR: edge-assisted Collaborative Augmented Reality Framework,"  We propose a novel edge-assisted multi-user collaborative augmented reality
framework in a large indoor environment. In Collaborative Augmented Reality,
data communication that synchronizes virtual objects has large network traffic
and high network latency. Due to drift, CAR applications without continuous
data communication for coordinate system alignment have virtual object
inconsistency. In addition, synchronization messages for online virtual object
updates have high latency as the number of collaborative devices increases. To
solve this problem, we implement the CAR framework, called eCAR, which utilizes
edge computing to continuously match the device's coordinate system with less
network traffic. Furthermore, we extend the co-visibility graph of the edge
server to maintain virtual object spatial-temporal consistency in neighboring
devices by synchronizing a local graph. We evaluate the system quantitatively
and qualitatively in the public dataset and a physical indoor environment. eCAR
communicates data for coordinate system alignment between the edge server and
devices with less network traffic and latency. In addition, collaborative
augmented reality synchronization algorithms quickly and accurately host and
resolve virtual objects. The proposed system continuously aligns coordinate
systems to multiple devices in a large indoor environment and shares augmented
reality content. Through our system, users interact with virtual objects and
share augmented reality experiences with neighboring users.
","['Jinwoo Jeon', 'Woontack Woo']"
http://arxiv.org/abs/physics/0612229v1,Nanotechnology,2006-12-23T02:09:08Z,2006-12-23T02:09:08Z,The Nanotechnology R(evolution),"  Nanotechnology as a social concept and investment focal point has drawn much
attention. Here we consider the place of nanotechnology in the second great
technological revolution of mankind that began some 200 years ago. The
so-called nanotechnology revolution represents both a continuation of prior
science and technology trends and a re-awakening to the benefits of significant
investment in fundamental research. We consider the role the military might
play in the development of nanotechnology innovations, nanotechnology's context
in the history of technology, and the global competition to lead the next
technological revolution.
",['Charles Tahan']
http://arxiv.org/abs/1801.08205v1,Nanotechnology,2018-01-24T21:26:13Z,2018-01-24T21:26:13Z,"A Multidisciplinary Undergraduate Nanoscience and Nanotechnology Program
  at the University of North Dakota","  This paper describes some of the results of a National Science Foundation
Nanotechnology Undergraduate Education project that aims to establish a
nanoscience and nanotechnology program at the University of North Dakota. The
goal is to generate new interest in nanoscience and nanotechnology among
engineering and science students and prepare them with the knowledge and skills
necessary for the next generation of graduates to compete in the global market
and contribute to the nanoscience and nanotechnology field. The project
explored several aspects of student learning, including students motivations
for investigating nanotechnology through interdisciplinary coursework. To
collect this information, a survey was administered to students who enrolled to
two nanoscience and nanotechnology courses. Data collected from the survey will
be used to improve the design and delivery of future courses as part of
constructing a complete nanoscience and nanotechnology curriculum.
","['Naima Kaabouch', 'Deborah Worley', 'Matt Cavalli', 'Kanishka Marasinghe', 'Nuri Oncel', 'David Pierce', 'Brian Tande', 'Julia Zhao']"
http://arxiv.org/abs/0911.2726v1,Nanotechnology,2009-11-13T23:04:44Z,2009-11-13T23:04:44Z,"Nanotechnology as a Field of Science: Its Delineation in terms of
  Journals and Patents","  The Journal Citation Reports of the Science Citation Index 2004 were used to
delineate a core set of nanotechnology journals and a nanotechnology-relevant
set. In comparison with 2003, the core set has grown and the relevant set has
decreased. This suggests a higher degree of codification in the field of
nanotechnology: the field has become more focused in terms of citation
practices. Using the citing patterns among journals at the aggregate level, a
core group of ten nanotechnology journals in the vector space can be delineated
on the criterion of betweenness centrality. National contributions to this core
group of journals are evaluated for the years 2003, 2004, and 2005.
Additionally, the specific class of nanotechnology patents in the database of
the U.S. Patent and Trade Office (USPTO) is analyzed to determine if non-patent
literature references can be used as a source for the delineation of the
knowledge base in terms of scientific journals. The references are primarily to
general science journals and letters, and therefore not specific enough for the
purpose of delineating a journal set.
","['Loet Leydesdorff', 'Ping Zhou']"
http://arxiv.org/abs/1812.04939v1,Nanotechnology,2018-12-08T20:32:39Z,2018-12-08T20:32:39Z,Nanotechnology: The New Features,"  Nanotechnologies are attracting increasing investments from both governments
and industries around the world, which offers great opportunities to explore
the new emerging nanodevices, such as the Carbon Nanotube and Nanosensors. This
technique exploits the specific properties which arise from structure at a
scale characterized by the interplay of classical physics and quantum
mechanics. It is difficult to predict these properties a priori according to
traditional technologies. Nanotechnologies will be one of the next promising
trends after MOS technologies. However, there has been much hype around
nanotechnology, both by those who want to promote it and those who have fears
about its potentials. This paper gives a deep survey regarding different
aspects of the new nanotechnologies, such as materials, physics, and
semiconductors respectively, followed by an introduction of several
state-of-the-art nanodevices and then new nanotechnology features. Since little
research has been carried out on the toxicity of manufactured nanoparticles and
nanotubes, this paper also discusses several problems in the nanotechnology
area and gives constructive suggestions and predictions.
",['Gang Wang']
http://arxiv.org/abs/2201.07166v1,Nanotechnology,2022-01-06T22:31:17Z,2022-01-06T22:31:17Z,Nanotechnology Applications The future arrived suddenly,"  There is already a significant time, but it gives the sensation of extremely
short,nanotechnology has become one of the most promising scientific hopes in
innumerable human domains. Now the hope become reality. Countless scientific
studies in several areas of knowledge have been made since the nanoscale
emergence, carrying their contribution to the nanoscience development. The
recent research in this field allowed the union of interests among several
areas, such as physical sciences, molecular engineering, biology, biotechnology
and medicine for example, contributing to the investigation of biosystems at a
nanoscale. In this work begin discussing nanotechnology in a general way. Then
nanotechnology and the applications in industry, in electronics and in medicine
are presented and some discussion is proposed in order to define the boundaries
for the advances on those areas. In the end, nanotechnology is discussed in
terms of ethics and in terms of the borders that nanotechnology applications
must satisfyand concluding notes are presented, highlighting the results of the
analysis. Important considerations are made about the close connection between
ethics and the nanotechnology and the effects over the society and values. Some
future directions for the research are suggested.
","['Manuel Alberto M. Ferreira', 'José António Filipe']"
http://arxiv.org/abs/physics/0504007v1,Nanotechnology,2005-04-01T15:06:33Z,2005-04-01T15:06:33Z,"Societal and ethical interactions with nanotechnology (""SEIN"") -- an
  introduction","  We identify 6 important issues tied to the continued development of
nantechnology: (1) environmental issues, (2) equity issues relating to the
possible emergence of a ""nanodivide"", (3) legal, regulatory and insurance
challenges, (4) privacy issues, (5) the interaction between nanomedicine and
medical issues and (6) ""hypertechnology, or the pace of nanotechnological
change. We conclude that continued efforts are needed to build upon an emerging
inclusice dialogue engaging all of nano's stakeholders - from various publics
to entrepreneurs, industrialists, venture capitalists, scientists and
engineers-to ensure a mutually beneficial relationship between nanotechnology
and society.
","['Davis Baird', 'Tom Vogt']"
http://arxiv.org/abs/physics/0510209v1,Nanotechnology,2005-10-24T01:58:18Z,2005-10-24T01:58:18Z,"A Map of the Nanoworld: Sizing up the Science, Politics, and Business of
  the Infinitesimal","  Mapping out the eight main nodes of nanotechnology discourse that have
emerged in the past decade, we explore how various scientific, social, and
ethical islands of discussion have developed, been recognized, and are being
continually renegotiated. We do so by (1) identifying the ways in which
scientists, policy makers, entrepreneurs, educators, and environmental groups
have drawn boundaries on issues relating to nanotechnology; (2) describing
concisely the perspectives from which these boundaries are drawn; and (3)
exploring how boundaries on nanotechnology are marked and negotiated by various
nodes of nanotechnology discourse.
","['Debashish Munshi', 'Priya Kurian', 'Robert V. Bartlett', 'Akhlesh Lakhtakia']"
http://arxiv.org/abs/1001.3771v1,Nanotechnology,2010-01-21T10:58:08Z,2010-01-21T10:58:08Z,"A Study of VLSI Technology, Wafers and Impact on Nanotechnology","  This paper presents a detailed study of the present VLSI technological
aspects, importance and their replacement or combination with the
Nanotechnology in the VLSI world of silicon semiconductors. Here authors bring
out the nanotechnology in Silicon world which invariably means shrinking
geometry of CMOS devices to nano scale. This also refers to a new world of
nanotechnology where chemists are working in manufacturing of carbon nanotubes
, nano devices of varius materials of nano dimensions without even knowing how
this could change the whole world of Si and CMOS technology and the world we
live in.
","['Kiran Gupta', 'T. R. Gopalakrishnan Nair']"
http://arxiv.org/abs/2105.03431v1,Nanotechnology,2021-05-10T13:32:46Z,2021-05-10T13:32:46Z,DNA Nanotechnology Meets Nanophotonics,"  In the past decades, DNA has been intensely studied and exploited in
different research areas of nanoscience and nanotechnology. At first glance,
DNA-based nanophotonics seems to deviate quite far from the original goal of
Nadrian Seeman, the founder of DNA nanotechnology, who hoped to organize
biological entities using DNA in high-resolution crystals. As a matter of fact,
DNA-based nanophotonics does closely follow his central spirit. That is, apart
from being a genetic material for inheritance, DNA is also an ideal material
for building molecular devices.
",['Na Liu']
http://arxiv.org/abs/2111.05263v1,Nanotechnology,2021-11-08T16:29:45Z,2021-11-08T16:29:45Z,Nanotechnology and Processes The NanoPhotovoltaic Panels,"  Nanotechnology may work as a powerful weapon to be used for creating
competitive advantages in the energy market. Using the photovoltaic
nano-panels, which may reduce considerably the production costs and meet
simultaneously socio-environmental requirements demanded by law. It is a way to
produce clean energy in innovative terms. Moreover, today the adoption of
nanotechnology in energy production can make this kind of energy very
interesting along the years. Nanotechnology may be responsible for considerable
gains, both economically and the ones resulting from its contribution to
protect the planet against pollution.
","['Manuel Alberto M. Ferreira', 'José António Filipe', 'José Chavaglia Neto']"
http://arxiv.org/abs/2306.05174v1,Nanotechnology,2023-06-08T13:11:55Z,2023-06-08T13:11:55Z,Quantum-dot single-photon sources for the quantum internet,"  High-performance quantum light sources based on semiconductor quantum dots
coupled to microcavities are showing their promise in long-distance solid-state
quantum networks.
","['Chao-Yang Lu', 'Jian-Wei Pan']"
http://arxiv.org/abs/1303.5290v2,Nanotechnology,2013-03-20T14:38:09Z,2013-04-06T15:09:24Z,"Nanotechnology and Innovation, Recent status and the strategic
  implication for the formation of high tech clusters in Greece, in between a
  global economic crisis","  Nanotechnology is the first major worldwide research initiative of the 21st
century and probably is the solution vector in the economic environment. Also,
innovation is widely recognized as a key factor in the economic development of
nations, and is essential for the competitiveness of the industrial firms as
well. Policy and management of innovation are necessary in order to develop
innovation and it involves processes. It is essential to develop new methods
for nanotechnology development for better understanding of nanotechnology based
innovation. Nanotechnologies reveal commercialization processes, from start ups
to large firms in collaboration with public sector research. In the current
paper, a study in the present status of innovation in nanotechnology and the
affection of global economic crisis in this section is made and also the
potential of increase the innovation via the presence of clusters in a small
country like Greece which is in the eye of tornado from the global crisis is
studied.
","['Evangelos I. Gkanas', 'Vasso MagkouKriticou', 'Sofoklis S. Makridis', 'Athanasios K. Stubos', 'Ioannis Bakouros']"
http://arxiv.org/abs/1001.3319v1,Nanotechnology,2010-01-19T14:49:44Z,2010-01-19T14:49:44Z,Biomimetic Nanotechnology: A Powerful Means to address Global Challenges,"  Biomimetic nanotechnology is a prominent research area at the meeting place
of life sciences with engineering and physics: it is a continuously growing
field that deals with knowledge transfer from biology to nanotechnology.
Biomimetic nanotechnology is a field that has the potential to substantially
support successful mastering of major global challenges. The Millennium Project
was commissioned by the United Nations Secretary-General in 2002 to develop a
concrete action plan for the world to reverse the grinding poverty, hunger and
disease affecting billions of people. It states 15 Global Challenges:
sustainable development, water, population and resources, democratization,
long-term perspectives, information technology, the rich-poor gap, health,
capacity to decide, peace and conflict, status of women, transnational crime,
energy, science and technology and global ethics. The possible contributions to
master these challenges with the help of biomimetic nanotechnology will be
discussed in detail.
","['Ille C. Gebeshuber', 'Burhanuddin Y. Majlis']"
http://arxiv.org/abs/2201.07183v1,Nanotechnology,2022-01-10T07:15:35Z,2022-01-10T07:15:35Z,"Unveiling philosophy and social aspects of nanotechnology: A short
  review","  Philosophy has nurtured fundamental science by asking the right questions.
This scientific growth has fuelled research in various domains and introduced
diverse disciplines. Nanotechnology is an interdisciplinary domain with
numerous applications ranging from medical diagnostics and food technology to
electronics and psychology. Exploring nanotechnology's philosophical and social
perspective can better understand these domains and may open new doors for
research. This review addresses philosophical and other aspects of
nanotechnology, such as history, definitions, vision, language, laws, politics,
and ethics. This is an attempt to equip anyone in the field of nanotechnology
with philosophical and social insights. We expect this review to provide an
introductory understanding of philosophy and other aspects to the
nanotechnologists, which are usually excluded from their degree curriculum.
",['Muhammad Sajeer P']
http://arxiv.org/abs/2202.01063v1,Nanotechnology,2022-01-22T12:10:10Z,2022-01-22T12:10:10Z,Ethical Considerations on Nanotechnology,"  Since a significant time ago, although time runs very fast,nanotechnology
transformed from one of the most promising scientific hopes in uncountable
human domains into a marvelous certainty. Innumerable scientific studies in
several areas of knowledge were made since nanoscale emergence, carrying their
contribution to the nanoscience development, leading to a great development of
technical and scientific knowledge but also raising numerous problems in the
ethical field. In this work, nanotechnology is discussed both in terms of
ethics and in terms of borders that nanotechnology applications must satisfy
and concluding notes are presented, highlighting the results of the analysis.
Significant considerations are made on the close connection between ethics and
the nanotechnology and the effects over the society and values.
","['Manuel Alberto M. Ferreira', 'José António Filipe']"
http://arxiv.org/abs/2210.16811v1,Nanotechnology,2022-10-30T11:10:35Z,2022-10-30T11:10:35Z,Biomimicry in Nanotechnology: A Comprehensive Review,"  Biomimicry has been utilized in many branches of science and engineering to
develop devices for enhanced and better performance. The application of
nanotechnology has made life easier in modern times. It has offered a way to
manipulate matter and systems at the atomic level. As a result, the
miniaturization of numerous devices has been possible. Of late, the integration
of biomimicry with nanotechnology has shown promising results in the fields of
medicine, robotics, sensors, photonics, etc. Biomimicry in nanotechnology has
provided eco-friendly and green solutions to the energy problem and in
textiles. This is a new research area that needs to be explored more
thoroughly. This review illustrates the progress and innovations made in the
field of nanotechnology with the integration of biomimicry.
","['Mehedi Hasan Himel', 'Bejoy Sikder', 'Tanvir Ahmed', 'Sajid Muhaimin Choudhury']"
http://arxiv.org/abs/1411.1927v1,Nanotechnology,2014-11-07T14:22:01Z,2014-11-07T14:22:01Z,DNA nanotechnology: understanding and optimisation through simulation,"  DNA nanotechnology promises to provide controllable self-assembly on the
nanoscale, allowing for the design of static structures, dynamic machines and
computational architectures. In this article I review the state-of-the art of
DNA nanotechnology, highlighting the need for a more detailed understanding of
the key processes, both in terms of theoretical modelling and experimental
characterisation. I then consider coarse-grained models of DNA, mesoscale
descriptions that have the potential to provide great insight into the
operation of DNA nanotechnology if they are well designed. In particular, I
discuss a number of nanotechnological systems that have been studied with
oxDNA, a recently developed coarse-grained model, highlighting the subtle
interplay of kinetic, thermodynamic and mechanical factors that can determine
behaviour. Finally, new results highlighting the importance of mechanical
tension in the operation of a two-footed walker are presented, demonstrating
that recovery from an unintended `overstepped' configuration can be accelerated
by three to four orders of magnitude by application of a moderate tension to
the walker's track. More generally, the walker illustrates the possibility of
biasing strand-displacement processes to affect the overall rate.
",['Thomas E. Ouldridge']
http://arxiv.org/abs/2106.02110v1,Nanotechnology,2021-06-03T20:07:08Z,2021-06-03T20:07:08Z,"Influence of cognitive, geographical, and collaborative proximity on
  knowledge production of Canadian nanotechnology","  Incorporating existing knowledge is vital for innovating, discovering, and
generating new ideas. Knowledge production through research and invention is
the key to scientific and technological development. As an emerging technology,
nanotechnology has already proved its great potential for the global economy,
attracting considerable federal investments. Canada is reported as one of the
major players in producing nanotechnology research. In this paper, we focused
on the main drivers of knowledge production and diffusion by analyzing Canadian
nanotechnology researchers. We hypothesized that knowledge production in
Canadian nanotechnology is influenced by three key proximity factors, namely
cognitive, geographical, and collaborative. Using statistical analysis, social
network analysis, and machine learning techniques we comprehensively assessed
the influence of the proximity factors on academic knowledge production. Our
results not only prove a significant impact of the three key proximity factors
but also their predictive potential.
","['Elva Luz Crespo Neira', 'Ashkan Ebadi', 'Catherine Beaudry', 'Andrea Schiffauerova']"
http://arxiv.org/abs/2502.08036v2,Nanotechnology,2025-02-12T00:35:08Z,2025-02-14T00:06:11Z,"Innovations in Nanotechnology: A Comprehensive Review of Applications
  Beyond Space Exploration","  Nanotechnology has emerged as a transformative force across multiple
industries, enhancing materials, improving instrumentation precision, and
developing intelligent systems. This review explores various nanotechnology
applications, including advancements in materials science, healthcare, energy
storage, environmental monitoring, and robotics. Nanomaterials, such as carbon
nanotubes and graphene, offer significant improvements in fields like energy
generation and medicine, while nanosensors revolutionize environmental and
industrial monitoring. Micro and nano robots provide automation solutions
across industries. By expanding beyond space exploration, this review
highlights the far-reaching potential of nanotechnology to reshape industries
through interdisciplinary collaboration and innovation.
","['Syed Muhammad Muslim Hussain', 'Batool Zehra Ladha', 'Muhammad Hasan Khan']"
http://arxiv.org/abs/physics/0505007v2,Nanotechnology,2005-05-01T09:15:54Z,2005-05-06T17:11:36Z,Taking nanotechnology to schools,"  After a primer on nanotechnology and a review of current educational
practices in secondary schools, the concept of just-in-time education is
proposed to integrate technosciences and humanities so that both future
technoscientists and non-technoscientists develop a common understanding,
possibly even a common language, to deal with social, ethical, legal, and
political issues that arise from the development of nanotechnology and its
convergence with other technoscientific developments.
",['Akhlesh Lakhtakia']
http://arxiv.org/abs/2110.00828v1,Sustainable energy,2021-10-02T15:51:51Z,2021-10-02T15:51:51Z,"Artificial intelligence for Sustainable Energy: A Contextual Topic
  Modeling and Content Analysis","  Parallel to the rising debates over sustainable energy and artificial
intelligence solutions, the world is currently discussing the ethics of
artificial intelligence and its possible negative effects on society and the
environment. In these arguments, sustainable AI is proposed, which aims at
advancing the pathway toward sustainability, such as sustainable energy. In
this paper, we offered a novel contextual topic modeling combining LDA, BERT,
and Clustering. We then combined these computational analyses with content
analysis of related scientific publications to identify the main scholarly
topics, sub-themes, and cross-topic themes within scientific research on
sustainable AI in energy. Our research identified eight dominant topics
including sustainable buildings, AI-based DSSs for urban water management,
climate artificial intelligence, Agriculture 4, the convergence of AI with IoT,
AI-based evaluation of renewable technologies, smart campus and engineering
education, and AI-based optimization. We then recommended 14 potential future
research strands based on the observed theoretical gaps. Theoretically, this
analysis contributes to the existing literature on sustainable AI and
sustainable energy, and practically, it intends to act as a general guide for
energy engineers and scientists, AI scientists, and social scientists to widen
their knowledge of sustainability in AI and energy convergence research.
","['Tahereh Saheb', 'Mohammad Dehghani']"
http://arxiv.org/abs/1505.03736v1,Sustainable energy,2015-05-14T14:29:27Z,2015-05-14T14:29:27Z,"Sustainability in Software Product Lines: Report on Discussion Panel at
  SPLC 2014","  Sustainability (defined as 'the capacity to keep up') encompasses a wide set
of aims: ranging from energy efficient software products (environmental
sustainability), reduction of software development and maintenance costs
(economic sustainability), to employee and end-user wellbeing (social
sustainability). In this report we explore the role that sustainability plays
in software product line engineering (SPL). The report is based on the
'Sustainability in Software Product Lines' panel held at SPLC 2014.
","['Ruzanna Chitchyan', 'Joost Noppen', 'Iris Groher']"
http://arxiv.org/abs/2501.17004v1,Sustainable energy,2025-01-28T15:00:45Z,2025-01-28T15:00:45Z,Using Sustainability Impact Scores for Software Architecture Evaluation,"  For future regulatory compliance, organizations must assess and report on the
state of sustainability in terms of its impacts over time. Sustainability,
being a multidimensional concern, is complex to quantify. This complexity
further increases with the interdependencies of the quality concerns across
different sustainability dimensions. The research literature lacks a holistic
way to evaluate sustainability at the software architecture level. With this
study, our aim is to identify quality attribute (QA) trade-offs at the software
architecture level and quantify the related sustainability impact. To this aim
we present an improved version of the Sustainability Impact Score (SIS),
building on our previous work. The SIS facilitates the identification and
quantification of trade-offs in terms of their sustainability impact,
leveraging a risk- and importance-based prioritization mechanism. To evaluate
our approach, we apply it to an industrial case study involving a multi-model
framework for integrated decision-making in the energy sector. Our study
reveals that technical quality concerns have significant, often unrecognized
impacts across sustainability dimensions. The SIS coupled with QA trade-offs
can help practitioners make informed decisions that align with their
sustainability goals. Early evaluations can help organizations mitigate
sustainability risks by taking preventive actions.
","['Iffat Fatima', 'Patricia Lago', 'Vasilios Andrikopoulos', 'Bram van der Waaij']"
http://arxiv.org/abs/2306.02444v2,Sustainable energy,2023-06-04T19:22:20Z,2023-10-27T23:17:48Z,"Energy-Sustainable IoT Connectivity: Vision, Technological Enablers,
  Challenges, and Future Directions","  Technology solutions must effectively balance economic growth, social equity,
and environmental integrity to achieve a sustainable society. Notably, although
the Internet of Things (IoT) paradigm constitutes a key sustainability enabler,
critical issues such as the increasing maintenance operations, energy
consumption, and manufacturing/disposal of IoT devices have long-term negative
economic, societal, and environmental impacts and must be efficiently
addressed. This calls for self-sustainable IoT ecosystems requiring minimal
external resources and intervention, effectively utilizing renewable energy
sources, and recycling materials whenever possible, thus encompassing energy
sustainability. In this work, we focus on energy-sustainable IoT during the
operation phase, although our discussions sometimes extend to other
sustainability aspects and IoT lifecycle phases. Specifically, we provide a
fresh look at energy-sustainable IoT and identify energy provision, transfer,
and energy efficiency as the three main energy-related processes whose
harmonious coexistence pushes toward realizing self-sustainable IoT systems.
Their main related technologies, recent advances, challenges, and research
directions are also discussed. Moreover, we overview relevant performance
metrics to assess the energy-sustainability potential of a certain technique,
technology, device, or network and list some target values for the next
generation of wireless systems. Overall, this paper offers insights that are
valuable for advancing sustainability goals for present and future generations.
","['Onel A. López', 'Osmel M. Rosabal', 'David Ruiz-Guirola', 'Prasoon Raghuwanshi', 'Konstantin Mikhaylov', 'Lauri Lovén', 'Sridhar Iyer']"
http://arxiv.org/abs/2301.01278v1,Sustainable energy,2022-12-26T09:14:01Z,2022-12-26T09:14:01Z,"Students Perceptions of Sustainable Universities in Hungary. An
  Importance-Performance Analysis","  In order to succeed, universities are forced to respond to the new challenges
in the rapidly changing world. The recently emerging fourth-generation
universities should meet sustainability objectives to better serve their
students and their communities. It is essential for universities to measure
their sustainability performance to capitalise on their core strengths and to
overcome their weaknesses. In line with the stakeholder theory, the objective
of this study was to investigate students perceptions of university
sustainability including their expectations about and satisfaction with the
efforts that universities make towards sustainability. This paper proposes a
new approach that combines the sustainable university scale, developed by the
authors, with the importance-performance analysis to identify key areas of
university sustainability. To collect data, an online survey was conducted in
Hungary in 2019. The sustainable university scale was found to be a reliable
construct to measure different aspects of university sustainability. Results of
the importance-performance analysis suggest that students consider Hungarian
universities unsustainable. Research findings indicate that Hungarian
universities perform poorly in sustainable purchasing and renewable energy use,
but their location and their efforts towards separate waste collection are
their major competitive advantages. The main domains of university
sustainability were also discussed. This study provides university
decision-makers and researchers with insightful results supporting the
transformation of traditional universities into sustainable, fourth-generation
higher education institutions.
","['Szabolcs Nagy', 'Mariann Veresne Somosi']"
http://arxiv.org/abs/2403.12698v1,Sustainable energy,2024-03-19T12:56:02Z,2024-03-19T12:56:02Z,System Support for Environmentally Sustainable Computing in Data Centers,"  Modern data centers suffer from a growing carbon footprint due to
insufficient support for environmental sustainability. While hardware
accelerators and renewable energy have been utilized to enhance sustainability,
addressing Quality of Service (QoS) degradation caused by renewable energy
supply and hardware recycling remains challenging: (1) prior accelerators
exhibit significant carbon footprints due to limited reconfigurability and
inability to adapt to renewable energy fluctuations; (2) integrating recycled
NAND flash chips in data centers poses challenges due to their short lifetime,
increasing energy consumption; (3) the absence of a sustainability estimator
impedes data centers and users in evaluating and improving their environmental
impact. This study aims to improve system support for environmentally
sustainable data centers by proposing a reconfigurable hardware accelerator for
intensive computing primitives and developing a fractional NAND flash cell to
extend the lifetime of recycled flash chips while supporting graceful capacity
degradation. We also introduce a sustainability estimator to evaluate user task
energy consumption and promote sustainable practices. We present our
preliminary results and recognize this as an ongoing initiative with
significant potential to advance environmentally sustainable computing in data
centers and stimulate further exploration in this critical research domain.
",['Fan Chen']
http://arxiv.org/abs/2404.03995v1,Sustainable energy,2024-04-05T10:11:08Z,2024-04-05T10:11:08Z,"Balancing Progress and Responsibility: A Synthesis of Sustainability
  Trade-Offs of AI-Based Systems","  Recent advances in artificial intelligence (AI) capabilities have increased
the eagerness of companies to integrate AI into software systems. While AI can
be used to have a positive impact on several dimensions of sustainability, this
is often overshadowed by its potential negative influence. While many studies
have explored sustainability factors in isolation, there is insufficient
holistic coverage of potential sustainability benefits or costs that
practitioners need to consider during decision-making for AI adoption. We
therefore aim to synthesize trade-offs related to sustainability in the context
of integrating AI into software systems. We want to make the sustainability
benefits and costs of integrating AI more transparent and accessible for
practitioners.
  The study was conducted in collaboration with a Dutch financial organization.
We first performed a rapid review that led to the inclusion of 151 research
papers. Afterward, we conducted six semi-structured interviews to enrich the
data with industry perspectives. The combined results showcase the potential
sustainability benefits and costs of integrating AI. The labels synthesized
from the review regarding potential sustainability benefits were clustered into
16 themes, with ""energy management"" being the most frequently mentioned one. 11
themes were identified in the interviews, with the top mentioned theme being
""employee wellbeing"". Regarding sustainability costs, the review discovered
seven themes, with ""deployment issues"" being the most popular one, followed by
""ethics & society"". ""Environmental issues"" was the top theme from the
interviews. Our results provide valuable insights to organizations and
practitioners for understanding the potential sustainability implications of
adopting AI.
","['Apoorva Nalini Pradeep Kumar', 'Justus Bogner', 'Markus Funke', 'Patricia Lago']"
http://arxiv.org/abs/2412.12235v1,Sustainable energy,2024-12-16T17:34:23Z,2024-12-16T17:34:23Z,"A Techno-Economic Analysis of the Interconnectedness between Energy
  Resources, Climate Change, and Sustainable Development","  Abstract: The rising global temperatures caused by climate change
significantly impact energy consumption and electricity generation. Fluctuating
temperatures and frequent extreme weather events disrupt energy production and
consumption patterns. Addressing these challenges has become a priority,
prompting governments, industries, and societies to pursue sustainable
development and embrace eco-friendly economies. This strategy aims to decouple
economic growth from environmental harm, ensuring a sustainable future for
generations. Understanding the link between climate change, energy resources,
and sustainable development is crucial. Techno-economic analysis provides a
framework for evaluating energy-related projects and policies, guiding
decision-makers toward sustainable solutions. A case study highlights the
interaction between hydroponic unit energy needs, electricity pricing from wind
farms, and product sales prices. Findings suggest that smaller 2-megawatt
investments are more efficient and adaptable than larger 18-megawatt projects,
proving economically viable and technologically flexible. However, such
investments must also consider their social and environmental impacts on local
communities. Sustainable development seeks to ensure that progress benefits all
stakeholders while protecting the environment. Achieving this requires
collaboration among governments, businesses, researchers, and individuals. By
fostering innovation, adopting eco-friendly practices, and creating supportive
policies, society can transition to a green economy, mitigating climate change
and promoting a sustainable, resilient future.
","['MohammadReza Askari', 'Navid Parsa']"
http://arxiv.org/abs/2005.13203v1,Sustainable energy,2020-05-27T07:01:07Z,2020-05-27T07:01:07Z,"Empowering the Earth system by technology: Using thermodynamics of the
  Earth system to illustrate a possible sustainable future of the planet","  With the use of the appropriate technology, such as photovoltaics and
seawater desalination, humans have the ability to sustainably increase their
production of food and energy while minimising detrimental impacts on the Earth
system.
",['Axel Kleidon']
http://arxiv.org/abs/1606.00889v1,Sustainable energy,2016-05-28T03:50:17Z,2016-05-28T03:50:17Z,Exploring the roles of ICT in supporting sustainability practices,"  The concern about sustainability has arisen due to the overuse of natural
resources and the increased use of energy consumption over the last decades.
Information communication technologies (ICT) has the potential to address the
three main aspects of sustainability (people, planet, profit) and therefore,
several organizations have initiated a sustainable development by integrating
ICT within their business activities. However, the roles of ICT in supporting
sustainability initiatives have only been discussed in a limited number of
studies and there is a lack of practical examples that demonstrate how the
different roles of ICT are played out in an organization's environment.
Therefore, this research aims to explore how ICT can be used by organizations
to support sustainability initiatives. In particular, in this
research-in-progress paper, we examine how a leading organization deploys
Internet-of-Things as an example of an ICT application to support various
sustainability initiatives. The study findings enhance the current
understanding of how ICT can support sustainability practices of organizations.
","['Abdon Carrera Rivera', 'Sherah Kurnia']"
http://arxiv.org/abs/2306.13686v2,Sustainable energy,2023-06-22T18:00:55Z,2023-11-22T19:58:22Z,"Broadening the perspective for sustainable AI: Comprehensive
  sustainability criteria and indicators for AI systems","  The increased use of AI systems is associated with multi-faceted societal,
environmental, and economic consequences. These include non-transparent
decision-making processes, discrimination, increasing inequalities, rising
energy consumption and greenhouse gas emissions in AI model development and
application, and an increasing concentration of economic power. By considering
the multi-dimensionality of sustainability, this paper takes steps towards
substantiating the call for an overarching perspective on ""sustainable AI"". It
presents the SCAIS Framework (Sustainability Criteria and Indicators for
Artificial Intelligence Systems) which contains a set 19 sustainability
criteria for sustainable AI and 67 indicators that is based on the results of a
critical review and expert workshops. This interdisciplinary approach
contributes a unique holistic perspective to facilitate and structure the
discourse on sustainable AI. Further, it provides a concrete framework that
lays the foundation for developing standards and tools to support the conscious
development and application of AI systems.
","['Friederike Rohde', 'Josephin Wagner', 'Andreas Meyer', 'Philipp Reinhard', 'Marcus Voss', 'Ulrich Petschow', 'Anne Mollen']"
http://arxiv.org/abs/2503.08353v1,Sustainable energy,2025-03-11T12:08:55Z,2025-03-11T12:08:55Z,"Towards Sustainability in 6G and beyond: Challenges and Opportunities of
  Open RAN","  The transition to 6G is expected to bring significant advancements, including
much higher data rates, enhanced reliability and ultra-low latency compared to
previous generations. Although 6G is anticipated to be 100 times more energy
efficient, this increased efficiency does not necessarily mean reduced energy
consumption or enhanced sustainability. Network sustainability encompasses a
broader scope, integrating business viability, environmental sustainability,
and social responsibility. This paper explores the sustainability requirements
for 6G and proposes Open RAN as a key architectural solution. By enabling
network diversification, fostering open and continuous innovation, and
integrating AI/ML, Open RAN can promote sustainability in 6G. The paper
identifies high energy consumption and e-waste generation as critical
sustainability challenges and discusses how Open RAN can address these issues
through softwarisation, edge computing, and AI integration.
","['Hamed Ahmadi', 'Mostafa Rahmani', 'Swarna Bindu Chetty', 'Eirini Eleni Tsiropoulou', 'Huseyin Arslan', 'Merouane Debbah', 'Tony Quek']"
http://arxiv.org/abs/1907.10052v1,Sustainable energy,2019-07-23T07:34:18Z,2019-07-23T07:34:18Z,Sustainable Business Models: A Review,"  The concept of the sustainable business model describes the rationale of how
an organization creates, delivers, and captures value, in economic, social,
cultural, or other contexts, in a sustainable way. The process of sustainable
business model construction forms an innovative part of a business strategy.
Different industries and businesses have utilized sustainable business models
concept to satisfy their economic, environmental, and social goals
simultaneously. However, the success, popularity, and progress of sustainable
business models in different application domains are not clear. To explore this
issue, this research provides a comprehensive review of sustainable business
models literature in various application areas. Notable sustainable business
models are identified and further classified in fourteen unique categories, and
in every category, the progress -- either failure or success -- has been
reviewed, and the research gaps are discussed. Taxonomy of the applications
includes innovation, management and marketing, entrepreneurship, energy,
fashion, healthcare, agri-food, supply chain management, circular economy,
developing countries, engineering, construction and real estate, mobility and
transportation, and hospitality. The key contribution of this study is that it
provides an insight into the state of the art of sustainable business models in
the various application areas and future research directions. This paper
concludes that popularity and the success rate of sustainable business models
in all application domains have been increased along with the increasing use of
advanced technologies.
","['Saeed Nosratabadi', 'Amir Mosavi', 'Shahaboddin Shamshirband', 'Edmundas Kazimieras Zavadskas', 'Andry Rakotonirainy', 'Kwok Wing Chau']"
http://arxiv.org/abs/2502.20021v1,Sustainable energy,2025-02-27T12:00:27Z,2025-02-27T12:00:27Z,"Systems-of-Systems for Environmental Sustainability: A Systematic
  Mapping Study","  Environmental sustainability in Systems-of-Systems (SoS) is an emerging field
that seeks to integrate technological solutions to promote the efficient
management of natural resources. While systematic reviews address
sustainability in the context of Smart Cities (a category of SoS), a systematic
study synthesizing the existing knowledge on environmental sustainability
applied to SoS in general does not exist. Although literature includes other
types of sustainability, such as financial and social, this study focuses on
environmental sustainability, analyzing how SoS contribute to sustainable
practices such as carbon emission reduction, energy efficiency, and
biodiversity conservation. We conducted a Systematic Mapping Study to identify
the application domains of SoS in sustainability, the challenges faced, and
research opportunities. We planned and executed a research protocol including
an automated search over four scientific databases. Of 926 studies retrieved,
we selected, analyzed, and reported the results of 39 relevant studies. Our
findings reveal that most studies focus on Smart Cities and Smart Grids, while
applications such as sustainable agriculture and wildfire prevention are less
explored. We identified challenges such as system interoperability,
scalability, and data governance. Finally, we propose future research
directions for SoS and environmental sustainability.
","['Ana Clara Araújo Gomes da Silva', 'Gilmar Teixeira Junior', 'Lívia Mancine C. de Campos', 'Renato F. Bulcão-Neto', 'Valdemar Vicente Graciano Neto']"
http://arxiv.org/abs/1712.02899v2,Sustainable energy,2017-12-08T00:50:30Z,2018-07-09T05:02:58Z,"A Taxonomy and Future Directions for Sustainable Cloud Computing: 360
  Degree View","  The cloud computing paradigm offers on-demand services over the Internet and
supports a wide variety of applications. With the recent growth of Internet of
Things (IoT) based applications the usage of cloud services is increasing
exponentially. The next generation of cloud computing must be energy-efficient
and sustainable to fulfil the end-user requirements which are changing
dynamically. Presently, cloud providers are facing challenges to ensure the
energy efficiency and sustainability of their services. The usage of large
number of cloud datacenters increases cost as well as carbon footprints, which
further effects the sustainability of cloud services. In this paper, we propose
a comprehensive taxonomy of sustainable cloud computing. The taxonomy is used
to investigate the existing techniques for sustainability that need careful
attention and investigation as proposed by several academic and industry
groups. Further, the current research on sustainable cloud computing is
organized into several categories: application design, sustainability metrics,
capacity planning, energy management, virtualization, thermal-aware scheduling,
cooling management, renewable energy and waste heat utilization. The existing
techniques have been compared and categorized based on the common
characteristics and properties. A conceptual model for sustainable cloud
computing has been proposed along with discussion on future research
directions.
","['Sukhpal Singh Gill', 'Rajkumar Buyya']"
http://arxiv.org/abs/2405.13530v1,Sustainable energy,2024-05-22T11:00:31Z,2024-05-22T11:00:31Z,Through energy droughts: hydropower's ability to sustain a high output,"  Previous research has raised concerns about energy droughts in
renewables-based energy systems. This study explores the ability of reservoir
hydropower to sustain a high output and, thereby, mitigate such energy
droughts. Using detailed modelling, we estimate that Swedish hydropower can
sustain 67-92% of its installed capacity for 3 weeks, with higher values
possible in springtime. The variation of the sustained output, equivalent to
the capacity of 3-4 Swedish nuclear reactors, under-scores the importance of
understanding the potential output levels when devising strategies to
counteract energy droughts. Moreover, we find that regulations imposed on the
flows in river bottlenecks hinder higher sustained output levels. With the
upcoming renewal of environmental permits for hydropower plants in Sweden,
these findings provide valuable insights for policymakers. Furthermore, the
sustained output capabilities demonstrated in this study challenge the
prevalent simplified representations of hydropower in energy models, suggesting
a need for more-sophisticated modelling approaches.
","['Hanna Ek Fälth', 'Fredrik Hedenus', 'Lina Reichenberg', 'Niclas Mattsson']"
http://arxiv.org/abs/2407.06978v1,Sustainable energy,2024-07-09T15:53:46Z,2024-07-09T15:53:46Z,"Exploring the Experiences of Experts: Sustainability in Agile Software
  Development -- Insights from the Finnish Software Industry","  Agile software development is gaining popularity among software developers
due to its benefits. As the interest in agile software development grows, there
is an increasing focus on investigating sustainability within this field. This
study aimed to explore sustainability within agile software development in the
Finnish software industry and, through gathered experiences, contribute to the
software engineering roadmap 2030. Using an interview approach, we conducted an
empirical study within the Finnish software industry to achieve this goal. The
findings indicate a growing interest among experts in integrating
sustainability into agile software development. The results show that the Scrum
methodology is the most popular approach in the Finnish software industry, and
addressing different sustainability dimensions can have a ripple effect on each
other. The study proposes three key elements to be considered in the software
engineering roadmap 2030: integrating sustainability into software engineering
education, creating sustainability tools and frameworks, and assessing the
energy efficiency of libraries used in software development.
","['Hatef Shamshiri', 'Ashok Tripathi', 'Shola Oyedeji', 'Jari Porras']"
http://arxiv.org/abs/2501.14995v1,Sustainable energy,2025-01-25T00:04:59Z,2025-01-25T00:04:59Z,"GreenAuto: An Automated Platform for Sustainable AI Model Design on Edge
  Devices","  We present GreenAuto, an end-to-end automated platform designed for
sustainable AI model exploration, generation, deployment, and evaluation.
GreenAuto employs a Pareto front-based search method within an expanded neural
architecture search (NAS) space, guided by gradient descent to optimize model
exploration. Pre-trained kernel-level energy predictors estimate energy
consumption across all models, providing a global view that directs the search
toward more sustainable solutions. By automating performance measurements and
iteratively refining the search process, GreenAuto demonstrates the efficient
identification of sustainable AI models without the need for human
intervention.
","['Xiaolong Tu', 'Dawei Chen', 'Kyungtae Han', 'Onur Altintas', 'Haoxin Wang']"
http://arxiv.org/abs/1703.01078v1,Sustainable energy,2017-03-03T08:39:48Z,2017-03-03T08:39:48Z,"On the Presence of Green and Sustainable Software Engineering in Higher
  Education Curricula","  Nowadays, software is pervasive in our everyday lives. Its sustainability and
environmental impact have become major factors to be considered in the
development of software systems. Millennials-the newer generation of university
students-are particularly keen to learn about and contribute to a more
sustainable and green society. The need for training on green and sustainable
topics in software engineering has been reflected in a number of recent
studies. The goal of this paper is to get a first understanding of what is the
current state of teaching sustainability in the software engineering community,
what are the motivations behind the current state of teaching, and what can be
done to improve it. To this end, we report the findings from a targeted survey
of 33 academics on the presence of green and sustainable software engineering
in higher education. The major findings from the collected data suggest that
sustainability is under-represented in the curricula, while the current focus
of teaching is on energy efficiency delivered through a fact-based approach.
The reasons vary from lack of awareness, teaching material and suitable
technologies, to the high effort required to teach sustainability. Finally, we
provide recommendations for educators willing to teach sustainability in
software engineering that can help to suit millennial students needs.
","['Damiano Torre', 'Giuseppe Procaccianti', 'Davide Fucci', 'Sonja Lutovac', 'Giuseppe Scanniello']"
http://arxiv.org/abs/1804.04832v1,Sustainable energy,2018-04-13T08:28:40Z,2018-04-13T08:28:40Z,"Sustainability of environment-assisted energy transfer in quantum
  photobiological complexes","  It is shown that quantum sustainability is a universal phenomenon which
emerges during environment-assisted electronic excitation energy transfer (EET)
in photobiological complexes (PBCs), such as photosynthetic reaction centers
and centers of melanogenesis. We demonstrate that quantum photobiological
systems must be sustainable for them to simultaneously endure continuous energy
transfer and keep their internal structure from destruction or critical
instability. These quantum effects occur due to the interaction of PBCs with
their environment which can be described by means of the reduced density
operator and effective non-Hermitian Hamiltonian (NH). Sustainable NH models of
EET predict the coherence beats, followed by the decrease of coherence down to
a small, yet non-zero value. This indicates that in sustainable PBCs, quantum
effects survive on a much larger time scale than the energy relaxation of an
exciton. We show that sustainable evolution significantly lowers the entropy of
PBCs and improves the speed and capacity of EET.
",['Konstantin G. Zloshchastiev']
http://arxiv.org/abs/1612.00800v1,Wearable technology,2016-12-02T19:28:58Z,2016-12-02T19:28:58Z,"HealthAdvisor: Recommendation System for Wearable Technologies enabling
  Proactive Health Monitoring","  Proactive monitoring of one's health could avoid serious diseases as well as
better maintain the individual's well-being. In today's IoT world, there has
been numerous wearable technological devices to monitor/measure different
health attributes. However, with that increasing number of attributes and
wearables, it becomes unclear to the individual which ones they should be
using. The aim of this paper is to provide a recommendation engine for
personalized recommended wearables for any given individual. The way the engine
works is through first identifying the diseases that this person is at risk of,
given his/her attributes and medical history. We built a machine learning
classification model for this task. Second, these diseases are mapped to the
attributes that need to be measured in order to monitor such diseases. Third,
we map these measurements to the appropriate wearable technologies. This is
done via a textual analytics model that we developed that uses available
information of different wearables to map the aforementioned measurements to
these wearables. The output can be used to recommend the wearables to
individuals as well as provide a feedback to wearable developers for common
measurements that do not have corresponding wearables today.
","['Shubhi Asthana', 'Ray Strong', 'Aly Megahed']"
http://arxiv.org/abs/2403.17863v1,Wearable technology,2024-03-26T16:50:44Z,2024-03-26T16:50:44Z,An AI-Native Runtime for Multi-Wearable Environments,"  The miniaturization of AI accelerators is paving the way for next-generation
wearable applications within wearable technologies. We introduce Mojito, an
AI-native runtime with advanced MLOps designed to facilitate the development
and deployment of these applications on wearable devices. It emphasizes the
necessity of dynamic orchestration of distributed resources equipped with
ultra-low-power AI accelerators to overcome challenges associated with
unpredictable runtime environments. Through its innovative approaches, Mojito
demonstrates how future wearable technologies can evolve to be more autonomous.
","['Chulhong Min', 'Utku Günay Acer', 'SiYoung Jang', 'Sangwon Choi', 'Diana A. Vasile', 'Taesik Gong', 'Juheon Yi', 'Fahim Kawsar']"
http://arxiv.org/abs/2406.18791v2,Wearable technology,2024-06-26T23:28:41Z,2024-07-12T22:50:20Z,Invited: Human-Inspired Distributed Wearable AI,"  The explosive surge in Human-AI interactions, fused with a soaring
fascination in wearable technology, has ignited a frenzy of innovation and the
emergence of a myriad of Wearable AI devices, each wielding diverse form
factors, tackling tasks from health surveillance to turbocharging productivity.
This paper delves into the vision for wearable AI technology, addressing the
technical bottlenecks that stand in the way of its promised advancements.
  Embracing a paradigm shift, we introduce a Human-Inspired Distributed Network
for Wearable AI, enabled by high-speed ultra-low-power secure connectivity via
the emerging 'Body as a Wire' (Wi-R) technology. This breakthrough acts as the
missing link: the artificial nervous system, seamlessly interconnecting all
wearables and implantables, ushering in a new era of interconnected
intelligence, where featherweight, perpetually operating wearable AI nodes
redefine the boundaries of possibility.
","['Shreyas Sen', 'Arunashish Datta']"
http://arxiv.org/abs/1504.00747v1,Wearable technology,2015-04-03T05:25:07Z,2015-04-03T05:25:07Z,Software for Wearable Devices: Challenges and Opportunities,"  Wearable devices are a new form of mobile computer system that provides
exclusive and user-personalized services. Wearable devices bring new issues and
challenges to computer science and technology. This paper summarizes the
development process and the categories of wearable devices. In addition, we
present new key issues arising in aspects of wearable devices, including
operating systems, database management system, network communication protocol,
application development platform, privacy and security, energy consumption,
human-computer interaction, software engineering, and big data.
","['He Jiang', 'Xin Chen', 'Shuwei Zhang', 'Xin Zhang', 'Weiqiang Kong', 'Tao Zhang']"
http://arxiv.org/abs/2104.05979v1,Wearable technology,2021-04-13T07:21:12Z,2021-04-13T07:21:12Z,"Investigating Opportunities to Support Kids' Agency and Well-being: A
  Review of Kids' Wearables","  Wearable devices hold great potential for promoting children's health and
well-being. However, research on kids' wearables is sparse and often focuses on
their use in the context of parental surveillance. To gain insight into the
current landscape of kids' wearables, we surveyed 47 wearable devices marketed
for children. We collected rich data on the functionality of these devices and
assessed how different features satisfy parents' information needs, and
identified opportunities for wearables to support children's needs and
interests. We found that many kids' wearables are technologically sophisticated
devices that focus on parents' ability to communicate with their children and
keep them safe, as well as encourage physical activity and nurture good habits.
We discuss how our findings could inform the design of wearables that serve as
more than monitoring devices, and instead support children and parents as equal
stakeholders, providing implications for kids' agency, long-term development,
and overall well-being. Finally, we identify future research efforts related to
designing for kids' self-tracking and collaborative tracking with parents.
","['Rachael Zehrung', 'Lily Huang', 'Bongshin Lee', 'Eun Kyoung Choe']"
http://arxiv.org/abs/1912.05282v1,Wearable technology,2019-12-11T13:16:00Z,2019-12-11T13:16:00Z,"Human Electromagnetic Field Exposure in Wearable Communications: A
  Review","  The concern on human health is often overseen while wearable technologies
attract exploding interests. Mainly due to the extreme proximity or a direct
physical contact to the human skin, wearable communications devices are
acknowledged to cause higher levels of specific absorption rate (SAR) at the
skin surface. Unfortunately, so far, we have found no study encompassing all
the aspects that the general public needs to understand about wearable
technologies--i.e., the analytical and experimental backgrounds, and report of
SAR levels generated from commercial wearable devices. In this context, this
paper provides an extensive review on SAR from various commercial wearable
devices that are currently sold in the market, as well as the analytical
framework and the current measurement methodologies for standard compliance
tests. Moreover, considering the present interest in millimeter wave (mmW),
this paper sheds light on the SAR evaluated at 60 GHz and also compares the SAR
to that measured at 2.4 GHz. We expect that this paper will be of value in
informing the general public of the safety in using the currently sold wearable
devices, and in igniting further study of the exact biological consequences
from electromagnetic field (EMF) exposure due to wearable devices.
","['Seungmo Kim', 'Yakub Sharif', 'Imtiaz Nasim']"
http://arxiv.org/abs/2003.01552v1,Wearable technology,2020-03-01T19:36:07Z,2020-03-01T19:36:07Z,"Human EMF Exposure in Wearable Networks for Internet of Battlefield
  Things","  Numerous antenna design approaches for wearable applications have been
investigated in the literature. As on-body wearable communications become more
ingrained in our daily activities, the necessity to investigate the impacts of
these networks burgeons as a major requirement. In this study, we investigate
the human electromagnetic field (EMF) exposure effect from on-body wearable
devices at 2.4 GHz and 60 GHz, and compare the results to illustrate how the
technology evolution to higher frequencies from wearable communications can
impact our health. Our results suggest the average specific absorption rate
(SAR) at 60 GHz can exceed the regulatory guidelines within a certain
separation distance between a wearable device and the human skin surface. To
the best of authors' knowledge, this is the first work that explicitly compares
the human EMF exposure at different operating frequencies for on-body wearable
communications, which provides a direct roadmap in design of wearable devices
to be deployed in the Internet of Battlefield Things (IoBT).
","['Imtiaz Nasim', 'Seungmo Kim']"
http://arxiv.org/abs/1504.05694v1,Wearable technology,2015-04-22T08:44:23Z,2015-04-22T08:44:23Z,Risk Perceptions for Wearable Devices,"  Wearable devices, or ""wearables,"" bring great benefits but also potential
risks that could expose users' activities with- out their awareness or consent.
In this paper, we report findings from the first large-scale survey conducted
to investigate user security and privacy concerns regarding wearables. We
surveyed 1,782 Internet users in order to identify risks that are particularly
concerning to them; these risks are inspired by the sensor inputs and
applications of popular wearable technologies. During this experiment, our
questions controlled for the effects of what data was being accessed and with
whom it was being shared. We also investigated how these emergent threats
compared to existent mobile threats, how upcoming capabilities and artifacts
compared to existing technologies, and how users ranked technical and
nontechnical concerns to sketch a concrete and broad view of the wearable
device landscape. We hope that this work will inform the design of future user
notification, permission management, and access control schemes for wearables.
","['Linda Lee', 'Serge Egelman', 'Joong Hwa Lee', 'David Wagner']"
http://arxiv.org/abs/2201.11878v1,Wearable technology,2022-01-28T01:20:59Z,2022-01-28T01:20:59Z,Research on Wearable Technologies for Learning: A Systematic Review,"  A good amount of research has explored the use of wearables for educational
or learning purposes. We have now reached a point when much literature can be
found on that topic, but few attempts have been made to make sense of that
literature from a holistic perspective. This paper presents a systematic review
of the literature on wearables for learning. Literature was sourced from
conferences and journals pertaining to technology and education, and through an
ad hoc search. Our review focuses on identifying the ways that wearables have
been used to support learning and provides perspectives on that issue from a
historical dimension, and with regards to the types of wearables used, the
populations targeted, and the settings addressed. Seven different ways of how
wearables have been used to support learning were identified. We propose a
framework identifying five main components that have been addressed in existing
research on how wearables can support learning and present our interpretations
of unaddressed research directions based on our review results.
","['Sharon Lynn Chu', 'Brittany M. Garcia', 'Neha Rani']"
http://arxiv.org/abs/2502.05797v2,Wearable technology,2025-02-09T07:13:42Z,2025-02-12T03:37:33Z,"Seamless Integration: The Evolution, Design, and Future Impact of
  Wearable Technology","  The rapid evolution of wearable technology marks a transformative phase in
human-computer interaction, seamlessly integrating digital functionality into
daily life. This paper explores the historical trajectory, current
advancements, and future potential of wearables, emphasizing their impact on
healthcare, productivity, and personal well-being. Key developments include the
integration of artificial intelligence (AI), Internet of Things (IoT), and
augmented reality (AR), driving personalization, real-time adaptability, and
enhanced user experiences. The study highlights user-centered design
principles, ethical considerations, and interdisciplinary collaboration as
critical factors in creating wearables that are intuitive, inclusive, and
secure. Furthermore, the paper examines sustainability trends, such as modular
designs and eco-friendly materials, aligning innovation with environmental
responsibility. By addressing challenges like data privacy, algorithmic bias,
and usability, wearable technology is poised to redefine the interaction
between humans and technology, offering unprecedented opportunities for
enrichment and empowerment in diverse contexts. This comprehensive analysis
provides a roadmap for advancing wearables to meet emerging societal needs
while fostering ethical and sustainable growth.
","['David Pearl', 'James Intriligator', 'Xuanjiang Liu']"
http://arxiv.org/abs/2503.15488v1,Wearable technology,2024-12-27T00:34:48Z,2024-12-27T00:34:48Z,Human-AI Collaboration for Wearable Technology Component Standardization,"  Due to the multidisciplinary nature of wearable technology, the industry
faces potential limitations in innovation. The wearable technology industry is
still in its infancy and increased applicable use faces stagnation in the
despite the plethora of technologies that have been largely wrist worn. This
could be a result of the lack of multidisciplinary expert knowledge
disseminating through the industry. Unlike other technologies which have
standardizations and processes for how they are developed, wearable
technologies exist in a realm of perpetual change as given the various
materials and subcomponents that continue to be developed. It is essential that
expert opinions form a collaborative foundation, and even more so that
intelligent systems foster that collaboration. The caveat though, is likeliness
of these artificial intelligence (AI) collaboration tools to be utilized by
industry experts. Mental model development for AI tool usage could be applied
to wearable technology innovation in this regard, thus the goal of this paper
and focus of research.
",['Andrew M. Lydner']
http://arxiv.org/abs/1512.02347v1,Wearable technology,2015-12-08T06:29:27Z,2015-12-08T06:29:27Z,"Medical Wearable Technologies: Applications, Problems and Solutions","  The focus of this paper is on wearable technologies which are increasingly
being employed in the medical field. From smart watches to smart glasses, from
electronic textile to data gloves; several gadgets are playing important roles
in diagnosis and treatment of various medical conditions. The threats posed by
these technologies are another matter of concern that must be seriously taken
into account. Numerous threats ranging from data privacy to big data problems
are facing us as adverse effects of these technologies. The paper analyses the
application areas and challenges of wearable technologies from a technical and
ethical point of view and presents solutions to possible threats.
",['Erkan Bostanci']
http://arxiv.org/abs/2401.13518v1,Wearable technology,2024-01-24T15:15:03Z,2024-01-24T15:15:03Z,"Addressing Data Quality Challenges in Observational Ambulatory Studies:
  Analysis, Methodologies and Practical Solutions for Wrist-worn Wearable
  Monitoring","  Chronic disease management and follow-up are vital for realizing sustained
patient well-being and optimal health outcomes. Recent advancements in wearable
sensing technologies, particularly wrist-worn devices, offer promising
solutions for longitudinal patient follow-up by shifting from subjective,
intermittent self-reporting to objective, continuous monitoring. However,
collecting and analyzing wearable data presents unique challenges, such as data
entry errors, non-wear periods, missing wearable data, and wearable artifacts.
We therefore present an in-depth exploration of data analysis challenges tied
to wrist-worn wearables and ambulatory label acquisition, using two real-world
datasets (i.e., mBrain21 and ETRI lifelog2020). We introduce novel practical
countermeasures, including participant compliance visualizations,
interaction-triggered questionnaires to assess personal bias, and an optimized
wearable non-wear detection pipeline. Further, we propose a visual analytics
approach to validate processing pipelines using scalable tools such as tsflex
and Plotly-Resampler. Lastly, we investigate the impact of missing wearable
data on ""window-of-interest"" analysis methodologies. Prioritizing transparency
and reproducibility, we offer open access to our detailed code examples,
facilitating adaptation in future wearable research. In conclusion, our
contributions provide actionable approaches for wearable data collection and
analysis in chronic disease management.
","['Jonas Van Der Donckt', 'Nicolas Vandenbussche', 'Jeroen Van Der Donckt', 'Stephanie Chen', 'Marija Stojchevska', 'Mathias De Brouwer', 'Bram Steenwinckel', 'Koen Paemeleire', 'Femke Ongenae', 'Sofie Van Hoecke']"
http://arxiv.org/abs/2012.14937v1,Wearable technology,2020-12-29T20:48:42Z,2020-12-29T20:48:42Z,Adaptive Extreme Edge Computing for Wearable Devices,"  Wearable devices are a fast-growing technology with impact on personal
healthcare for both society and economy. Due to the widespread of sensors in
pervasive and distributed networks, power consumption, processing speed, and
system adaptation are vital in future smart wearable devices. The visioning and
forecasting of how to bring computation to the edge in smart sensors have
already begun, with an aspiration to provide adaptive extreme edge computing.
Here, we provide a holistic view of hardware and theoretical solutions towards
smart wearable devices that can provide guidance to research in this pervasive
computing era. We propose various solutions for biologically plausible models
for continual learning in neuromorphic computing technologies for wearable
sensors. To envision this concept, we provide a systematic outline in which
prospective low power and low latency scenarios of wearable sensors in
neuromorphic platforms are expected. We successively describe vital potential
landscapes of neuromorphic processors exploiting complementary metal-oxide
semiconductors (CMOS) and emerging memory technologies (e.g. memristive
devices). Furthermore, we evaluate the requirements for edge computing within
wearable devices in terms of footprint, power consumption, latency, and data
size. We additionally investigate the challenges beyond neuromorphic computing
hardware, algorithms and devices that could impede enhancement of adaptive edge
computing in smart wearable devices.
","['Erika Covi', 'Elisa Donati', 'Hadi Heidari', 'David Kappel', 'Xiangpeng Liang', 'Melika Payvand', 'Wei Wang']"
http://arxiv.org/abs/2304.09861v1,Wearable technology,2023-04-12T13:50:06Z,2023-04-12T13:50:06Z,IoT-based Wearables: A comprehensive Survey,"  A substantial amount of growth is being achieved by businesses through
IoT-based services. The emergent of small electronic devices capable of
computing, which are commonly known as wearables in IoT domain has proven to
have huge impact in people's life. Theses wearables are capable of collecting
vital information about a person's activities and behaviours regularly. This
makes them suitable for many applications in health monitoring, fitness,
sports, education and some industry related applications. To this end, in this
paper, we aim to provide a general review on IoT-based wearables, the sensors
adopted for several categorized wearables, the communication technologies
adopted and the most widely adopted data processing techniques for wearables.
Furthermore, we present the challenges faced for wide adoption of wearables and
the future research directions.
","['Yahuza Bello', 'Emanuel Figetakis']"
http://arxiv.org/abs/1708.05410v3,Wearable technology,2017-08-17T18:51:14Z,2018-07-11T02:38:20Z,Wearable Communications in 5G: Challenges and Enabling Technologies,"  As wearable devices become more ingrained in our daily lives, traditional
communication networks primarily designed for human being-oriented applications
are facing tremendous challenges. The upcoming 5G wireless system aims to
support unprecedented high capacity, low latency, and massive connectivity. In
this article, we evaluate key challenges in wearable communications. A
cloud/edge communication architecture that integrates the cloud radio access
network, software defined network, device to device communications, and
cloud/edge technologies is presented. Computation offloading enabled by this
multi-layer communications architecture can offload computation-excessive and
latency-stringent applications to nearby devices through device to device
communications or to nearby edge nodes through cellular or other wireless
technologies. Critical issues faced by wearable communications such as short
battery life, limited computing capability, and stringent latency can be
greatly alleviated by this cloud/edge architecture. Together with the presented
architecture, current transmission and networking technologies, including
non-orthogonal multiple access, mobile edge computing, and energy harvesting,
can greatly enhance the performance of wearable communication in terms of
spectral efficiency, energy efficiency, latency, and connectivity.
","['Haijian Sun', 'Zekun Zhang', 'Rose Qingyang Hu', 'Yi Qian']"
http://arxiv.org/abs/2005.06958v1,Wearable technology,2020-04-20T14:04:08Z,2020-04-20T14:04:08Z,"Wearable Internet of Things for Personalized Healthcare Study of Trends
  and Latent Research","  In this age of heterogeneous systems, diverse technologies are integrated to
create application-specific solutions. The recent upsurge in acceptance of
technologies such as cloud computing and ubiquitous Internet has cleared the
path for Internet of Things (IoT). Moreover, the increasing Internet
penetration with the rising use of mobile devices has inspired an era of
technology that allows interfacing of physical objects and connecting them to
Internet for developing applications serving a wide range of purposes. Recent
developments in the area of wearable devices has led to the creation of another
segment in IoT, which can be conveniently referred to as Wearable Internet of
Things (WIoT). Research in this area promises to personalize healthcare in
previously unimaginable ways by allowing individual tracking of wellness and
health information. This chapter shall cover the different facets of Wearable
Internet of Things (WIoT) and ways in which it is a key driving technology
behind the concept of personalized healthcare. It shall discuss the theoretical
aspects of WIoT, focusing on functionality, design and applicability. Moreover,
it shall also elaborate on the role of wearable sensors, big data and cloud
computing as enabling technologies for WIoT.
","['Samiya Khan', 'Mansaf Alam']"
http://arxiv.org/abs/1904.13226v1,Wearable technology,2019-04-27T11:04:36Z,2019-04-27T11:04:36Z,"Different Stages of Wearable Health Tracking Adoption & Abandonment: A
  Survey Study and Analysis","  Health trackers are widely adopted to support users with daily health and
wellness tracking. They can help increase steps taken, enhance sleeping
pattern, improve healthy diet, and promote overall health. Despite the growth
in the adoption of such technology, their reallife use is still questionable.
While some users derive longterm value from their trackers, others face
barriers to integrate it into their daily routine. Studies have analysed
technical aspects of these barriers. In this study, we analyse the behavioural
factors of discouragement and wearable abandonment strictly tied to user habits
and living circumstances. A data analysis was conducted in two different
studies, one with users posts about wearable sales and the other one was a
survey analysis. The two studies were used to analyse the stages of wearable
adoption, use and abandonment. Therefore, we mainly focused on users motives to
get a wearable tracker and to post it for sale. We extracted insights about
user motives, highlighted technology condition and limitations, and timeframe
before abandonment. The findings revealed certain user behavioural pattern
throughout the wearable use and abandonment.
",['Ahmed Fadhil']
http://arxiv.org/abs/1607.03730v1,Wearable technology,2016-07-13T13:47:49Z,2016-07-13T13:47:49Z,"Learning Shallow Detection Cascades for Wearable Sensor-Based Mobile
  Health Applications","  The field of mobile health aims to leverage recent advances in wearable
on-body sensing technology and smart phone computing capabilities to develop
systems that can monitor health states and deliver just-in-time adaptive
interventions. However, existing work has largely focused on analyzing
collected data in the off-line setting. In this paper, we propose a novel
approach to learning shallow detection cascades developed explicitly for use in
a real-time wearable-phone or wearable-phone-cloud systems. We apply our
approach to the problem of cigarette smoking detection from a combination of
wrist-worn actigraphy data and respiration chest band data using two and three
stage cascades.
","['Hamid Dadkhahi', 'Nazir Saleheen', 'Santosh Kumar', 'Benjamin Marlin']"
http://arxiv.org/abs/2111.07365v1,Wearable technology,2021-11-14T15:24:29Z,2021-11-14T15:24:29Z,Learning Enhancement in Higher Education with Wearable Technology,"  Wearable technologies have traditionally been used to measure and monitor
vital human signs for well-being and healthcare applications. However, there is
a growing interest in using and deploying these technologies to facilitate
teaching and learning, particularly in a higher education environment. The aim
of this paper is therefore to systematically review the range of wearable
devices that have been used for enhancing the teaching and delivery of
engineering curricula in higher education. Moreover, we compare the advantages
and disadvantages of these devices according to the location in which they are
worn on the human body. According to our survey, wearable devices for enhanced
learning have mainly been worn on the head (e.g. eyeglasses), wrist (e.g.
watches) and chest (e.g. electrocardiogram patch). In fact, among those
locations, head-worn devices enable better student engagement with the learning
materials, improved student attention as well as higher spatial and visual
awareness. We identify the research questions and discuss the research
inclusion and exclusion criteria to present the challenges faced by researchers
in implementing learning technologies for enhanced engineering education.
Furthermore, we provide recommendations on using wearable devices to improve
the teaching and learning of engineering courses in higher education.
","['Sara Khosravi', 'Stuart G. Bailey', 'Hadi Parvizi', 'Rami Ghannam']"
http://arxiv.org/abs/2303.13534v3,Prompt engineering,2023-03-13T14:25:56Z,2024-07-04T12:13:06Z,"Prompting AI Art: An Investigation into the Creative Skill of Prompt
  Engineering","  We are witnessing a novel era of creativity where anyone can create digital
content via prompt-based learning (known as prompt engineering). This paper
investigates prompt engineering as a novel creative skill for creating AI art
with text-to-image generation. In three consecutive studies, we explore whether
crowdsourced participants can 1) discern prompt quality, 2) write prompts, and
3) refine prompts. We find that participants could evaluate prompt quality and
crafted descriptive prompts, but they lacked style-specific vocabulary
necessary for effective prompting. This is in line with our hypothesis that
prompt engineering is a new type of skill that is non-intuitive and must first
be acquired (e.g., through means of practice and learning) before it can be
used. Our studies deepen our understanding of prompt engineering and chart
future research directions. We conclude by envisioning four potential futures
for prompt engineering.
","['Jonas Oppenlaender', 'Rhema Linder', 'Johanna Silvennoinen']"
http://arxiv.org/abs/2402.12959v1,Prompt engineering,2024-02-20T12:25:26Z,2024-02-20T12:25:26Z,Prompt Stealing Attacks Against Large Language Models,"  The increasing reliance on large language models (LLMs) such as ChatGPT in
various fields emphasizes the importance of ``prompt engineering,'' a
technology to improve the quality of model outputs. With companies investing
significantly in expert prompt engineers and educational resources rising to
meet market demand, designing high-quality prompts has become an intriguing
challenge. In this paper, we propose a novel attack against LLMs, named prompt
stealing attacks. Our proposed prompt stealing attack aims to steal these
well-designed prompts based on the generated answers. The prompt stealing
attack contains two primary modules: the parameter extractor and the prompt
reconstruction. The goal of the parameter extractor is to figure out the
properties of the original prompts. We first observe that most prompts fall
into one of three categories: direct prompt, role-based prompt, and in-context
prompt. Our parameter extractor first tries to distinguish the type of prompts
based on the generated answers. Then, it can further predict which role or how
many contexts are used based on the types of prompts. Following the parameter
extractor, the prompt reconstructor can be used to reconstruct the original
prompts based on the generated answers and the extracted features. The final
goal of the prompt reconstructor is to generate the reversed prompts, which are
similar to the original prompts. Our experimental results show the remarkable
performance of our proposed attacks. Our proposed attacks add a new dimension
to the study of prompt engineering and call for more attention to the security
issues on LLMs.
","['Zeyang Sha', 'Yang Zhang']"
http://arxiv.org/abs/2501.03508v1,Prompt engineering,2025-01-07T03:51:10Z,2025-01-07T03:51:10Z,"A Sequential Optimal Learning Approach to Automated Prompt Engineering
  in Large Language Models","  Designing effective prompts is essential to guiding large language models
(LLMs) toward desired responses. Automated prompt engineering aims to reduce
reliance on manual effort by streamlining the design, refinement, and
optimization of natural language prompts. This paper proposes an optimal
learning framework for automated prompt engineering, designed to sequentially
identify effective prompt features while efficiently allocating a limited
evaluation budget. We introduce a feature-based method to express prompts,
which significantly broadens the search space. Bayesian regression is employed
to utilize correlations among similar prompts, accelerating the learning
process. To efficiently explore the large space of prompt features for a high
quality prompt, we adopt the forward-looking Knowledge-Gradient (KG) policy for
sequential optimal learning. The KG policy is computed efficiently by solving
mixed-integer second-order cone optimization problems, making it scalable and
capable of accommodating prompts characterized only through constraints. We
demonstrate that our method significantly outperforms a set of benchmark
strategies assessed on instruction induction tasks. The results highlight the
advantages of using the KG policy for prompt learning given a limited
evaluation budget. Our framework provides a solution to deploying automated
prompt engineering in a wider range applications where prompt evaluation is
costly.
","['Shuyang Wang', 'Somayeh Moazeni', 'Diego Klabjan']"
http://arxiv.org/abs/2311.09773v1,Prompt engineering,2023-11-16T10:55:29Z,2023-11-16T10:55:29Z,"To be or not to be? an exploration of continuously controllable prompt
  engineering","  As the use of large language models becomes more widespread, techniques like
parameter-efficient fine-tuning and other methods for controlled generation are
gaining traction for customizing models and managing their outputs. However,
the challenge of precisely controlling how prompts influence these models is an
area ripe for further investigation. In response, we introduce ControlPE
(Continuously Controllable Prompt Engineering). ControlPE enables finer
adjustments to prompt effects, complementing existing prompt engineering, and
effectively controls continuous targets. This approach harnesses the power of
LoRA (Low-Rank Adaptation) to create an effect akin to prompt weighting,
enabling fine-tuned adjustments to the impact of prompts. Our methodology
involves generating specialized datasets for prompt distillation, incorporating
these prompts into the LoRA model, and carefully adjusting LoRA merging weight
to regulate the influence of prompts. This provides a dynamic and adaptable
tool for prompt control. Through our experiments, we have validated the
practicality and efficacy of ControlPE. It proves to be a promising solution
for control a variety of prompts, ranging from generating short responses
prompts, refusal prompts to chain-of-thought prompts.
","['Yuhan Sun', 'Mukai Li', 'Yixin Cao', 'Kun Wang', 'Wenxiao Wang', 'Xingyu Zeng', 'Rui Zhao']"
http://arxiv.org/abs/2403.08950v1,Prompt engineering,2024-03-13T20:32:32Z,2024-03-13T20:32:32Z,Exploring Prompt Engineering Practices in the Enterprise,"  Interaction with Large Language Models (LLMs) is primarily carried out via
prompting. A prompt is a natural language instruction designed to elicit
certain behaviour or output from a model. In theory, natural language prompts
enable non-experts to interact with and leverage LLMs. However, for complex
tasks and tasks with specific requirements, prompt design is not trivial.
Creating effective prompts requires skill and knowledge, as well as significant
iteration in order to determine model behavior, and guide the model to
accomplish a particular goal. We hypothesize that the way in which users
iterate on their prompts can provide insight into how they think prompting and
models work, as well as the kinds of support needed for more efficient prompt
engineering. To better understand prompt engineering practices, we analyzed
sessions of prompt editing behavior, categorizing the parts of prompts users
iterated on and the types of changes they made. We discuss design implications
and future directions based on these prompt engineering practices.
","['Michael Desmond', 'Michelle Brachman']"
http://arxiv.org/abs/2308.11628v1,Prompt engineering,2023-08-08T20:47:16Z,2023-08-08T20:47:16Z,Prompt Engineering For Students of Medicine and Their Teachers,"  ""Prompt Engineering for Students of Medicine and Their Teachers"" brings the
principles of prompt engineering for large language models such as ChatGPT and
Google Bard to medical education. This book contains a comprehensive guide to
prompt engineering to help both teachers and students improve education in the
medical field. Just as prompt engineering is critical in getting good
information out of an AI, it is also critical to get students to think and
understand more deeply. The principles of prompt engineering that we have
learned from AI systems have the potential to simultaneously revolutionize
learning in the healthcare field. The book analyzes from multiple angles the
anatomy of a good prompt for both AI models and students. The different types
of prompts are examined, showing how each style has unique characteristics and
applications. The principles of prompt engineering, applied properly, are
demonstrated to be effective in teaching across the diverse fields of anatomy,
physiology, pathology, pharmacology, and clinical skills. Just like ChatGPT and
similar large language AI models, students need clear and detailed prompting in
order for them to fully understand a topic. Using identical principles, a
prompt that gets good information from an AI will also cause a student to think
more deeply and accurately. The process of prompt engineering facilitates this
process. Because each chapter contains multiple examples and key takeaways, it
is a practical guide for implementing prompt engineering in the learning
process. It provides a hands-on approach to ensure readers can immediately
apply the concepts they learn
",['Thomas F. Heston']
http://arxiv.org/abs/2412.12644v1,Prompt engineering,2024-12-17T08:09:15Z,2024-12-17T08:09:15Z,"iPrOp: Interactive Prompt Optimization for Large Language Models with a
  Human in the Loop","  Prompt engineering has made significant contributions to the era of large
language models, yet its effectiveness depends on the skills of a prompt
author. Automatic prompt optimization can support the prompt development
process, but requires annotated data. This paper introduces $\textit{iPrOp}$, a
novel Interactive Prompt Optimization system, to bridge manual prompt
engineering and automatic prompt optimization. With human intervention in the
optimization loop, $\textit{iPrOp}$ offers users the flexibility to assess
evolving prompts. We present users with prompt variations, selected instances,
large language model predictions accompanied by corresponding explanations, and
performance metrics derived from a subset of the training data. This approach
empowers users to choose and further refine the provided prompts based on their
individual preferences and needs. This system not only assists non-technical
domain experts in generating optimal prompts tailored to their specific tasks
or domains, but also enables to study the intrinsic parameters that influence
the performance of prompt optimization. Our evaluation shows that our system
has the capability to generate improved prompts, leading to enhanced task
performance.
","['Jiahui Li', 'Roman Klinger']"
http://arxiv.org/abs/2311.03359v1,Prompt engineering,2023-09-07T20:40:04Z,2023-09-07T20:40:04Z,Prompted Software Engineering in the Era of AI Models,"  This paper introduces prompted software engineering (PSE), which integrates
prompt engineering to build effective prompts for language-based AI models, to
enhance the software development process. PSE enables the use of AI models in
software development to produce high-quality software with fewer resources,
automating tedious tasks and allowing developers to focus on more innovative
aspects. However, effective prompts are necessary to guide software development
in generating accurate, relevant, and useful responses, while mitigating risks
of misleading outputs. This paper describes how productive prompts should be
built throughout the software development cycle.
",['Dae-Kyoo Kim']
http://arxiv.org/abs/2407.12865v1,Prompt engineering,2024-07-12T19:11:21Z,2024-07-12T19:11:21Z,"GRAD-SUM: Leveraging Gradient Summarization for Optimal Prompt
  Engineering","  Prompt engineering for large language models (LLMs) is often a manual
time-intensive process that involves generating, evaluating, and refining
prompts iteratively to ensure high-quality outputs. While there has been work
on automating prompt engineering, the solutions generally are either tuned to
specific tasks with given answers or are quite costly. We introduce GRAD-SUM, a
scalable and flexible method for automatic prompt engineering that builds on
gradient-based optimization techniques. Our approach incorporates user-defined
task descriptions and evaluation criteria, and features a novel gradient
summarization module to generalize feedback effectively. Our results
demonstrate that GRAD-SUM consistently outperforms existing methods across
various benchmarks, highlighting its versatility and effectiveness in automatic
prompt optimization.
","['Derek Austin', 'Elliott Chartock']"
http://arxiv.org/abs/2506.00058v1,Prompt engineering,2025-05-29T09:11:23Z,2025-05-29T09:11:23Z,Prompt Engineer: Analyzing Skill Requirements in the AI Job Market,"  The rise of large language models (LLMs) has created a new job role: the
Prompt Engineer. Despite growing interest in this position, we still do not
fully understand what skills this new job role requires or how common these
jobs are. We analyzed 20,662 job postings on LinkedIn, including 72 prompt
engineer positions, to learn more about this emerging role. We found that
prompt engineering is still rare (less than 0.5% of sampled job postings) but
has a unique skill profile. Prompt engineers need AI knowledge (22.8%), prompt
design skills (18.7%), good communication (21.9%), and creative problem-solving
(15.8%) skills. These requirements significantly differ from those of
established roles, such as data scientists and machine learning engineers,
showing that prompt engineering is becoming its own profession. Our findings
help job seekers, employers, and educational institutions in better
understanding the emerging field of prompt engineering.
","['An Vu', 'Jonas Oppenlaender']"
http://arxiv.org/abs/2311.05661v3,Prompt engineering,2023-11-09T08:00:32Z,2024-07-03T01:29:20Z,Prompt Engineering a Prompt Engineer,"  Prompt engineering is a challenging yet crucial task for optimizing the
performance of large language models on customized tasks. It requires complex
reasoning to examine the model's errors, hypothesize what is missing or
misleading in the current prompt, and communicate the task with clarity. While
recent works indicate that large language models can be meta-prompted to
perform automatic prompt engineering, we argue that their potential is limited
due to insufficient guidance for complex reasoning in the meta-prompt. We fill
this gap by infusing into the meta-prompt three key components: detailed
descriptions, context specification, and a step-by-step reasoning template. The
resulting method, named PE2, exhibits remarkable versatility across diverse
language tasks. It finds prompts that outperform ""let's think step by step"" by
6.3% on MultiArith and 3.1% on GSM8K, and outperforms competitive baselines on
counterfactual tasks by 6.9%. Further, we show that PE2 can make targeted and
highly specific prompt edits, rectify erroneous prompts, and induce multi-step
plans for complex tasks.
","['Qinyuan Ye', 'Maxamed Axmed', 'Reid Pryzant', 'Fereshte Khani']"
http://arxiv.org/abs/2504.04351v1,Prompt engineering,2025-04-06T04:19:19Z,2025-04-06T04:19:19Z,"DDPT: Diffusion-Driven Prompt Tuning for Large Language Model Code
  Generation","  Large Language Models (LLMs) have demonstrated remarkable capabilities in
code generation. However, the quality of the generated code is heavily
dependent on the structure and composition of the prompts used. Crafting
high-quality prompts is a challenging task that requires significant knowledge
and skills of prompt engineering. To advance the automation support for the
prompt engineering for LLM-based code generation, we propose a novel solution
Diffusion-Driven Prompt Tuning (DDPT) that learns how to generate optimal
prompt embedding from Gaussian Noise to automate the prompt engineering for
code generation. We evaluate the feasibility of diffusion-based optimization
and abstract the optimal prompt embedding as a directional vector toward the
optimal embedding. We use the code generation loss given by the LLMs to help
the diffusion model capture the distribution of optimal prompt embedding during
training. The trained diffusion model can build a path from the noise
distribution to the optimal distribution at the sampling phrase, the evaluation
result demonstrates that DDPT helps improve the prompt optimization for code
generation.
","['Jinyang Li', 'Sangwon Hyun', 'M. Ali Babar']"
http://arxiv.org/abs/2401.14447v1,Prompt engineering,2024-01-25T18:58:11Z,2024-01-25T18:58:11Z,Wordflow: Social Prompt Engineering for Large Language Models,"  Large language models (LLMs) require well-crafted prompts for effective use.
Prompt engineering, the process of designing prompts, is challenging,
particularly for non-experts who are less familiar with AI technologies. While
researchers have proposed techniques and tools to assist LLM users in prompt
design, these works primarily target AI application developers rather than
non-experts. To address this research gap, we propose social prompt
engineering, a novel paradigm that leverages social computing techniques to
facilitate collaborative prompt design. To investigate social prompt
engineering, we introduce Wordflow, an open-source and social text editor that
enables everyday users to easily create, run, share, and discover LLM prompts.
Additionally, by leveraging modern web technologies, Wordflow allows users to
run LLMs locally and privately in their browsers. Two usage scenarios highlight
how social prompt engineering and our tool can enhance laypeople's interaction
with LLMs. Wordflow is publicly accessible at
https://poloclub.github.io/wordflow.
","['Zijie J. Wang', 'Aishwarya Chakravarthy', 'David Munechika', 'Duen Horng Chau']"
http://arxiv.org/abs/2405.01249v1,Prompt engineering,2024-05-02T12:52:23Z,2024-05-02T12:52:23Z,"Prompt engineering paradigms for medical applications: scoping review
  and recommendations for better practices","  Prompt engineering is crucial for harnessing the potential of large language
models (LLMs), especially in the medical domain where specialized terminology
and phrasing is used. However, the efficacy of prompt engineering in the
medical domain remains to be explored. In this work, 114 recent studies
(2022-2024) applying prompt engineering in medicine, covering prompt learning
(PL), prompt tuning (PT), and prompt design (PD) are reviewed. PD is the most
prevalent (78 articles). In 12 papers, PD, PL, and PT terms were used
interchangeably. ChatGPT is the most commonly used LLM, with seven papers using
it for processing sensitive clinical data. Chain-of-Thought emerges as the most
common prompt engineering technique. While PL and PT articles typically provide
a baseline for evaluating prompt-based approaches, 64% of PD studies lack
non-prompt-related baselines. We provide tables and figures summarizing
existing work, and reporting recommendations to guide future research
contributions.
","['Jamil Zaghir', 'Marco Naguib', 'Mina Bjelogrlic', 'Aurélie Névéol', 'Xavier Tannier', 'Christian Lovis']"
http://arxiv.org/abs/2412.05127v1,Prompt engineering,2024-12-06T15:35:18Z,2024-12-06T15:35:18Z,"The Prompt Canvas: A Literature-Based Practitioner Guide for Creating
  Effective Prompts in Large Language Models","  The rise of large language models (LLMs) has highlighted the importance of
prompt engineering as a crucial technique for optimizing model outputs. While
experimentation with various prompting methods, such as Few-shot,
Chain-of-Thought, and role-based techniques, has yielded promising results,
these advancements remain fragmented across academic papers, blog posts and
anecdotal experimentation. The lack of a single, unified resource to
consolidate the field's knowledge impedes the progress of both research and
practical application. This paper argues for the creation of an overarching
framework that synthesizes existing methodologies into a cohesive overview for
practitioners. Using a design-based research approach, we present the Prompt
Canvas, a structured framework resulting from an extensive literature review on
prompt engineering that captures current knowledge and expertise. By combining
the conceptual foundations and practical strategies identified in prompt
engineering, the Prompt Canvas provides a practical approach for leveraging the
potential of Large Language Models. It is primarily designed as a learning
resource for pupils, students and employees, offering a structured introduction
to prompt engineering. This work aims to contribute to the growing discourse on
prompt engineering by establishing a unified methodology for researchers and
providing guidance for practitioners.
","['Michael Hewing', 'Vincent Leinhos']"
http://arxiv.org/abs/2408.07302v1,Prompt engineering,2024-07-30T15:05:24Z,2024-07-30T15:05:24Z,"Effects of a Prompt Engineering Intervention on Undergraduate Students'
  AI Self-Efficacy, AI Knowledge and Prompt Engineering Ability: A Mixed
  Methods Study","  Prompt engineering is critical for effective interaction with large language
models (LLMs) such as ChatGPT. However, efforts to teach this skill to students
have been limited. This study designed and implemented a prompt engineering
intervention, examining its influence on undergraduate students' AI
self-efficacy, AI knowledge, and proficiency in creating effective prompts. The
intervention involved 27 students who participated in a 100-minute workshop
conducted during their history course at a university in Hong Kong. During the
workshop, students were introduced to prompt engineering strategies, which they
applied to plan the course's final essay task. Multiple data sources were
collected, including students' responses to pre- and post-workshop
questionnaires, pre- and post-workshop prompt libraries, and written
reflections. The study's findings revealed that students demonstrated a higher
level of AI self-efficacy, an enhanced understanding of AI concepts, and
improved prompt engineering skills because of the intervention. These findings
have implications for AI literacy education, as they highlight the importance
of prompt engineering training for specific higher education use cases. This is
a significant shift from students haphazardly and intuitively learning to
engineer prompts. Through prompt engineering education, educators can faciitate
students' effective navigation and leverage of LLMs to support their
coursework.
","['David James Woo', 'Deliang Wang', 'Tim Yung', 'Kai Guo']"
http://arxiv.org/abs/2504.20355v1,Prompt engineering,2025-04-29T01:45:47Z,2025-04-29T01:45:47Z,Local Prompt Optimization,"  In recent years, the use of prompts to guide the output of Large Language
Models have increased dramatically. However, even the best of experts struggle
to choose the correct words to stitch up a prompt for the desired task. To
solve this, LLM driven prompt optimization emerged as an important problem.
Existing prompt optimization methods optimize a prompt globally, where in all
the prompt tokens have to be optimized over a large vocabulary while solving a
complex task. The large optimization space (tokens) leads to insufficient
guidance for a better prompt. In this work, we introduce Local Prompt
Optimization (LPO) that integrates with any general automatic prompt
engineering method. We identify the optimization tokens in a prompt and nudge
the LLM to focus only on those tokens in its optimization step. We observe
remarkable performance improvements on Math Reasoning (GSM8k and MultiArith)
and BIG-bench Hard benchmarks across various automatic prompt engineering
methods. Further, we show that LPO converges to the optimal prompt faster than
global methods.
","['Yash Jain', 'Vishal Chowdhary']"
http://arxiv.org/abs/2401.14423v4,Prompt engineering,2024-01-24T06:20:18Z,2024-05-05T00:54:26Z,Prompt Design and Engineering: Introduction and Advanced Methods,"  Prompt design and engineering has rapidly become essential for maximizing the
potential of large language models. In this paper, we introduce core concepts,
advanced techniques like Chain-of-Thought and Reflection, and the principles
behind building LLM-based agents. Finally, we provide a survey of tools for
prompt engineers.
",['Xavier Amatriain']
http://arxiv.org/abs/2408.09127v1,Prompt engineering,2024-08-17T07:38:10Z,2024-08-17T07:38:10Z,"From Specifications to Prompts: On the Future of Generative LLMs in
  Requirements Engineering","  Generative LLMs, such as GPT, have the potential to revolutionize
Requirements Engineering (RE) by automating tasks in new ways. This column
explores the novelties and introduces the importance of precise prompts for
effective interactions. Human evaluation and prompt engineering are essential
in leveraging LLM capabilities.
",['Andreas Vogelsang']
http://arxiv.org/abs/2504.16204v1,Prompt engineering,2025-04-22T18:51:32Z,2025-04-22T18:51:32Z,"Reflexive Prompt Engineering: A Framework for Responsible Prompt
  Engineering and Interaction Design","  Responsible prompt engineering has emerged as a critical framework for
ensuring that generative artificial intelligence (AI) systems serve society's
needs while minimizing potential harms. As generative AI applications become
increasingly powerful and ubiquitous, the way we instruct and interact with
them through prompts has profound implications for fairness, accountability,
and transparency. This article examines how strategic prompt engineering can
embed ethical and legal considerations and societal values directly into AI
interactions, moving beyond mere technical optimization for functionality. This
article proposes a comprehensive framework for responsible prompt engineering
that encompasses five interconnected components: prompt design, system
selection, system configuration, performance evaluation, and prompt management.
Drawing from empirical evidence, the paper demonstrates how each component can
be leveraged to promote improved societal outcomes while mitigating potential
risks. The analysis reveals that effective prompt engineering requires a
delicate balance between technical precision and ethical consciousness,
combining the systematic rigor and focus on functionality with the nuanced
understanding of social impact. Through examination of real-world and emerging
practices, the article illustrates how responsible prompt engineering serves as
a crucial bridge between AI development and deployment, enabling organizations
to fine-tune AI outputs without modifying underlying model architectures. This
approach aligns with broader ""Responsibility by Design"" principles, embedding
ethical considerations directly into the implementation process rather than
treating them as post-hoc additions. The article concludes by identifying key
research directions and practical guidelines for advancing the field of
responsible prompt engineering.
",['Christian Djeffal']
http://arxiv.org/abs/2410.10839v1,6G,2024-09-30T11:52:24Z,2024-09-30T11:52:24Z,"BUPTCMCC-6G-DataAI+: A generative channel dataset for 6G AI air
  interface research","  In September 2024, Beijing University of Posts and Telecommunications and
China Mobile Communications Group jointly releases a channel dataset for the
sixth generation (6G) mobile communications, named BUPTCMCC-6G-DataAI+.
BUPTCMCC-6G-DataAI+ is the update version of BUPTCMCC-6G-DataAI, which is
already published in June 2023, aiming at extending 6G new technologies,
frequency bands, and applications. BUPTCMCC-6G-DataAI+ provides deterministic
data covering new mid-bands, millimeter wave (mmWave), and terahertz (THz),
supports the features of XL-MIMO near-field, high mobility and provides
multiple 6G scenarios such as reconfigurable intelligent surface (RIS) and
industrial Internet. Configured with customized features according to different
user needs, BUPTCMCC-6G-DataAI+ can adaptively generate scalable large-scale or
small-scale parameters, providing data support for 6G research and development,
and standardization.
","['Li Yu', 'Jianhua Zhang', 'Mingjun Fu', 'Qixing Wang']"
http://arxiv.org/abs/2411.18435v1,6G,2024-11-27T15:20:11Z,2024-11-27T15:20:11Z,6G Takes Shape,"  The contours of 6G -- its key technical components and driving requirements
-- are finally coming into focus. Through twenty questions and answers, this
article defines the important aspects of 6G across four categories. First, we
identify the key themes and forces driving the development of 6G, and what will
make 6G unique. We argue that 6G requirements and system design will be driven
by (i) the tenacious pursuit of spectral (bits/Hz/area), energy (bits/Joule),
and cost (bits/dollar) efficiencies, and (ii) three new service enhancements:
sensing/localization/awareness, compute, and global broadband/emergency
connectivity. Second, we overview the important role of spectrum in 6G, what
new spectrum to expect in 6G, and outline how the different bands will be used
to provide 6G services. Third, we focus our attention on the 6G physical layer,
including waveforms, MIMO advancements, and the potential use of deep learning.
Finally, we explore how global connectivity will be achieved in 6G, through
non-terrestrial networks as well as low-cost network expansion via
disaggregation and O-RAN. Although 6G standardization activities will not begin
until late 2025, meaning this article is by definition speculative, our
predictions are informed by several years of intensive research and
discussions. Our goal is to provide a grounded perspective that will be helpful
to both researchers and engineers as we move into the 6G era.
","['Jeffrey G. Andrews', 'Todd E. Humphreys', 'Tingfang Ji']"
http://arxiv.org/abs/2411.09660v1,6G,2024-11-14T18:31:16Z,2024-11-14T18:31:16Z,"Capacity and Power Consumption of Multi-Layer 6G Networks Using the
  Upper Mid-Band","  This paper presents a new system model to evaluate the capacity and power
consumption of multi-layer 6G networks utilising the upper mid-band (FR3). The
model captures heterogeneous 4G, 5G, and 6G deployments, analyzing their
performance under different deployment strategies. Our results show that
strategic 6G deployments, non-co-located with existing 5G sites, significantly
enhance throughput, with median and peak user rates of 300 Mbps and exceeding 1
Gbps, respectively. We also emphasize the importance of priority-based cell
reselection and beam configuration to fully leverage 6G capabilities. While 6G
implementation increases power consumption by 33%, non-colocated deployments
strike a balance between performance and power consumption.
","['David López-Pérez', 'Nicola Piovesan', 'Giovanni Geraci']"
http://arxiv.org/abs/2411.10138v1,6G,2024-11-15T12:28:22Z,2024-11-15T12:28:22Z,"Architecture Proposal for 6G Systems Integrating Sensing and
  Communication","  Integrating sensing functionality into 6G communication networks requires
some changes to existing components as well as new entities processing the
radar sensing signals received by the communication antennas. This whitepaper
provides a comprehensive overview of the 6G design proposal for ISaC
(Integrated Sensing and Communication). The whitepaper has been created by the
architecture group of the KOMSENS-6G project. It represents an intermediate
state of the work, as the KOMSENS-6G project is still ongoing. The proposal
should serve as a basis for further discussions and alignment across innovative
6G projects.
","['Peter Gersing', 'Mark Doll', 'Joerg Huschke', 'Oliver Holschke']"
http://arxiv.org/abs/2004.04024v3,6G,2020-04-07T13:49:20Z,2020-06-07T18:05:07Z,6G Communication: Envisioning the Key Issues and Challenges,"  In 2030, we are going to evidence the 6G mobile communication technology,
which will enable the Internet of Everything. Yet 5G has to be experienced by
people worldwide and B5G has to be developed; the researchers have already
started planning, visioning, and gathering requirements of the 6G. Moreover,
many countries have already initiated the research on 6G. 6G promises
connecting every smart device to the Internet from smartphone to intelligent
vehicles. 6G will provide sophisticated and high QoS such as holographic
communication, augmented reality/virtual reality and many more. Also, it will
focus on Quality of Experience (QoE) to provide rich experiences from 6G
technology. Notably, it is very important to vision the issues and challenges
of 6G technology, otherwise, promises may not be delivered on time. The
requirements of 6G poses new challenges to the research community. To achieve
desired parameters of 6G, researchers are exploring various alternatives.
Hence, there are diverse research challenges to envision, from devices to
softwarization. Therefore, in this article, we discuss the future issues and
challenges to be faced by the 6G technology. We have discussed issues and
challenges from every aspect from hardware to the enabling technologies which
will be utilized by 6G.
","['Sabuzima Nayak', 'Ripon Patgiri']"
http://arxiv.org/abs/2406.00308v1,6G,2024-06-01T05:48:40Z,2024-06-01T05:48:40Z,"Toward 6G Optical Fronthaul: A Survey on Enabling Technologies and
  Research Perspectives","  The anticipated launch of the Sixth Generation (6G) of mobile technology by
2030 will mark a significant milestone in the evolution of wireless
communication, ushering in a new era with advancements in technology and
applications. 6G is expected to deliver ultra-high data rates and almost
instantaneous communications, with three-dimensional coverage for everything,
everywhere, and at any time. In the 6G Radio Access Networks (RANs)
architecture, the Fronthaul connects geographically distributed Remote Units
(RUs) to Distributed/Digital Units (DUs)pool. Among all possible solutions for
implementing 6G fronthaul, optical technologies will remain crucial in
supporting the 6G fronthaul, as they offer high-speed, low-latency, and
reliable transmission capabilities to meet the 6G strict requirements. This
survey provides an explanation of the 5G and future 6G optical fronthaul
concept and presents a comprehensive overview of the current state of the art
and future research directions in 6G optical fronthaul, highlighting the key
technologies and research perspectives fundamental in designing fronthaul
networks for 5G and future 6G. Additionally, it examines the benefits and
drawbacks of each optical technology and its potential applications in 6G
fronthaul networks. This paper aims to serve as a comprehensive resource for
researchers and industry professionals about the current state and future
prospects of 6G optical fronthaul technologies, facilitating the development of
robust and efficient wireless networks of the future.
","['Abdulhalim Fayad', 'Tibor Cinkler', 'Jacek Rak']"
http://arxiv.org/abs/1906.00741v3,6G,2019-05-09T12:37:55Z,2020-07-29T05:31:17Z,What should 6G be?,"  The standardization of fifth generation (5G) communications has been
completed, and the 5G network should be commercially launched in 2020. As a
result, the visioning and planning of sixth generation (6G) communications has
begun, with an aim to provide communication services for the future demands of
the 2030s. Here we provide a vision for 6G that could serve a research guide in
the post-5G era. We suggest that human-centric mobile communications will still
be the most important application of 6G and the 6G network should be human
centric. Thus, high security, secrecy, and privacy should be key features of 6G
and should be given particular attention by the wireless research community. To
support this vision, we provide a systematic framework in which potential
application scenarios of 6G are anticipated and subdivided. We subsequently
define key potential features of 6G and discuss the required communication
technologies. We also explore the issues beyond communication technologies that
could hamper research and deployment of 6G.
","['Shuping Dang', 'Osama Amin', 'Basem Shihada', 'Mohamed-Slim Alouini']"
http://arxiv.org/abs/2201.06079v1,6G,2022-01-16T16:20:31Z,2022-01-16T16:20:31Z,"Towards 6G Communications: Architecture, Challenges, and Future
  Directions","  The cellular network standard is gradually stepping towards the 6th
Generation (6G). In 6G, the pioneering and exclusive features, such as creating
connectivity even in space and under water, are attracting Governments,
organizations and researchers to spend time, money, effort extensively in this
area. In the direction of intelligent network management and distributed
secured systems, Artificial Intelligence (AI) and blockchain are going to form
the backbone of 6G, respectively. However, there is a need for the study of the
6g architecture and technology, such that researchers can identify the scopes
of improvement in 6G. Therefore, in this survey, we discuss the primary
requirements of 6G along with its overall architecture and technological
aspects. We also highlight crucial challenges and future research directions in
6G networks, which can lead to the successful practical implementation of 6G,
as per the objective of its introduction in next generation cellular networks.
","['Purbita Mitra', 'Rouprita Bhattacharjee', 'Twinkle Chatterjee', 'Soumalya De', 'Raja Karmakar', 'Arindam Ghosh', 'Tinku Adhikari']"
http://arxiv.org/abs/2201.12266v3,6G,2022-01-28T17:28:49Z,2022-02-07T18:23:17Z,Six Questions about 6G,"  Although 5G (Fifth Generation) mobile technology is still in the rollout
phase, research and development of 6G (Sixth Generation) wireless have already
begun. This paper is an introduction to 6G wireless networks, covering the main
drivers for 6G, some of the expected use cases, some of the technical
challenges in 6G, example areas that will require research and new
technologies, the expected timeline for 6G development and rollout, and a list
of some important 6G initiatives world-wide. It was compiled as part of a
series of workshops about 6G held by Thinknet 6G and MUENCHNER KREIS in 2021.
","['Kimberley Parsons Trommler', 'Matthias Hafner', 'Wolfgang Kellerer', 'Peter Merz', 'Sigurd Schuster', 'Josef Urban', 'Uwe Baeder', 'Bertram Gunzelmann', 'Andreas Kornbichler']"
http://arxiv.org/abs/2207.04744v1,6G,2022-07-11T10:05:07Z,2022-07-11T10:05:07Z,"The Confluence of Blockchain and 6G Network: Scenarios Analysis and
  Performance Assessment","  Emerging advanced applications, such as smart cities, healthcare, and virtual
reality, demand more challenging requirements on sixth-generation (6G) mobile
networks, including the need for improved secrecy, greater integrity,
non-repudiation, authentication, and access control. While blockchain, with its
intrinsic features, is generally regarded as one of the most disruptive
technological enablers for 6G functional standards, there is no comprehensive
study of whether, when, and how blockchain will be used in 6G scenarios.
Existing research lacks performance assessment methodology for the use of
blockchain in 6G scenarios. Therefore, we abstract seven fine-grained 6G
possibilities from the application layer and investigate the why, what, and
when issues for 6G scenarios in this work. Moreover, we provide a methodology
for evaluating the performance and scalability of blockchain-based 6G
scenarios. In conclusion, we undertake comprehensive experimental to assess the
performance of the Quorum blockchain and 6G scenarios. The experimental results
show that a consortium blockchain with the proper settings may satisfy the
performance and scalability requiremen
","['Bo Li', 'Shuiguang Deng', 'Xueqiang Yan', 'Schahram Dustdar']"
http://arxiv.org/abs/2309.16714v1,6G,2023-08-19T17:13:18Z,2023-08-19T17:13:18Z,"On Security Strategies for Addressing Potential Vulnerabilities in 6G
  Technologies Deployable in Healthcare","  Researchers are now focusing on 6G as a new network technology that will
bring significant gains over the previous generations while many sectors are
still implementing the 5G network in their business processes and operations.
Meanwhile, key technological fields that will be influenced by 6G networks have
been identified. These include distributed artificial intelligence, intelligent
radio, real-time intelligent edge computing, and 3D intercoms. Additionally,
each area and potential application of 6G is supported by relevant emerging
technologies. Nevertheless, these 6G technology and applications have
significant security vulnerabilities that must be addressed before the complete
adoption of 6G networks. The healthcare is one of the sectors that are
benefiting from the great features introduced in the 5G networks that enhance
digital communications and data protection; that notwithstanding, there are
still security flaws in 5G technologies that can be transferred to the 6G
networks if not properly addressed. This paper highlights the key areas of 6G
networks that would provide grand support for the development of healthcare
systems. It also identifies certain vulnerabilities in the previous cellular
networks that are transferable to 6G networks, and suggests security strategies
including zero trust initiatives that could be implemented to address the
security concerns.
",['Chinazunwa Uwaoma']
http://arxiv.org/abs/1904.11686v2,6G,2019-04-26T06:27:27Z,2019-07-19T06:21:06Z,The Roadmap to 6G -- AI Empowered Wireless Networks,"  The recent upsurge of diversified mobile applications, especially those
supported by Artificial Intelligence (AI), is spurring heated discussions on
the future evolution of wireless communications. While 5G is being deployed
around the world, efforts from industry and academia have started to look
beyond 5G and conceptualize 6G. We envision 6G to undergo an unprecedented
transformation that will make it substantially different from the previous
generations of wireless cellular systems. In particular, 6G will go beyond
mobile Internet and will be required to support ubiquitous AI services from the
core to the end devices of the network. Meanwhile, AI will play a critical role
in designing and optimizing 6G architectures, protocols, and operations. In
this article, we discuss potential technologies for 6G to enable mobile AI
applications, as well as AI-enabled methodologies for 6G network design and
optimization. Key trends in the evolution to 6G will also be discussed.
","['Khaled B. Letaief', 'Wei Chen', 'Yuanming Shi', 'Jun Zhang', 'Ying-Jun Angela Zhang']"
http://arxiv.org/abs/2005.07532v1,6G,2020-04-16T06:53:05Z,2020-04-16T06:53:05Z,6G Communication Technology: A Vision on Intelligent Healthcare,"  6G is a promising communication technology that will dominate the entire
health market from 2030 onward. It will dominate not only health sector but
also diverse sectors. It is expected that 6G will revolutionize many sectors
including healthcare. Healthcare will be fully AI-driven and dependent on 6G
communication technology, which will change our perception of lifestyle.
Currently, time and space are the key barriers to health care and 6G will be
able to overcome these barriers. Also, 6G will be proven as a game changing
technology for healthcare. Therefore, in this perspective, we envision
healthcare system for the era of 6G communication technology. Also, various new
methodologies have to be introduced to enhance our lifestyle, which is
addressed in this perspective, including Quality of Life (QoL), Intelligent
Wearable Devices (IWD), Intelligent Internet of Medical Things (IIoMT),
Hospital-to-Home (H2H) services, and new business model. In addition, we expose
the role of 6G communication technology in telesurgery, Epidemic and Pandemic.
","['Sabuzima Nayak', 'Ripon Patgiri']"
http://arxiv.org/abs/2107.05728v1,6G,2021-07-12T20:46:23Z,2021-07-12T20:46:23Z,Toward Efficient Transfer Learning in 6G,"  6G networks will greatly expand the support for data-oriented, autonomous
applications for over the top (OTT) and networking use cases. The success of
these use cases will depend on the availability of big data sets which is not
practical in many real scenarios due to the highly dynamic behavior of systems
and the cost of data collection procedures. Transfer learning (TL) is a
promising approach to deal with these challenges through the sharing of
knowledge among diverse learning algorithms. with TL, the learning rate and
learning accuracy can be considerably improved. However, there are
implementation challenges to efficiently deploy and utilize TL in 6G. In this
paper, we initiate this discussion by providing some performance metrics to
measure the TL success. Then, we show how infrastructure, application,
management, and training planes of 6G can be adapted to handle TL. We provide
examples of TL in 6G and highlight the spatio-temporal features of data in 6G
that can lead to efficient TL. By simulation results, we demonstrate how
transferring the quantized neural network weights between two use cases can
make a trade-off between overheads and performance and attain more efficient TL
in 6G. We also provide a list of future research directions in TL for 6G.
","['Saeedeh Parsaeefard', 'Alberto Leon-Garcia']"
http://arxiv.org/abs/2112.04698v2,6G,2021-12-09T04:46:31Z,2023-02-07T09:13:17Z,"Applications of Explainable AI for 6G: Technical Aspects, Use Cases, and
  Research Challenges","  When 5G began its commercialisation journey around 2020, the discussion on
the vision of 6G also surfaced. Researchers expect 6G to have higher bandwidth,
coverage, reliability, energy efficiency, lower latency, and an integrated
""human-centric"" network system powered by artificial intelligence (AI). Such a
6G network will lead to an excessive number of automated decisions made in
real-time. These decisions can range widely, from network resource allocation
to collision avoidance for self-driving cars. However, the risk of losing
control over decision-making may increase due to high-speed, data-intensive AI
decision-making beyond designers' and users' comprehension. The promising
explainable AI (XAI) methods can mitigate such risks by enhancing the
transparency of the black-box AI decision-making process. This paper surveys
the application of XAI towards the upcoming 6G age in every aspect, including
6G technologies (e.g., intelligent radio, zero-touch network management) and 6G
use cases (e.g., industry 5.0). Moreover, we summarised the lessons learned
from the recent attempts and outlined important research challenges in applying
XAI for 6G in the near future.
","['Shen Wang', 'M. Atif Qureshi', 'Luis Miralles-Pechuán', 'Thien Huynh-The', 'Thippa Reddy Gadekallu', 'Madhusanka Liyanage']"
http://arxiv.org/abs/2207.13382v3,6G,2022-07-27T09:11:05Z,2022-08-04T05:14:49Z,Exploration and Application of AI in 6G Field,"  The recent upsurge of diversified mobile applications, especially those
supported by AI, is spurring heated discussions on the future evolution of
wireless communications. While 5G is being deployed around the world, efforts
from industry and academia have started to look beyond 5G and conceptualize 6G.
We envision 6G to experience an unprecedented transformation that will make it
completely different from the previous generations of wireless systems. In
particular, 6G will go beyond mobile Internet and will be required to support
AI services. Meanwhile, AI will play a critical role in designing and
optimizing 6G architectures, protocols and operations. In this article, we
discuss the features of 6G, and the difficulties of carrying out 6G, and
AI-enabled methods for 6G network design and optimization.
","['Renhao Xue', 'Jialei Tan', 'Yutao Shi']"
http://arxiv.org/abs/2111.06596v1,6G,2021-11-12T08:13:49Z,2021-11-12T08:13:49Z,"Towards 6G Internet of Things: Recent Advances, Use Cases, and Open
  Challenges","  Smart services based on the Internet of Everything (IoE) are gaining
considerable popularity due to the ever-increasing demands of wireless
networks. This demands the appraisal of the wireless networks with enhanced
properties as next-generation communication systems. Although 5G networks show
great potential to support numerous IoE based services, it is not adequate to
meet the complete requirements of the new smart applications. Therefore, there
is an increased demand for envisioning the 6G wireless communication systems to
overcome the major limitations in the existing 5G networks. Moreover,
incorporating artificial intelligence in 6G will provide solutions for very
complex problems relevant to network optimization. Furthermore, to add further
value to the future 6G networks, researchers are investigating new
technologies, such as THz and quantum communications. The requirements of
future 6G wireless communications demand to support massive data-driven
applications and the increasing number of users. This paper presents recent
advances in the 6G wireless networks, including the evolution from 1G to 5G
communications, the research trends for 6G, enabling technologies, and
state-of-the-art 6G projects.
","['Zakria Qadir', 'Hafiz Suliman Munawar', 'Nasir Saeed', 'Khoa Le']"
http://arxiv.org/abs/2411.18836v1,6G,2024-11-28T00:53:35Z,2024-11-28T00:53:35Z,Perspectives on 6G Architectures,"  Mobile communications have been undergoing a generational change every ten
years. While 5G network deployments are maturing, significant efforts are being
made to standardize 6G, which is expected to be commercially introduced by
2030. This paper provides unique perspectives on the 6G network (radio and
core) architecture(s) from the anticipated 6G use cases to meet the necessary
performance requirements. To cater for the key 6G use cases, the 6G
architecture must integrate different network-level functions in a multiplicity
of virtual cloud environments, leveraging the advancements of distributed
processing, artificial intelligence, and securely integrating different
sub-networks e.g., terrestrial, and non-terrestrial networks into the overall
6G network. This paper characterizes the impact of 6G architectures from a
deployment perspective with backwards compatibility in mind.
","['Rainer Liebhart', 'Mansoor Shafi', 'Harsh Tataria', 'Gajan Shivanandan', 'Devaki Chandramouli']"
http://arxiv.org/abs/2203.13094v2,6G,2022-03-24T14:39:52Z,2022-05-20T12:32:12Z,"Six Insights into 6G: Orientation and Input for Developing Your
  Strategic 6G Research Plan","  This paper is a summary of the findings from a series of workshops which were
held by Thinknet 6G and MUENCHNER KREIS in 2021, with the goal to provide
orientation and input for developing a strategic 6G research plan. The topics
selected for the workshops are aspects of 6G that we expect will have a
significant impact on other industries and on society:
  - 6G as both a communication infrastructure and a sensing infrastructure
  - The extensive use of artificial intelligence in 6G
  - The security and resilience of 6G
  This paper does not go into the technical details of how to develop and
implement 6G. Rather, it provides input from experts from both the wireless
industry as well as from other sectors about (mostly) non-technical topics that
will need to be addressed in parallel with the technical developments, such as
new use cases, regulation, communication with the public, and cross-industry
cooperation.
  We have identified six areas that will have a significant impact on the
development and use of 6G, and that organizations must consider as they begin
their plans and designs for 6G. Based on these six impact areas and on the
discussion in the workshops, we compiled a list of the top 10 recommendations
for specific areas where organizations should place their focus when developing
their strategic plan for 6G. In addition, for our readers who are involved in
6G research, be it at a university, at a research institute or in industrial
research, we also included a summary of the top 10 areas that require
additional research, again based on the input received in the workshops.
  A version of this paper is also available at www.thinknet-6g.de.
  If you had a copy of the preview version of this paper, the text is exactly
the same. Only the layout and graphics have changed.
","['Kimberley Parsons Trommler', 'Matthias Hafner', 'Wolfgang Kellerer', 'Peter Merz', 'Sigurd Schuster', 'Josef Urban', 'Uwe Baeder', 'Bertram Gunzelmann', 'Andreas Kornbichler']"
http://arxiv.org/abs/2412.11366v1,6G,2024-12-16T01:43:58Z,2024-12-16T01:43:58Z,Towards 6G Network Slicing,"  Networks should connect communicating peers, supporting vertical services
requirements. The network evolution towards 6G requires native network slicing
techniques. Some literature approaches claim network slice realization, but
they do not convincingly address the deployment across multiple Autonomous
Systems. This work investigates the current 6G network slicing landscape,
presents some gaps, and introduces the concept of the recursive network slicing
between multiple Autonomous Systems, supported by the NASOR approach. This
innovative concept supports implementing new network services required by the
6G vision. This work also sheds light on the 6G requirements for network
slicing.
","['Rodrigo Moreira', 'Flávio de Oliveira Silva']"
http://arxiv.org/abs/2403.14699v2,Digital twin,2024-03-16T01:25:59Z,2024-03-26T02:24:23Z,Digital Twins: How Far from Ideas to Twins?,"  As a bridge from virtuality to reality, Digital Twin has increased in
popularity since proposed. Ideas have been proposed theoretical and practical
for digital twins. From theoretical perspective, digital twin is fusion of data
mapping between modalities; from practical point of view, digital twin is
scenario implementation based on the Internet of Things and models. From these
two perspectives, we explore the researches from idea to realization of digital
twins and discuss thoroughly.
",['Lu Jingyu']
http://arxiv.org/abs/2001.09747v1,Digital twin,2020-01-03T19:20:47Z,2020-01-03T19:20:47Z,Digital Twins,"  Digital Twins are one of the hottest digital trends. In this contribution we
will shortly review the concept of Digital Twins and the chances for novel
industrial applications. Mathematics are a key enabler and the impact will be
highlighted along four specific examples addressing Digital Product Twins
democratizing Design, Digital Production Twins enabling robots to mill, Digital
Production Twins driving industrialization of additive manufacturing, and
Digital Performance Twins boosting operations. We conclude the article with an
outlook on the next wave of Digital Twins, Executable Digital Twins, and will
review the associated challenges and opportunities for mathematics.
","['Dirk Hartmann', 'Herman van der Auweraer']"
http://arxiv.org/abs/2304.01093v1,Digital twin,2023-04-03T15:53:22Z,2023-04-03T15:53:22Z,"Demonstration of a Standalone, Descriptive, and Predictive Digital Twin
  of a Floating Offshore Wind Turbine","  Digital Twins bring several benefits for planning, operation, and maintenance
of remote offshore assets. In this work, we explain the digital twin concept
and the capability level scale in the context of wind energy. Furthermore, we
demonstrate a standalone digital twin, a descriptive digital twin, and a
prescriptive digital twin of an operational floating offshore wind turbine. The
standalone digital twin consists of the virtual representation of the wind
turbine and its operating environment. While at this level the digital twin
does not evolve with the physical turbine, it can be used during the planning-,
design-, and construction phases. At the next level, the descriptive digital
twin is built upon the standalone digital twin by enhancing the latter with
real data from the turbine. All the data is visualized in virtual reality for
informed decision-making. Besides being used for data bundling and
visualization, the descriptive digital twin forms the basis for diagnostic,
predictive, prescriptive, and autonomous tools. A predictive digital twin is
created through the use of weather forecasts, neural networks, and transfer
learning. Finally, digital twin technology is discussed in a much wider context
of ocean engineering.
","['Florian Stadtmann', 'Henrik Gusdal Wassertheurer', 'Adil Rasheed']"
http://arxiv.org/abs/2305.07244v2,Digital twin,2023-05-12T04:34:30Z,2023-06-13T08:59:12Z,"Digital Twin as a Service (DTaaS): A Platform for Digital Twin
  Developers and Users","  Establishing digital twins is a non-trivial endeavour especially when users
face significant challenges in creating them from scratch. Ready availability
of reusable models, data and tool assets, can help with creation and use of
digital twins. A number of digital twin frameworks exist to facilitate creation
and use of digital twins. In this paper we propose a digital twin framework to
author digital twin assets, create digital twins from reusable assets and make
the digital twins available as a service to other users. The proposed framework
automates the management of reusable assets, storage, provision of compute
infrastructure, communication and monitoring tasks. The users operate at the
level of digital twins and delegate rest of the work to the digital twin as a
service framework.
","['Prasad Talasila', 'Cláudio Gomes', 'Peter Høgh Mikkelsen', 'Santiago Gil Arboleda', 'Eduard Kamburjan', 'Peter Gorm Larsen']"
http://arxiv.org/abs/2109.08632v1,Digital twin,2021-09-17T16:34:33Z,2021-09-17T16:34:33Z,Graph Learning for Cognitive Digital Twins in Manufacturing Systems,"  Future manufacturing requires complex systems that connect simulation
platforms and virtualization with physical data from industrial processes.
Digital twins incorporate a physical twin, a digital twin, and the connection
between the two. Benefits of using digital twins, especially in manufacturing,
are abundant as they can increase efficiency across an entire manufacturing
life-cycle. The digital twin concept has become increasingly sophisticated and
capable over time, enabled by rises in many technologies. In this paper, we
detail the cognitive digital twin as the next stage of advancement of a digital
twin that will help realize the vision of Industry 4.0. Cognitive digital twins
will allow enterprises to creatively, effectively, and efficiently exploit
implicit knowledge drawn from the experience of existing manufacturing systems.
They also enable more autonomous decisions and control, while improving the
performance across the enterprise (at scale). This paper presents graph
learning as one potential pathway towards enabling cognitive functionalities in
manufacturing digital twins. A novel approach to realize cognitive digital
twins in the product design stage of manufacturing that utilizes graph learning
is presented.
","['Trier Mortlock', 'Deepan Muthirayan', 'Shih-Yuan Yu', 'Pramod P. Khargonekar', 'Mohammad A. Al Faruque']"
http://arxiv.org/abs/2410.02358v1,Digital twin,2024-10-03T10:14:21Z,2024-10-03T10:14:21Z,"Cross-Domain Comparative Analysis of Digital Twins and Universalised
  Solutions","  Digitalisation is one of the main drivers of most economic sectors nowadays
and the digital twin, as a reification of digitalisation for complex systems
has attracted much attention from both academics and industry. There have been
studies focusing on digital twins in a specific sector while there are few
exercising insightful comparisons of digital twins from different domains.
Considering the digital twinning is a cross-domain transformation, it is
beneficial to establish the principles of universality and variation that can
explain similarities and differences in any digital twins. This paper first
delivers a comparative analysis of digital twins in five domains through a
six-dimensional characterisation framework. Then, by departing from the
correlations among the domain-specific DT development, a cross-domain Digital
Twin Platform-as-a-Service (DT-PaaS) is proposed to universalise the common
process, tools and applications, meanwhile being inclusive of variations of
every digital twin instance. As a centralised data, modeling and service
platform, it is expected to break the barriers between domains by enabling the
cross-domain digital twin data sharing, interoperability and development
synergy and tackle some complex global challenges such as climate challenge,
net zero, pandemics, etc.
","['Guanyu Xiong', 'Yan Gao', 'Haijiang Li']"
http://arxiv.org/abs/2401.07985v1,Digital twin,2024-01-15T22:13:48Z,2024-01-15T22:13:48Z,"From Digital Twins to Digital Twin Prototypes: Concepts, Formalization,
  and Applications","  The transformation to Industry 4.0 also transforms the processes of how we
develop intelligent manufacturing production systems. To advance the software
development of these new (embedded) software systems, digital twins may be
employed. However, there is no consensual definition of what a digital twin is.
In this paper, we give an overview of the current state of the digital twin
concept and formalize the digital twin concept using the Object-Z notation.
This formalization includes the concepts of physical twins, digital models,
digital templates, digital threads, digital shadows, digital twins, and digital
twin prototypes. The relationships between all these concepts are visualized as
UML class diagrams.
  Our digital twin prototype (DTP) approach supports engineers during the
development and automated testing of complex embedded software systems. This
approach enable engineers to test embedded software systems in a virtual
context, without the need of a connection to a physical object. In continuous
integration / continuous deployment pipelines such digital twin prototypes can
be used for automated integration testing and, thus, allow for an agile
verification and validation process.
  In this paper, we demonstrate and report on how to apply and implement a
digital twin by the example of two real-world field studies (ocean observation
systems and smart farming). For independent replication and extension of our
approach by other researchers, we provide a lab study published open source on
GitHub.
","['Alexander Barbie', 'Wilhelm Hasselbring']"
http://arxiv.org/abs/2402.02252v1,Digital twin,2024-02-03T20:06:46Z,2024-02-03T20:06:46Z,"Collaboration of Digital Twins through Linked Open Data: Architecture
  with FIWARE as Enabling Technology","  The collaboration of the real world and the virtual world, known as Digital
Twin, has become a trend with numerous successful use cases. However, there are
challenges mentioned in the literature that must be addressed. One of the most
important issues is the difficulty of collaboration of Digital Twins due to the
lack of standardization in their implementation. This article continues a
previous work that proposed a generic architecture based on the FIWARE
components to build Digital Twins in any field. Our work proposes the use of
Linked Open Data as a mechanism to facilitate the communication of Digital
Twins. We validate our proposal with a use case of an urban Digital Twin that
collaborates with a parking Digital Twin. We conclude that Linked Open Data in
combination with the FIWARE ecosystem is a real reference option to deploy
Digital Twins and to enable the collaboration between Digital Twins.
","['Javier Conde', 'Andres Munoz-Arcentales', 'Álvaro Alonso', 'Gabriel Huecas', 'Joaquín Salvachúa']"
http://arxiv.org/abs/2403.07162v3,Digital twin,2024-03-11T21:06:13Z,2024-08-19T23:24:07Z,Digital Twin Evolution for Sustainable Smart Ecosystems,"  Smart ecosystems are the drivers of modern society. They control
infrastructures of socio-techno-economic importance, ensuring their stable and
sustainable operation. Smart ecosystems are governed by digital twins --
real-time virtual representations of physical infrastructure. To support the
open-ended and reactive traits of smart ecosystems, digital twins need to be
able to evolve in reaction to changing conditions. However, digital twin
evolution is challenged by the intertwined nature of physical and software
components, and their individual evolution. As a consequence, software
practitioners find a substantial body of knowledge on software evolution hard
to apply in digital twin evolution scenarios and a lack of knowledge on the
digital twin evolution itself. The aim of this paper, consequently, is to
provide software practitioners with tangible leads toward understanding and
managing the evolutionary concerns of digital twins. We use four distinct
digital twin evolution scenarios, contextualized in a citizen energy community
case to illustrate the usage of the 7R taxonomy of digital twin evolution. By
that, we aim to bridge a significant gap in leveraging software engineering
practices to develop robust smart ecosystems.
","['Judith Michael', 'Istvan David', 'Dominik Bork']"
http://arxiv.org/abs/2405.05301v2,Digital twin,2024-05-08T17:17:58Z,2024-06-16T22:26:50Z,"A design specification for Critical Illness Digital Twins to cure
  sepsis: responding to the National Academies of Sciences, Engineering and
  Medicine Report: Foundational Research Gaps and Future Directions for Digital
  Twins","  On December 15, 2023, The National Academies of Sciences, Engineering and
Medicine (NASEM) released a report entitled: Foundational Research Gaps and
Future Directions for Digital Twins. The ostensible purpose of this report was
to bring some structure to the burgeoning field of digital twins by providing a
working definition and a series of research challenges that need to be
addressed to allow this technology to fulfill its full potential. In the work
presented herein we focus on five specific findings from the NASEM Report: 1)
definition of a Digital Twin, 2) using fit-for-purpose guidance, 3) developing
novel approaches to Verification, Validation and Uncertainty Quantification
(VVUQ) of Digital Twins, 4) incorporating control as an explicit purpose for a
Digital Twin and 5) using a Digital Twin to guide data collection and sensor
development, and describe how these findings are addressed through the design
specifications for a Critical Illness Digital Twin (CIDT) aimed at curing
sepsis.
","['Gary An', 'Chase Cockrell']"
http://arxiv.org/abs/2407.11990v1,Digital twin,2024-06-06T14:51:01Z,2024-06-06T14:51:01Z,"Digital twins in sport: Concepts, Taxonomies, Challenges and Practical
  Potentials","  Digital twins belong to ten of the strategic technology trends according to
the Gartner list from 2019, and have encountered a big expansion, especially
with the introduction of Industry 4.0. Sport, on the other hand, has become a
constant companion of the modern human suffering a lack of a healthy way of
life. The application of digital twins in sport has brought dramatic changes
not only in the domain of sport training, but also in managing athletes during
competitions, searching for strategical solutions before and tactical solutions
during the games by coaches. In this paper, the domain of digital twins in
sport is reviewed based on papers which have emerged in this area. At first,
the concept of a digital twin is discussed in general. Then, taxonomies of
digital twins are appointed. According to these taxonomies, the collection of
relevant papers is analyzed, and some real examples of digital twins are
exposed. The review finishes with a discussion about how the digital twins
affect changes in the modern sport disciplines, and what challenges and
opportunities await the digital twins in the future.
","['Tilen Hliš', 'Iztok Fister', 'Iztok Fister Jr']"
http://arxiv.org/abs/2208.14197v2,Digital twin,2022-08-26T15:01:26Z,2022-09-30T13:26:30Z,"A Comprehensive Review of Digital Twin -- Part 1: Modeling and Twinning
  Enabling Technologies","  As an emerging technology in the era of Industry 4.0, digital twin is gaining
unprecedented attention because of its promise to further optimize process
design, quality control, health monitoring, decision and policy making, and
more, by comprehensively modeling the physical world as a group of
interconnected digital models. In a two-part series of papers, we examine the
fundamental role of different modeling techniques, twinning enabling
technologies, and uncertainty quantification and optimization methods commonly
used in digital twins. This first paper presents a thorough literature review
of digital twin trends across many disciplines currently pursuing this area of
research. Then, digital twin modeling and twinning enabling technologies are
further analyzed by classifying them into two main categories:
physical-to-virtual, and virtual-to-physical, based on the direction in which
data flows. Finally, this paper provides perspectives on the trajectory of
digital twin technology over the next decade, and introduces a few emerging
areas of research which will likely be of great use in future digital twin
research. In part two of this review, the role of uncertainty quantification
and optimization are discussed, a battery digital twin is demonstrated, and
more perspectives on the future of digital twin are shared.
","['Adam Thelen', 'Xiaoge Zhang', 'Olga Fink', 'Yan Lu', 'Sayan Ghosh', 'Byeng D. Youn', 'Michael D. Todd', 'Sankaran Mahadevan', 'Chao Hu', 'Zhen Hu']"
http://arxiv.org/abs/2503.02167v1,Digital twin,2025-03-04T01:13:31Z,2025-03-04T01:13:31Z,"Leveraging Large Language Models for Enhanced Digital Twin Modeling:
  Trends, Methods, and Challenges","  Digital twin technology is a transformative innovation driving the digital
transformation and intelligent optimization of manufacturing systems. By
integrating real-time data with computational models, digital twins enable
continuous monitoring, simulation, prediction, and optimization, effectively
bridging the gap between the physical and digital worlds. Recent advancements
in communication, computing, and control technologies have accelerated the
development and adoption of digital twins across various industries. However,
significant challenges remain, including limited data for accurate system
modeling, inefficiencies in system analysis, and a lack of explainability in
the interactions between physical and digital systems. The rise of large
language models (LLMs) offers new avenues to address these challenges. LLMs
have shown exceptional capabilities across diverse domains, exhibiting strong
generalization and emergent abilities that hold great potential for enhancing
digital twins. This paper provides a comprehensive review of recent
developments in LLMs and their applications to digital twin modeling. We
propose a unified description-prediction-prescription framework to integrate
digital twin modeling technologies and introduce a structured taxonomy to
categorize LLM functionalities in these contexts. For each stage of
application, we summarize the methodologies, identify key challenges, and
explore potential future directions. To demonstrate the effectiveness of
LLM-enhanced digital twins, we present an LLM-enhanced enterprise digital twin
system, which enables automatic modeling and optimization of an enterprise.
Finally, we discuss future opportunities and challenges in advancing
LLM-enhanced digital twins, offering valuable insights for researchers and
practitioners in related fields.
","['Linyao Yang', 'Shi Luo', 'Xi Cheng', 'Lei Yu']"
http://arxiv.org/abs/2203.12867v1,Digital twin,2022-03-24T06:20:59Z,2022-03-24T06:20:59Z,"Revisiting Digital Twins: Origins, Fundamentals and Practices","  The Digital Twins (DT) has quickly become a hot topic since it was proposed.
It not only appears in all kinds of commercial propaganda, but also is widely
quoted by academic circles. However, there are misstatements and misuse of the
term DT in business and academy. This paper revisits Digital Twins and defines
it to be a more advanced system/product/service modelling and simulation
environment that combines the most modern Information Communication Technology
(ICTs) and engineering mechanisms digitization, and characterized by
system/product/service life cycle management, physically geometric
visualization, real-time sensing and measurement of system operating
conditions, predictability of system performance/safety/lifespan, complete
engineering mechanisms-based simulations. The idea of Digital Twins originates
from modelling and simulation practices of engineering informatization,
including Virtual Manufacturing (VM), Model Predictive Control (MPC), and
Building Information Model (BIM). Based on the two-element VM model, we propose
a three-element model to represent Digital Twins. Digital Twins does not have
its own unique technical characteristics; the existing practices of Digital
Twins are extensions of the engineering informatization embracing modern ICTs.
These insights clarify the origin of Digital Twins and its technical
essentials.
","['Jiehan Zhou', 'Shouhua Zhang', 'Mu Gu']"
http://arxiv.org/abs/2107.09485v1,Digital twin,2021-07-19T14:26:15Z,2021-07-19T14:26:15Z,"Supply Chain Digital Twin Framework Design: An Approach of Supply Chain
  Operations Reference Model and System of Systems","  Digital twin technology has been regarded as a beneficial approach in supply
chain development. Different from traditional digital twin (temporal dynamic),
supply chain digital twin is a spatio-temporal dynamic system. This paper
explains what is 'twined' in supply chain digital twin and how to 'twin' them
to handle the spatio-temporal dynamic issue. A supply chain digital twin
framework is developed based on the theories of system of systems and supply
chain operations reference model. This framework is universal and can be
applied in various types of supply chain systems. We firstly decompose the
supply chain system into unified standard blocks preparing for the adoption of
digital twin. Next, the idea of supply chain operations reference model is
adopted to digitise basic supply chain activities within each block and explain
how to use existing information system. Then, individual sub-digital twin is
established for each member in supply chain system. After that, we apply the
concept of system of systems to integrate and coordinate sub-digital twin into
supply chain digital twin from the views of supply chain business integration
and information system integration. At last, one simple supply chain system is
applied to illustrate the application of the proposed model.
","['Jie Zhang', 'Alexandra Brintrup', 'Anisoara Calinescu', 'Edward Kosasih', 'Angira Sharma']"
http://arxiv.org/abs/2012.05841v3,Digital twin,2020-12-10T17:33:59Z,2021-04-13T16:47:53Z,"A Probabilistic Graphical Model Foundation for Enabling Predictive
  Digital Twins at Scale","  A unifying mathematical formulation is needed to move from one-off digital
twins built through custom implementations to robust digital twin
implementations at scale. This work proposes a probabilistic graphical model as
a formal mathematical representation of a digital twin and its associated
physical asset. We create an abstraction of the asset-twin system as a set of
coupled dynamical systems, evolving over time through their respective
state-spaces and interacting via observed data and control inputs. The formal
definition of this coupled system as a probabilistic graphical model enables us
to draw upon well-established theory and methods from Bayesian statistics,
dynamical systems, and control theory. The declarative and general nature of
the proposed digital twin model make it rigorous yet flexible, enabling its
application at scale in a diverse range of application areas. We demonstrate
how the model is instantiated to enable a structural digital twin of an
unmanned aerial vehicle (UAV). The digital twin is calibrated using
experimental data from a physical UAV asset. Its use in dynamic decision making
is then illustrated in a synthetic example where the UAV undergoes an in-flight
damage event and the digital twin is dynamically updated using sensor data. The
graphical model foundation ensures that the digital twin calibration and
updating process is principled, unified, and able to scale to an entire fleet
of digital twins.
","['Michael G. Kapteyn', 'Jacob V. R. Pretorius', 'Karen E. Willcox']"
http://arxiv.org/abs/2003.09370v1,Digital twin,2020-03-11T03:31:44Z,2020-03-11T03:31:44Z,"TiLA: Twin-in-the-Loop Architecture for Cyber-Physical Production
  Systems","  Digital twin is a virtual replica of a real-world object that lives
simultaneously with its physical counterpart. Since its first introduction in
2003 by Grieves, digital twin has gained momentum in a wide range of
applications such as industrial manufacturing, automotive and artificial
intelligence. However, many digital-twin-related approaches, found in
industries as well as literature, mainly focus on modelling individual physical
things with high-fidelity methods with limited scalability. In this paper, we
introduce a digital-twin architecture called TiLA (Twin-in-the-Loop
Architecture). TiLA employs heterogeneous models and online data to create a
digital twin, which follows a Globally Asynchronous Locally Synchronous (GALS)
model of computation. It facilitates the creation of a scalable digital twin
with different levels of modelling abstraction as well as giving GALS formalism
for execution strategy. Furthermore, TiLA provides facilities to develop
applications around the twin as well as an interface to synchronise the twin
with the physical system through an industrial communication protocol. A
digital twin for a manufacturing line has been developed as a case study using
TiLA. It demonstrates the use of digital twin models together with online data
for monitoring and analysing failures in the physical system.
","['Heejong Park', 'Arvind Easwaran', 'Sidharta Andalam']"
http://arxiv.org/abs/2409.17650v1,Digital twin,2024-09-26T08:56:54Z,2024-09-26T08:56:54Z,Digital Twin Ecosystem for Oncology Clinical Operations,"  Artificial Intelligence (AI) and Large Language Models (LLMs) hold
significant promise in revolutionizing healthcare, especially in clinical
applications. Simultaneously, Digital Twin technology, which models and
simulates complex systems, has gained traction in enhancing patient care.
However, despite the advances in experimental clinical settings, the potential
of AI and digital twins to streamline clinical operations remains largely
untapped. This paper introduces a novel digital twin framework specifically
designed to enhance oncology clinical operations. We propose the integration of
multiple specialized digital twins, such as the Medical Necessity Twin, Care
Navigator Twin, and Clinical History Twin, to enhance workflow efficiency and
personalize care for each patient based on their unique data. Furthermore, by
synthesizing multiple data sources and aligning them with the National
Comprehensive Cancer Network (NCCN) guidelines, we create a dynamic Cancer Care
Path, a continuously evolving knowledge base that enables these digital twins
to provide precise, tailored clinical recommendations.
","['Himanshu Pandey', 'Akhil Amod', ' Shivang', 'Kshitij Jaggi', 'Ruchi Garg', 'Abheet Jain', 'Vinayak Tantia']"
http://arxiv.org/abs/2112.01367v1,Digital twin,2021-11-05T12:28:10Z,2021-11-05T12:28:10Z,"Digital Twin-Assisted Controlling of AGVs in Flexible Manufacturing
  Environments","  Digital Twins are increasingly being introduced for smart manufacturing
systems to improve the efficiency of the main disciplines of such systems.
Formal techniques, such as graphs, are a common way of describing Digital Twin
models, allowing broad types of tools to provide Digital Twin based services
such as fault detection in production lines. Obtaining correct and complete
formal Digital Twins of physical systems can be a complicated and time
consuming process, particularly for manufacturing systems with plenty of
physical objects and the associated manufacturing processes. Automatic
generation of Digital Twins is an emerging research field and can reduce time
and costs. In this paper, we focus on the generation of Digital Twins for
flexible manufacturing systems with Automated Guided Vehicles (AGVs) on the
factory floor. In particular, we propose an architectural framework and the
associated design choices and software development tools that facilitate
automatic generation of Digital Twins for AGVs. Specifically, the scope of the
generated digital twins is controlling AGVs in the factory floor. To this end,
we focus on different control levels of AGVs and utilize graph theory to
generate the graph-based Digital Twin of the factory floor.
","['Mohammad Azangoo', 'Amir Taherkordi', 'Jan Olaf Blech', 'Valeriy Vyatkin']"
http://arxiv.org/abs/2311.05748v1,Digital twin,2023-11-09T21:24:12Z,2023-11-09T21:24:12Z,"Enabling Automated Integration Testing of Smart Farming Applications via
  Digital Twin Prototypes","  Industry 4.0 represents a major technological shift that has the potential to
transform the manufacturing industry, making it more efficient, productive, and
sustainable. Smart farming is a concept that involves the use of advanced
technologies to improve the efficiency and sustainability of agricultural
practices. Industry 4.0 and smart farming are closely related, as many of the
technologies used in smart farming are also used in Industry 4.0. Digital twins
have the potential for cost-effective software development of such
applications. With our Digital Twin Prototype approach, all sensor interfaces
are integrated into the development process, and their inputs and outputs of
the emulated hardware match those of the real hardware. The emulators respond
to the same commands and return identically formatted data packages as their
real counterparts, making the Digital Twin Prototype a valid source of a
digital shadow, i.e. the Digital Twin Prototype is a prototype of the physical
twin and can replace it for automated testing of the digital twin software. In
this paper, we present a case study for employing our Digital Twin Prototype
approach to automated testing of software for improving the making of silage
with a smart farming application. Besides automated testing with continuous
integration, we also discuss continuous deployment of modular Docker containers
in this context.
","['Alexander Barbie', 'Wilhelm Hasselbring', 'Malte Hansen']"
http://arxiv.org/abs/1706.04651v2,Spatial computing,2017-06-14T19:42:35Z,2017-07-31T21:33:45Z,Spatial Regression and the Bayesian Filter,"  Regression for spatially dependent outcomes poses many challenges, for
inference and for computation. Non-spatial models and traditional spatial
mixed-effects models each have their advantages and disadvantages, making it
difficult for practitioners to determine how to carry out a spatial regression
analysis. We discuss the data-generating mechanisms implicitly assumed by
various popular spatial regression models, and discuss the implications of
these assumptions. We propose Bayesian spatial filtering as an approximate
middle way between non-spatial models and traditional spatial mixed models. We
show by simulation that our Bayesian spatial filtering model has several
desirable properties and hence may be a useful addition to a spatial
statistician's toolkit.
",['John Hughes']
http://arxiv.org/abs/1601.03817v1,Spatial computing,2016-01-15T05:17:40Z,2016-01-15T05:17:40Z,"Entity-oriented spatial coding and discrete topological spatial
  relations","  Based on a newly proposed spatial data model - spatial chromatic model (SCM),
we developed a spatial coding scheme, called full-coded ordinary arranged
chromatic diagram (full-OACD). Full-OACD is a type of spatial tessellation,
where space is partitioned into a number of subspaces such as cells, edges, and
vertexes. These subspaces are called spatial particles and assigned with unique
codes - chromatic codes. The generation, structures, computations, and
properties of full-OACD are introduced and relations between chromatic codes
and particle spatial topology are investigated, indicating that chromatic codes
provide a potential useful and meaningful tool not only for spatial analysis in
geographical information science, but also for other relevant disciplines such
as discrete mathematics, topology, and computer science.
",['Weining Zhu']
http://arxiv.org/abs/2005.09981v2,Spatial computing,2020-05-20T11:53:10Z,2021-05-28T09:50:35Z,"Balancing spatial and non-spatial variation in varying coefficient
  modeling: a remedy for spurious correlation","  This study discusses the importance of balancing spatial and non-spatial
variation in spatial regression modeling. Unlike spatially varying coefficients
(SVC) modeling, which is popular in spatial statistics, non-spatially varying
coefficients (NVC) modeling has largely been unexplored in spatial fields.
Nevertheless, as we will explain, consideration of non-spatial variation is
needed not only to improve model accuracy but also to reduce spurious
correlation among varying coefficients, which is a major problem in SVC
modeling. We consider a Moran eigenvector approach modeling spatially and
non-spatially varying coefficients (S&NVC). A Monte Carlo simulation experiment
comparing our S&NVC model with existing SVC models suggests both modeling
accuracy and computational efficiency for our approach. Beyond that, somewhat
surprisingly, our approach identifies true and spurious correlations among
coefficients nearly perfectly, even when usual SVC models suffer from severe
spurious correlations. It implies that S&NVC model should be used even when the
analysis purpose is modeling SVCs. Finally, our S&NVC model is employed to
analyze a residential land price dataset. Its results suggest existence of both
spatial and non-spatial variation in regression coefficients in practice. The
S&NVC model is now implemented in the R package spmoran.
","['Daisuke Murakami', 'Daniel A. Griffith']"
http://arxiv.org/abs/1308.0399v1,Spatial computing,2013-08-02T03:46:33Z,2013-08-02T03:46:33Z,Spatial Process Generation,"  The generation of random spatial data on a computer is an important tool for
understanding the behavior of spatial processes. In this paper we describe how
to generate realizations from the main types of spatial processes, including
Gaussian and Markov random fields, point processes, spatial Wiener processes,
and Levy fields. Concrete MATLAB code is provided.
","['Dirk P. Kroese', 'Zdravko I. Botev']"
http://arxiv.org/abs/2411.06048v1,Spatial computing,2024-11-09T03:07:33Z,2024-11-09T03:07:33Z,"An Empirical Analysis on Spatial Reasoning Capabilities of Large
  Multimodal Models","  Large Multimodal Models (LMMs) have achieved strong performance across a
range of vision and language tasks. However, their spatial reasoning
capabilities are under-investigated. In this paper, we construct a novel VQA
dataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and
reasoning capabilities. Our analyses on object-relationship and multi-hop
reasoning reveal several important findings. Firstly, bounding boxes and scene
graphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning.
Secondly, LMMs struggle more with questions posed from the human perspective
than the camera perspective about the image. Thirdly, chain of thought (CoT)
prompting does not improve model performance on complex multi-hop questions
involving spatial relations. % Moreover, spatial reasoning steps are much less
accurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis
on GQA-spatial reveals that LMMs are much stronger at basic object detection
than complex spatial reasoning. We believe our benchmark dataset and in-depth
analyses can spark further research on LMMs spatial reasoning. Spatial-MM
benchmark is available at: https://github.com/FatemehShiri/Spatial-MM
","['Fatemeh Shiri', 'Xiao-Yu Guo', 'Mona Golestan Far', 'Xin Yu', 'Gholamreza Haffari', 'Yuan-Fang Li']"
http://arxiv.org/abs/2004.03352v3,Spatial computing,2020-04-07T13:27:02Z,2020-08-03T01:25:46Z,"GeoFlink: A Distributed and Scalable Framework for the Real-time
  Processing of Spatial Streams","  Apache Flink is an open-source system for scalable processing of batch and
streaming data. Flink does not natively support efficient processing of spatial
data streams, which is a requirement of many applications dealing with spatial
data. Besides Flink, other scalable spatial data processing platforms including
GeoSpark, Spatial Hadoop, etc. do not support streaming workloads and can only
handle static/batch workloads. To fill this gap, we present GeoFlink, which
extends Apache Flink to support spatial data types, indexes and continuous
queries over spatial data streams. To enable the efficient processing of
spatial continuous queries and for the effective data distribution across Flink
cluster nodes, a gird-based index is introduced. GeoFlink currently supports
spatial range, spatial $k$NN and spatial join queries on point data type. An
extensive experimental study on real spatial data streams shows that GeoFlink
achieves significantly higher query throughput than ordinary Flink processing.
","['Salman Ahmed Shaikh', 'Komal Mariam', 'Hiroyuki Kitagawa', 'Kyoung-Sook Kim']"
http://arxiv.org/abs/2007.09557v1,Spatial computing,2020-07-19T02:11:53Z,2020-07-19T02:11:53Z,From Spatial Relations to Spatial Configurations,"  Spatial Reasoning from language is essential for natural language
understanding. Supporting it requires a representation scheme that can capture
spatial phenomena encountered in language as well as in images and videos.
Existing spatial representations are not sufficient for describing spatial
configurations used in complex tasks. This paper extends the capabilities of
existing spatial representation languages and increases coverage of the
semantic aspects that are needed to ground the spatial meaning of natural
language text in the world. Our spatial relation language is able to represent
a large, comprehensive set of spatial concepts crucial for reasoning and is
designed to support the composition of static and dynamic spatial
configurations. We integrate this language with the Abstract Meaning
Representation(AMR) annotation schema and present a corpus annotated by this
extended AMR. To exhibit the applicability of our representation scheme, we
annotate text taken from diverse datasets and show how we extend the
capabilities of existing spatial representation languages with the fine-grained
decomposition of semantics and blend it seamlessly with AMRs of sentences and
discourse representations as a whole.
","['Soham Dan', 'Parisa Kordjamshidi', 'Julia Bonn', 'Archna Bhatia', 'Jon Cai', 'Martha Palmer', 'Dan Roth']"
http://arxiv.org/abs/1804.05521v1,Spatial computing,2018-04-16T07:01:00Z,2018-04-16T07:01:00Z,SpatEntropy: Spatial Entropy Measures in R,"  This article illustrates how to measure the heterogeneity of spatial data
presenting a finite number of categories via computation of spatial entropy.
The R package SpatEntropy contains functions for the computation of entropy and
spatial entropy measures. The extension to spatial entropy measures is a unique
feature of SpatEntropy. In addition to the traditional version of Shannon's
entropy, the package includes Batty's spatial entropy, O'Neill's entropy, Li
and Reynolds' contagion index, Karlstrom and Ceccato's entropy, Leibovici's
entropy, Parresol and Edwards' entropy and Altieri's entropy. The package is
able to work with both areal and point data. This paper is a general
description of SpatEntropy, as well as its necessary theoretical background,
and an introduction for new users.
","['Linda Altieri', 'Daniela Cocchi', 'Giulia Roli']"
http://arxiv.org/abs/2010.07266v1,Spatial computing,2020-10-14T17:47:20Z,2020-10-14T17:47:20Z,Spatial-Slepian Transform on the Sphere,"  We present spatial-Slepian transform~(SST) for the representation of signals
on the sphere to support localized signal analysis. We use well-optimally
concentrated Slepian functions, obtained by solving the Slepian
spatial-spectral concentration problem of finding bandlimited and spatially
optimally concentrated functions on the sphere, to formulate the proposed
transform and obtain the joint spatial-Slepian domain representation of the
signal. Due to the optimal energy concentration of the Slepian functions in the
spatial domain, the proposed spatial-Slepian transform allows us to probe
spatially localized content of the signal. Furthermore, we present an inverse
transform to recover the signal from the spatial-Slepian coefficients, and show
that well-optimally concentrated rotated Slepian functions form a tight frame
on the sphere. We develop an algorithm for the fast computation of the
spatial-Slepian transform and carry out computational complexity analysis. We
present the formulation of SST for zonal Slepian functions, which are spatially
optimally concentrated in the polar cap~(axisymmetric) region, and provide an
illustration using the Earth topography map. To demonstrate the utility of the
proposed transform, we carry out localized variation analysis; employing SST
for detecting hidden localized variations in the signal.
","['Adeem Aslam', 'Zubair Khalid']"
http://arxiv.org/abs/2504.08061v1,Spatial computing,2025-04-10T18:32:56Z,2025-04-10T18:32:56Z,"STEI-PCN: an efficient pure convolutional network for traffic prediction
  via spatial-temporal encoding and inferring","  Traffic data exhibits complex temporal, spatial, and spatial-temporal
correlations. Most of models use either independent modules to separately
extract temporal and spatial correlations or joint modules to synchronously
extract them, without considering the spatial-temporal correlations. Moreover,
models that consider joint spatial-temporal correlations (temporal, spatial,
and spatial-temporal correlations) often encounter significant challenges in
accuracy and computational efficiency which prevent such models from
demonstrating the expected advantages of a joint spatial-temporal correlations
architecture. To address these issues, this paper proposes an efficient pure
convolutional network for traffic prediction via spatial-temporal encoding and
inferring (STEI-PCN). The model introduces and designs a dynamic adjacency
matrix inferring module based on absolute spatial and temporal coordinates, as
well as relative spatial and temporal distance encoding, using a graph
convolutional network combined with gating mechanism to capture local
synchronous joint spatial-temporal correlations. Additionally, three layers of
temporal dilated causal convolutional network are used to capture long-range
temporal correlations. Finally, through multi-view collaborative prediction
module, the model integrates the gated-activated original, local synchronous
joint spatial-temporal, and long-range temporal features to achieve
comprehensive prediction. This study conducts extensive experiments on flow
datasets (PeMS03/04/07/08) and speed dataset (PeMS-Bay), covering multiple
prediction horizons. The results show that STEI-PCN demonstrates competitive
computational efficiency in both training and inference speeds, and achieves
superior or slightly inferior to state-of-the-art (SOTA) models on most
evaluation metrics.
","['Kai Hu', 'Zhidan Zhao', 'Zhifeng Hao']"
http://arxiv.org/abs/1910.06484v1,Spatial computing,2019-10-15T02:19:19Z,2019-10-15T02:19:19Z,"Spatial Data Science: Closing the human-spatial computing-environment
  loop","  Over the last decade, the term spatial computing has grown to have two
different, though not entirely unrelated, definitions. The first definition of
spatial computing stems from industry, where it refers primarily to new kinds
of augmented, virtual, mixed-reality, and natural user interface technologies.
A second definition coming out of academia takes a broader perspective that
includes active research in geographic information science as well as the
aforementioned novel UI technologies. Both senses reflect an ongoing shift
toward increased interaction with computing interfaces and sensors embedded in
the environment and how the use of these technologies influence how we behave
and make sense of and even change the world we live in. Regardless of the
definition, research in spatial computing is humming along nicely without the
need to identify new research agendas or new labels for communities of
researchers. However, as a field of research, it could be helpful to view
spatial data science as the glue that coheres spatial computing with
problem-solving and learning in the real world into a more holistic discipline.
",['Benjamin Adams']
http://arxiv.org/abs/2006.00595v2,Spatial computing,2020-05-31T19:43:42Z,2021-02-15T02:07:12Z,"Spatial Factor Modeling: A Bayesian Matrix-Normal Approach for
  Misaligned Data","  Multivariate spatially-oriented data sets are prevalent in the environmental
and physical sciences. Scientists seek to jointly model multiple variables,
each indexed by a spatial location, to capture any underlying spatial
association for each variable and associations among the different dependent
variables. Multivariate latent spatial process models have proved effective in
driving statistical inference and rendering better predictive inference at
arbitrary locations for the spatial process. High-dimensional multivariate
spatial data, which is the theme of this article, refers to data sets where the
number of spatial locations and the number of spatially dependent variables is
very large. The field has witnessed substantial developments in scalable models
for univariate spatial processes, but such methods for multivariate spatial
processes, especially when the number of outcomes are moderately large, are
limited in comparison. Here, we extend scalable modeling strategies for a
single process to multivariate processes. We pursue Bayesian inference which is
attractive for full uncertainty quantification of the latent spatial process.
Our approach exploits distribution theory for the Matrix-Normal distribution,
which we use to construct scalable versions of a hierarchical linear model of
coregionalization (LMC) and spatial factor models that deliver inference over a
high-dimensional parameter space including the latent spatial process. We
illustrate the computational and inferential benefits of our algorithms over
competing methods using simulation studies and an analysis of a massive
vegetation index data set.
","['Lu Zhang', 'Sudipto Banerjee']"
http://arxiv.org/abs/2406.07050v1,Spatial computing,2024-06-11T08:26:42Z,2024-06-11T08:26:42Z,"DualMamba: A Lightweight Spectral-Spatial Mamba-Convolution Network for
  Hyperspectral Image Classification","  The effectiveness and efficiency of modeling complex spectral-spatial
relations are both crucial for Hyperspectral image (HSI) classification. Most
existing methods based on CNNs and transformers still suffer from heavy
computational burdens and have room for improvement in capturing the
global-local spectral-spatial feature representation. To this end, we propose a
novel lightweight parallel design called lightweight dual-stream
Mamba-convolution network (DualMamba) for HSI classification. Specifically, a
parallel lightweight Mamba and CNN block are first developed to extract global
and local spectral-spatial features. First, the cross-attention
spectral-spatial Mamba module is proposed to leverage the global modeling of
Mamba at linear complexity. Within this module, dynamic positional embedding is
designed to enhance the spatial location information of visual sequences. The
lightweight spectral/spatial Mamba blocks comprise an efficient scanning
strategy and a lightweight Mamba design to efficiently extract global
spectral-spatial features. And the cross-attention spectral-spatial fusion is
designed to learn cross-correlation and fuse spectral-spatial features. Second,
the lightweight spectral-spatial residual convolution module is proposed with
lightweight spectral and spatial branches to extract local spectral-spatial
features through residual learning. Finally, the adaptive global-local fusion
is proposed to dynamically combine global Mamba features and local convolution
features for a global-local spectral-spatial representation. Compared with
state-of-the-art HSI classification methods, experimental results demonstrate
that DualMamba achieves significant classification accuracy on three public HSI
datasets and a superior reduction in model parameters and floating point
operations (FLOPs).
","['Jiamu Sheng', 'Jingyi Zhou', 'Jiong Wang', 'Peng Ye', 'Jiayuan Fan']"
http://arxiv.org/abs/1506.04929v1,Spatial computing,2015-06-16T11:52:50Z,2015-06-16T11:52:50Z,"ASPMT(QS): Non-Monotonic Spatial Reasoning with Answer Set Programming
  Modulo Theories","  The systematic modelling of \emph{dynamic spatial systems} [9] is a key
requirement in a wide range of application areas such as comonsense cognitive
robotics, computer-aided architecture design, dynamic geographic information
systems. We present ASPMT(QS), a novel approach and fully-implemented prototype
for non-monotonic spatial reasoning ---a crucial requirement within dynamic
spatial systems-- based on Answer Set Programming Modulo Theories (ASPMT).
ASPMT(QS) consists of a (qualitative) spatial representation module (QS) and a
method for turning tight ASPMT instances into Sat Modulo Theories (SMT)
instances in order to compute stable models by means of SMT solvers. We
formalise and implement concepts of default spatial reasoning and spatial frame
axioms using choice formulas. Spatial reasoning is performed by encoding
spatial relations as systems of polynomial constraints, and solving via SMT
with the theory of real nonlinear arithmetic. We empirically evaluate ASPMT(QS)
in comparison with other prominent contemporary spatial reasoning systems. Our
results show that ASPMT(QS) is the only existing system that is capable of
reasoning about indirect spatial effects (i.e. addressing the ramification
problem), and integrating geometric and qualitative spatial information within
a non-monotonic spatial reasoning context.
","['Przemysław Andrzej Wałęga', 'Mehul Bhatt', 'Carl Schultz']"
http://arxiv.org/abs/1908.10917v1,Spatial computing,2019-08-28T19:32:00Z,2019-08-28T19:32:00Z,"SpatialNLI: A Spatial Domain Natural Language Interface to Databases
  Using Spatial Comprehension","  A natural language interface (NLI) to databases is an interface that
translates a natural language question to a structured query that is executable
by database management systems (DBMS). However, an NLI that is trained in the
general domain is hard to apply in the spatial domain due to the idiosyncrasy
and expressiveness of the spatial questions. Inspired by the machine
comprehension model, we propose a spatial comprehension model that is able to
recognize the meaning of spatial entities based on the semantics of the
context. The spatial semantics learned from the spatial comprehension model is
then injected to the natural language question to ease the burden of capturing
the spatial-specific semantics. With our spatial comprehension model and
information injection, our NLI for the spatial domain, named SpatialNLI, is
able to capture the semantic structure of the question and translate it to the
corresponding syntax of an executable query accurately. We also experimentally
ascertain that SpatialNLI outperforms state-of-the-art methods.
","['Jingjing Li', 'Wenlu Wang', 'Wei-Shinn Ku', 'Yingtao Tian', 'Haixun Wang']"
http://arxiv.org/abs/1911.01202v2,Spatial computing,2019-10-22T03:07:58Z,2019-11-05T01:54:51Z,"Asymptotic expansion approximation for spatial structure arising from
  directionally biased movement","  Spatial structure can arise in spatial point process models via a range of
mechanisms, including neighbour-dependent directionally biased movement. This
spatial structure is neglected by mean-field models, but can have important
effects on population dynamics. Spatial moment dynamics are one way to obtain a
deterministic approximation of a dynamic spatial point process that retains
some information about spatial structure. However, the applicability of this
approach is limited by the computational cost of numerically solving spatial
moment dynamic equations at a sufficient resolution. We present an asymptotic
expansion for the equilibrium solution to the spatial moment dynamics equations
in the presence of neighbour-dependent directional bias. We show that the
asymptotic expansion provides a highly efficient scheme for obtaining
approximate equilibrium solutions to the spatial moment dynamics equations when
bias is weak. This scheme will be particularly useful for performing parameter
inference on spatial moment models.
",['Michael J Plank']
http://arxiv.org/abs/2207.05064v1,Spatial computing,2022-07-09T19:21:00Z,2022-07-09T19:21:00Z,"Adaptive Graph Spatial-Temporal Transformer Network for Traffic Flow
  Forecasting","  Traffic flow forecasting on graphs has real-world applications in many
fields, such as transportation system and computer networks. Traffic
forecasting can be highly challenging due to complex spatial-temporal
correlations and non-linear traffic patterns. Existing works mostly model such
spatial-temporal dependencies by considering spatial correlations and temporal
correlations separately and fail to model the direct spatial-temporal
correlations. Inspired by the recent success of transformers in the graph
domain, in this paper, we propose to directly model the cross-spatial-temporal
correlations on the spatial-temporal graph using local multi-head
self-attentions. To reduce the time complexity, we set the attention receptive
field to the spatially neighboring nodes, and we also introduce an adaptive
graph to capture the hidden spatial-temporal dependencies. Based on these
attention mechanisms, we propose a novel Adaptive Graph Spatial-Temporal
Transformer Network (ASTTN), which stacks multiple spatial-temporal attention
layers to apply self-attention on the input graph, followed by linear layers
for predictions. Experimental results on public traffic network datasets,
METR-LA PEMS-BAY, PeMSD4, and PeMSD7, demonstrate the superior performance of
our model.
","['Aosong Feng', 'Leandros Tassiulas']"
http://arxiv.org/abs/2310.18550v1,Spatial computing,2023-10-28T00:41:35Z,2023-10-28T00:41:35Z,"MultiScale Spectral-Spatial Convolutional Transformer for Hyperspectral
  Image Classification","  Due to the powerful ability in capturing the global information, Transformer
has become an alternative architecture of CNNs for hyperspectral image
classification. However, general Transformer mainly considers the global
spectral information while ignores the multiscale spatial information of the
hyperspectral image. In this paper, we propose a multiscale spectral-spatial
convolutional Transformer (MultiscaleFormer) for hyperspectral image
classification. First, the developed method utilizes multiscale spatial patches
as tokens to formulate the spatial Transformer and generates multiscale spatial
representation of each band in each pixel. Second, the spatial representation
of all the bands in a given pixel are utilized as tokens to formulate the
spectral Transformer and generate the multiscale spectral-spatial
representation of each pixel. Besides, a modified spectral-spatial CAF module
is constructed in the MultiFormer to fuse cross-layer spectral and spatial
information. Therefore, the proposed MultiFormer can capture the multiscale
spectral-spatial information and provide better performance than most of other
architectures for hyperspectral image classification. Experiments are conducted
over commonly used real-world datasets and the comparison results show the
superiority of the proposed method.
","['Zhiqiang Gong', 'Xian Zhou', 'Wen Yao']"
http://arxiv.org/abs/2311.17340v1,Spatial computing,2023-11-29T03:38:56Z,2023-11-29T03:38:56Z,"Cross-Scope Spatial-Spectral Information Aggregation for Hyperspectral
  Image Super-Resolution","  Hyperspectral image super-resolution has attained widespread prominence to
enhance the spatial resolution of hyperspectral images. However,
convolution-based methods have encountered challenges in harnessing the global
spatial-spectral information. The prevailing transformer-based methods have not
adequately captured the long-range dependencies in both spectral and spatial
dimensions. To alleviate this issue, we propose a novel cross-scope
spatial-spectral Transformer (CST) to efficiently investigate long-range
spatial and spectral similarities for single hyperspectral image
super-resolution. Specifically, we devise cross-attention mechanisms in spatial
and spectral dimensions to comprehensively model the long-range
spatial-spectral characteristics. By integrating global information into the
rectangle-window self-attention, we first design a cross-scope spatial
self-attention to facilitate long-range spatial interactions. Then, by
leveraging appropriately characteristic spatial-spectral features, we construct
a cross-scope spectral self-attention to effectively capture the intrinsic
correlations among global spectral bands. Finally, we elaborate a concise
feed-forward neural network to enhance the feature representation capacity in
the Transformer structure. Extensive experiments over three hyperspectral
datasets demonstrate that the proposed CST is superior to other
state-of-the-art methods both quantitatively and visually. The code is
available at \url{https://github.com/Tomchenshi/CST.git}.
","['Shi Chen', 'Lefei Zhang', 'Liangpei Zhang']"
http://arxiv.org/abs/2401.10044v2,Spatial computing,2024-01-18T15:08:42Z,2024-03-10T16:37:32Z,"Deep spatial context: when attention-based models meet spatial
  regression","  We propose 'Deep spatial context' (DSCon) method, which serves for
investigation of the attention-based vision models using the concept of spatial
context. It was inspired by histopathologists, however, the method can be
applied to various domains. The DSCon allows for a quantitative measure of the
spatial context's role using three Spatial Context Measures: $SCM_{features}$,
$SCM_{targets}$, $SCM_{residuals}$ to distinguish whether the spatial context
is observable within the features of neighboring regions, their target values
(attention scores) or residuals, respectively. It is achieved by integrating
spatial regression into the pipeline. The DSCon helps to verify research
questions. The experiments reveal that spatial relationships are much bigger in
the case of the classification of tumor lesions than normal tissues. Moreover,
it turns out that the larger the size of the neighborhood taken into account
within spatial regression, the less valuable contextual information is.
Furthermore, it is observed that the spatial context measure is the largest
when considered within the feature space as opposed to the targets and
residuals.
","['Paulina Tomaszewska', 'Elżbieta Sienkiewicz', 'Mai P. Hoang', 'Przemysław Biecek']"
http://arxiv.org/abs/1811.03479v3,WebAssembly,2018-11-08T15:04:20Z,2019-07-13T20:54:07Z,A Program Logic for First-Order Encapsulated WebAssembly,"  We introduce Wasm Logic, a sound program logic for first-order, encapsulated
WebAssembly. We design a novel assertion syntax, tailored to WebAssembly's
stack-based semantics and the strong guarantees given by WebAssembly's type
system, and show how to adapt the standard separation logic triple and proof
rules in a principled way to capture WebAssembly's uncommon structured control
flow. Using Wasm Logic, we specify and verify a simple WebAssembly B-tree
library, giving abstract specifications independent of the underlying
implementation. We mechanise Wasm Logic and its soundness proof in full in
Isabelle/HOL. As part of the soundness proof, we formalise and fully mechanise
a novel, big-step semantics of WebAssembly, which we prove equivalent, up to
transitive closure, to the original WebAssembly small-step semantics. Wasm
Logic is the first program logic for WebAssembly, and represents a first step
towards the creation of static analysis tools for WebAssembly.
","['Conrad Watt', 'Petar Maksimović', 'Neelakantan R. Krishnaswami', 'Philippa Gardner']"
http://arxiv.org/abs/2109.01386v1,WebAssembly,2021-09-03T09:11:08Z,2021-09-03T09:11:08Z,"Vivienne: Relational Verification of Cryptographic Implementations in
  WebAssembly","  This paper explores the use of relational symbolic execution to counter
timing side channels in WebAssembly programs. We design and implement Vivienne,
an open-source tool to automatically analyze WebAssembly cryptographic
libraries for constant-time violations. Our approach features various
optimizations that leverage the structure of WebAssembly and automated theorem
provers, including support for loops via relational invariants. We evaluate
Vivienne on 57 real-world cryptographic implementations, including a previously
unverified implementation of the HACL* library in WebAssembly. The results
indicate that Vivienne is a practical solution for constant-time analysis of
cryptographic libraries in WebAssembly.
","['Rodothea Myrsini Tsoupidi', 'Musard Balliu', 'Benoit Baudry']"
http://arxiv.org/abs/2404.03171v1,WebAssembly,2024-04-04T03:03:38Z,2024-04-04T03:03:38Z,Multi-modal Learning for WebAssembly Reverse Engineering,"  The increasing adoption of WebAssembly (Wasm) for performance-critical and
security-sensitive tasks drives the demand for WebAssembly program
comprehension and reverse engineering. Recent studies have introduced machine
learning (ML)-based WebAssembly reverse engineering tools. Yet, the
generalization of task-specific ML solutions remains challenging, because their
effectiveness hinges on the availability of an ample supply of high-quality
task-specific labeled data. Moreover, previous works overlook the high-level
semantics present in source code and its documentation. Acknowledging the
abundance of available source code with documentation, which can be compiled
into WebAssembly, we propose to learn representations of them concurrently and
harness their mutual relationships for effective WebAssembly reverse
engineering.
  In this paper, we present WasmRev, the first multi-modal pre-trained language
model for WebAssembly reverse engineering. WasmRev is pre-trained using
self-supervised learning on a large-scale multi-modal corpus encompassing
source code, code documentation and the compiled WebAssembly, without requiring
labeled data. WasmRev incorporates three tailored multi-modal pre-training
tasks to capture various characteristics of WebAssembly and cross-modal
relationships. WasmRev is only trained once to produce general-purpose
representations that can broadly support WebAssembly reverse engineering tasks
through few-shot fine-tuning with much less labeled data, improving data
efficiency. We fine-tune WasmRev onto three important reverse engineering
tasks: type recovery, function purpose identification and WebAssembly
summarization. Our results show that WasmRev pre-trained on the corpus of
multi-modal samples establishes a robust foundation for these tasks, achieving
high task accuracy and outperforming the state-of-the-art ML methods for
WebAssembly reverse engineering.
","['Hanxian Huang', 'Jishen Zhao']"
http://arxiv.org/abs/2407.12297v1,WebAssembly,2024-07-17T03:37:28Z,2024-07-17T03:37:28Z,WebAssembly and Security: a review,"  WebAssembly is revolutionizing the approach to developing modern
applications. Although this technology was born to create portable and
performant modules in web browsers, currently, its capabilities are extensively
exploited in multiple and heterogeneous use-case scenarios. With the extensive
effort of the community, new toolkits make the use of this technology more
suitable for real-world applications. In this context, it is crucial to study
the liaisons between the WebAssembly ecosystem and software security. Indeed,
WebAssembly can be a medium for improving the security of a system, but it can
also be exploited to evade detection systems or for performing cryptomining
activities. In addition, programs developed in low-level languages such as C
can be compiled in WebAssembly binaries, and it is interesting to evaluate the
security impacts of executing programs vulnerable to attacks against memory in
the WebAssembly sandboxed environment. Also, WebAssembly has been designed to
provide a secure and isolated environment, but such capabilities should be
assessed in order to analyze their weaknesses and propose new mechanisms for
addressing them. Although some research works have provided surveys of the most
relevant solutions aimed at discovering WebAssembly vulnerabilities or
detecting attacks, at the time of writing, there is no comprehensive review of
security-related literature in the WebAssembly ecosystem. We aim to fill this
gap by proposing a comprehensive review of research works dealing with security
in WebAssembly. We analyze 121 papers by identifying seven different security
categories.
  We hope that our work will provide insights into the complex landscape of
WebAssembly and guide researchers, developers, and security professionals
towards novel avenues in the realm of the WebAssembly ecosystem.
","['Gaetano Perrone', 'Simon Pietro Romano']"
http://arxiv.org/abs/2412.20258v1,WebAssembly,2024-12-28T20:24:41Z,2024-12-28T20:24:41Z,"Reusing Legacy Code in WebAssembly: Key Challenges of Cross-Compilation
  and Code Semantics Preservation","  WebAssembly (Wasm) has emerged as a powerful technology for executing
high-performance code and reusing legacy code in web browsers. With its
increasing adoption, ensuring the reliability of WebAssembly code becomes
paramount. In this paper, we investigate how well WebAssembly compilers fulfill
code reusability. Specifically, we inquire (1) what challenges arise when
cross-compiling a high-level language codebase into WebAssembly and (2) how
faithfully WebAssembly compilers preserve code semantics in this new binary.
Through a study on 115 open-source codebases, we identify the key challenges in
cross-compiling legacy C/C++ code into WebAssembly, highlighting the risks of
silent miscompilation and compile-time errors. We categorize these challenges
based on their root causes and propose corresponding solutions. We then
introduce a differential testing approach, implemented in a framework named
WasmChecker, to investigate the semantics equivalency of code between native
x86-64 and WebAssembly binaries. Using WasmChecker, we provide a witness that
WebAssembly compilers do not necessarily preserve code semantics when
cross-compiling high-level language code into WebAssembly due to different
implementations of standard libraries, unsupported system calls/APIs,
WebAssembly's unique features, and compiler bugs. Furthermore, we have
identified 11 new bugs in the Emscripten compiler toolchain, all confirmed by
Emscripten developers. As proof of concept, we make our framework and the
collected dataset of open-source codebases publicly available.
","['Sara Baradaran', 'Liyan Huang', 'Mukund Raghothaman', 'Weihang Wang']"
http://arxiv.org/abs/2110.15433v1,WebAssembly,2021-10-28T20:48:25Z,2021-10-28T20:48:25Z,"Fuzzm: Finding Memory Bugs through Binary-Only Instrumentation and
  Fuzzing of WebAssembly","  WebAssembly binaries are often compiled from memory-unsafe languages, such as
C and C++. Because of WebAssembly's linear memory and missing protection
features, e.g., stack canaries, source-level memory vulnerabilities are
exploitable in compiled WebAssembly binaries, sometimes even more easily than
in native code. This paper addresses the problem of detecting such
vulnerabilities through the first binary-only fuzzer for WebAssembly. Our
approach, called Fuzzm, combines canary instrumentation to detect overflows and
underflows on the stack and the heap, an efficient coverage instrumentation, a
WebAssembly VM, and the input generation algorithm of the popular AFL fuzzer.
Besides as an oracle for fuzzing, our canaries also serve as a stand-alone
binary hardening technique to prevent the exploitation of vulnerable binaries
in production. We evaluate Fuzzm with 28 real-world WebAssembly binaries, some
compiled from source and some found in the wild without source code. The fuzzer
explores thousands of execution paths, triggers dozens of crashes, and performs
hundreds of program executions per second. When used for binary hardening, the
approach prevents previously published exploits against vulnerable WebAssembly
binaries while imposing low runtime overhead.
","['Daniel Lehmann', 'Martin Toldam Torp', 'Michael Pradel']"
http://arxiv.org/abs/2401.05943v2,WebAssembly,2024-01-11T14:28:13Z,2024-03-22T13:28:21Z,SoK: Analysis techniques for WebAssembly,"  WebAssembly is a low-level bytecode language that allows high-level languages
like C, C++, and Rust to be executed in the browser at near-native performance.
In recent years, WebAssembly has gained widespread adoption is now natively
supported by all modern browsers. However, vulnerabilities in memory-unsafe
languages, like C and C++, can translate into vulnerabilities in WebAssembly
binaries. Unfortunately, most WebAssembly binaries are compiled from such
memory-unsafe languages, and these vulnerabilities have been shown to be
practical in real-world scenarios. WebAssembly smart contracts have also been
found to be vulnerable, causing significant financial loss. Additionally,
WebAssembly has been used for malicious purposes like cryptojacking. To address
these issues, several analysis techniques for WebAssembly binaries have been
proposed. In this paper, we conduct a comprehensive literature review of these
techniques and categorize them based on their analysis strategy and objectives.
Furthermore, we compare and evaluate the techniques using quantitative data,
highlighting their strengths and weaknesses. In addition, one of the main
contributions of this paper is the identification of future research directions
based on the thorough literature review conducted.
","['Håkon Harnes', 'Donn Morrison']"
http://arxiv.org/abs/2303.09623v1,WebAssembly,2023-03-16T19:55:47Z,2023-03-16T19:55:47Z,Wasmizer: Curating WebAssembly-driven Projects on GitHub,"  WebAssembly has attracted great attention as a portable compilation target
for programming languages. To facilitate in-depth studies about this
technology, we have deployed Wasmizer, a tool that regularly mines GitHub
projects and makes an up-to-date dataset of WebAssembly sources and their
binaries publicly available. Presently, we have collected 2 540 C and C++
projects that are highly-related to WebAssembly, and built a dataset of 8 915
binaries that are linked to their source projects. To demonstrate an
application of this dataset, we have investigated the presence of eight
WebAssembly compilation smells in the wild.
","['Alexander Nicholson', 'Quentin Stiévenart', 'Arash Mazidi', 'Mohammad Ghafari']"
http://arxiv.org/abs/2010.01723v1,WebAssembly,2020-10-05T00:09:01Z,2020-10-05T00:09:01Z,Wasm/k: Delimited Continuations for WebAssembly,"  WebAssembly is designed to be an alternative to JavaScript that is a safe,
portable, and efficient compilation target for a variety of languages. The
performance of high-level languages depends not only on the underlying
performance of WebAssembly, but also on the quality of the generated
WebAssembly code. In this paper, we identify several features of high-level
languages that current approaches can only compile to WebAssembly by generating
complex and inefficient code. We argue that these problems could be addressed
if WebAssembly natively supported first-class continuations. We then present
Wasm/k, which extends WebAssembly with delimited continuations. Wasm/k
introduces no new value types, and thus does not require significant changes to
the WebAssembly type system (validation). Wasm/k is safe, even in the presence
of foreign function calls (e.g., to and from JavaScript). Finally, Wasm/k is
amenable to efficient implementation: we implement Wasm/k as a local change to
Wasmtime, an existing WebAssembly JIT. We evaluate Wasm/k by implementing C/k,
which adds delimited continuations to C/C++. C/k uses Emscripten and its
implementation serves as a case study on how to use Wasm/k in a compiler that
targets WebAssembly. We present several case studies using C/k, and show that
on implementing green threads, it can outperform the state-of-the-art approach
Asyncify with an 18% improvement in performance and a 30% improvement in code
size.
","['Donald Pinckney', 'Arjun Guha', 'Yuriy Brun']"
http://arxiv.org/abs/2112.11745v1,WebAssembly,2021-12-22T09:24:55Z,2021-12-22T09:24:55Z,Security Risks of Porting C Programs to WebAssembly,"  WebAssembly is a compilation target for cross-platform applications that is
increasingly being used. In this paper, we investigate whether one can
transparently cross-compile C programs to WebAssembly, and if not, what impact
porting can have on their security. We compile 17,802 programs that exhibit
common vulnerabilities to 64-bit x86 and to WebAssembly binaries, and we
observe that the execution of 4,911 binaries produces different results across
these platforms. Through manual inspection, we identify three classes of root
causes for such differences: the use of a different standard library
implementation, the lack of security measures in WebAssembly, and the different
semantics of the execution environments. We describe our observations and
discuss the ones that are critical from a security point of view and need most
attention from developers. We conclude that compiling an existing C program to
WebAssembly for cross-platform distribution may require source code
adaptations; otherwise, the security of the WebAssembly application may be at
risk.
","['Quentin Stiévenart', 'Coen De Roover', 'Mohammad Ghafari']"
http://arxiv.org/abs/2111.01421v1,WebAssembly,2021-11-02T08:30:37Z,2021-11-02T08:30:37Z,The Security Risk of Lacking Compiler Protection in WebAssembly,"  WebAssembly is increasingly used as the compilation target for cross-platform
applications. In this paper, we investigate whether one can rely on the
security measures enforced by existing C compilers when compiling C programs to
WebAssembly. We compiled 4,469 C programs with known buffer overflow
vulnerabilities to x86 code and to WebAssembly, and observed the outcome of the
execution of the generated code to differ for 1,088 programs. Through manual
inspection, we identified that the root cause for these is the lack of security
measures such as stack canaries in the generated WebAssembly: while x86 code
crashes upon a stack-based buffer overflow, the corresponding WebAssembly
continues to be executed. We conclude that compiling an existing C program to
WebAssembly without additional precautions may hamper its security, and we
encourage more research in this direction.
","['Quentin Stiévenart', 'Coen De Roover', 'Mohammad Ghafari']"
http://arxiv.org/abs/2212.08427v2,WebAssembly,2022-12-16T12:02:26Z,2023-04-27T05:53:26Z,WebAssembly Diversification for Malware Evasion,"  WebAssembly has become a crucial part of the modern web, offering a faster
alternative to JavaScript in browsers. While boosting rich applications in
browser, this technology is also very efficient to develop cryptojacking
malware. This has triggered the development of several methods to detect
cryptojacking malware. However, these defenses have not considered the
possibility of attackers using evasion techniques. This paper explores how
automatic binary diversification can support the evasion of WebAssembly
cryptojacking detectors. We experiment with a dataset of 33 WebAssembly
cryptojacking binaries and evaluate our evasion technique against two malware
detectors: VirusTotal, a general-purpose detector, and MINOS, a
WebAssembly-specific detector. Our results demonstrate that our technique can
automatically generate variants of WebAssembly cryptojacking that evade the
detectors in 90% of cases for VirusTotal and 100% for MINOS. Our results
emphasize the importance of meta-antiviruses and diverse detection techniques,
and provide new insights into which WebAssembly code transformations are best
suited for malware evasion. We also show that the variants introduce limited
performance overhead, making binary diversification an effective technique for
evasion.
","['Javier Cabrera-Arteaga', 'Martin Monperrus', 'Tim Toady', 'Benoit Baudry']"
http://arxiv.org/abs/2309.07638v2,WebAssembly,2023-09-14T12:03:17Z,2024-01-17T12:21:27Z,WASM-MUTATE: Fast and Effective Binary Diversification for WebAssembly,"  WebAssembly is the fourth officially endorsed Web language. It is recognized
because of its efficiency and design, focused on security. Yet, its swiftly
expanding ecosystem lacks robust software diversification systems. We introduce
WASM-MUTATE, a diversification engine specifically designed for WebAssembly.
Our engine meets several essential criteria: 1) To quickly generate
functionally identical, yet behaviorally diverse, WebAssembly variants, 2) To
be universally applicable to any WebAssembly program, irrespective of the
source programming language, and 3) Generated variants should counter
side-channels. By leveraging an e-graph data structure, WASM-MUTATE is
implemented to meet both speed and efficacy. We evaluate WASM-MUTATE by
conducting experiments on 404 programs, which include real-world applications.
Our results highlight that WASM-MUTATE can produce tens of thousands of unique
and efficient WebAssembly variants within minutes. Significantly, WASM-MUTATE
can safeguard WebAssembly binaries against timing side-channel
attacks,especially those of the Spectre type.
","['Javier Cabrera-Arteaga', 'Nicholas Fitzgerald', 'Martin Monperrus', 'Benoit Baudry']"
http://arxiv.org/abs/2410.17925v1,WebAssembly,2024-10-23T14:41:59Z,2024-10-23T14:41:59Z,Securing Stack Smashing Protection in WebAssembly Applications,"  WebAssembly is an instruction set architecture and binary format standard,
designed for secure execution by an interpreter. Previous work has shown that
WebAssembly is vulnerable to buffer overflow due to the lack of effective
protection mechanisms. In this paper, we evaluate the implementation of Stack
Smashing Protection (SSP) in WebAssembly standalone runtimes, and uncover two
weaknesses in their current implementation. The first one is the possibility to
overwrite the SSP reference value because of the contiguous memory zones inside
a WebAssembly process. The second comes from the reliance of WebAssembly on the
runtime to provide randomness in order to initialize the SSP reference value,
which impacts the robustness of the solution. We address these two flaws by
hardening the SSP implementation in terms of storage and random generator
failure, in a way that is generalizable to all of WebAssembly. We evaluate our
new, more robust, solution to prove that the implemented improvements do not
reduce the efficiency of SSP.
","['Quentin Michaud', 'Yohan Pipereau', 'Olivier Levillain', 'Dhouha Ayed']"
http://arxiv.org/abs/2411.03344v1,WebAssembly,2024-11-02T23:35:19Z,2024-11-02T23:35:19Z,"Comparing Security and Efficiency of WebAssembly and Linux Containers in
  Kubernetes Cloud Computing","  This study investigates the potential of WebAssembly as a more secure and
efficient alternative to Linux containers for executing untrusted code in cloud
computing with Kubernetes. Specifically, it evaluates the security and
performance implications of this shift. Security analyses demonstrate that both
Linux containers and WebAssembly have attack surfaces when executing untrusted
code, but WebAssembly presents a reduced attack surface due to an additional
layer of isolation. The performance analysis further reveals that while
WebAssembly introduces overhead, particularly in startup times, it could be
negligible in long-running computations. However, WebAssembly enhances the core
principle of containerization, offering better security through isolation and
platform-agnostic portability compared to Linux containers. This research
demonstrates that WebAssembly is not a silver bullet for all security concerns
or performance requirements in a Kubernetes environment, but typical attacks
are less likely to succeed and the performance loss is relatively small.
",['Jasper Alexander Wiegratz']
http://arxiv.org/abs/1901.09056v3,WebAssembly,2019-01-25T19:20:44Z,2019-05-31T14:10:41Z,Not So Fast: Analyzing the Performance of WebAssembly vs. Native Code,"  All major web browsers now support WebAssembly, a low-level bytecode intended
to serve as a compilation target for code written in languages like C and C++.
A key goal of WebAssembly is performance parity with native code; previous work
reports near parity, with many applications compiled to WebAssembly running on
average 10% slower than native code. However, this evaluation was limited to a
suite of scientific kernels, each consisting of roughly 100 lines of code.
Running more substantial applications was not possible because compiling code
to WebAssembly is only part of the puzzle: standard Unix APIs are not available
in the web browser environment. To address this challenge, we build
Browsix-Wasm, a significant extension to Browsix that, for the first time,
makes it possible to run unmodified WebAssembly-compiled Unix applications
directly inside the browser. We then use Browsix-Wasm to conduct the first
large-scale evaluation of the performance of WebAssembly vs. native. Across the
SPEC CPU suite of benchmarks, we find a substantial performance gap:
applications compiled to WebAssembly run slower by an average of 45% (Firefox)
to 55% (Chrome), with peak slowdowns of 2.08x (Firefox) and 2.5x (Chrome). We
identify the causes of this performance degradation, some of which are due to
missing optimizations and code generation issues, while others are inherent to
the WebAssembly platform.
","['Abhinav Jangda', 'Bobby Powers', 'Emery Berger', 'Arjun Guha']"
http://arxiv.org/abs/2204.12575v1,WebAssembly,2022-04-26T20:26:35Z,2022-04-26T20:26:35Z,Wasmati: An Efficient Static Vulnerability Scanner for WebAssembly,"  WebAssembly is a new binary instruction format that allows targeted compiled
code written in high-level languages to be executed with near-native speed by
the browser's JavaScript engine. However, given that WebAssembly binaries can
be compiled from unsafe languages like C/C++, classical code vulnerabilities
such as buffer overflows or format strings can be transferred over from the
original programs down to the cross-compiled binaries. As a result, this
possibility of incorporating vulnerabilities in WebAssembly modules has widened
the attack surface of modern web applications. This paper presents Wasmati, a
static analysis tool for finding security vulnerabilities in WebAssembly
binaries. It is based on the generation of a code property graph (CPG), a
program representation previously adopted for detecting vulnerabilities in
various languages but hitherto unapplied to WebAssembly. We formalize the
definition of CPG for WebAssembly, introduce techniques to generate CPG for
complex WebAssembly, and present four different query specification languages
for finding vulnerabilities by traversing a program's CPG. We implemented ten
queries capturing different vulnerability types and extensively tested Wasmati
on four heterogeneous datasets. We show that Wasmati can scale the generation
of CPGs for large real-world applications and can efficiently find
vulnerabilities for all our query types. We have also tested our tool on
WebAssembly binaries collected in the wild and identified several potential
vulnerabilities, some of which we have manually confirmed to exist unless the
enclosing application properly sanitizes the interaction with such affected
binaries.
","['Tiago Brito', 'Pedro Lopes', 'Nuno Santos', 'José Fragoso Santos']"
http://arxiv.org/abs/2002.10213v2,WebAssembly,2020-02-24T12:58:25Z,2022-11-23T13:43:05Z,Superoptimization of WebAssembly Bytecode,"  Motivated by the fast adoption of WebAssembly, we propose the first
functional pipeline to support the superoptimization of WebAssembly bytecode.
Our pipeline works over LLVM and Souper. We evaluate our superoptimization
pipeline with 12 programs from the Rosetta code project. Our pipeline improves
the code section size of 8 out of 12 programs. We discuss the challenges faced
in superoptimization of WebAssembly with two case studies.
","['Javier Cabrera-Arteaga', 'Shrinish Donde', 'Jian Gu', 'Orestis Floros', 'Lucas Satabin', 'Benoit Baudry', 'Martin Monperrus']"
http://arxiv.org/abs/2306.05698v1,WebAssembly,2023-06-09T06:35:14Z,2023-06-09T06:35:14Z,"JABBERWOCK: A Tool for WebAssembly Dataset Generation and Its
  Application to Malicious Website Detection","  Machine learning is often used for malicious website detection, but an
approach incorporating WebAssembly as a feature has not been explored due to a
limited number of samples, to the best of our knowledge. In this paper, we
propose JABBERWOCK (JAvascript-Based Binary EncodeR by WebAssembly Optimization
paCKer), a tool to generate WebAssembly datasets in a pseudo fashion via
JavaScript. Loosely speaking, JABBERWOCK automatically gathers JavaScript code
in the real world, convert them into WebAssembly, and then outputs vectors of
the WebAssembly as samples for malicious website detection. We also conduct
experimental evaluations of JABBERWOCK in terms of the processing time for
dataset generation, comparison of the generated samples with actual WebAssembly
samples gathered from the Internet, and an application for malicious website
detection. Regarding the processing time, we show that JABBERWOCK can construct
a dataset in 4.5 seconds per sample for any number of samples. Next, comparing
10,000 samples output by JABBERWOCK with 168 gathered WebAssembly samples, we
believe that the generated samples by JABBERWOCK are similar to those in the
real world. We then show that JABBERWOCK can provide malicious website
detection with 99\% F1-score because JABBERWOCK makes a gap between benign and
malicious samples as the reason for the above high score. We also confirm that
JABBERWOCK can be combined with an existing malicious website detection tool to
improve F1-scores. JABBERWOCK is publicly available via GitHub
(https://github.com/c-chocolate/Jabberwock).
","['Chika Komiya', 'Naoto Yanai', 'Kyosuke Yamashita', 'Shingo Okamura']"
http://arxiv.org/abs/1807.08349v1,WebAssembly,2018-07-22T19:13:51Z,2018-07-22T19:13:51Z,Taint Tracking for WebAssembly,"  WebAssembly seeks to provide an alternative to running large and untrusted
binaries within web browsers by implementing a portable, performant, and secure
bytecode format for native web computation. However, WebAssembly is largely
unstudied from a security perspective. In this work, we build the first
WebAssembly virtual machine that runs in native JavaScript, and implement a
novel taint tracking system that allows a user to run untrusted WebAssembly
code while monitoring the flow of sensitive data through the application. We
also introduce indirect taint, a label that denotes the implicit flow of
sensitive information between local variables. Through rigorous testing and
validation, we show that our system is correct, secure, and relatively
efficient, benefiting from the native performance of WebAssembly while
retaining precise security guarantees of more mature software paradigms.
","['Aron Szanto', 'Timothy Tamm', 'Artidoro Pagnoni']"
